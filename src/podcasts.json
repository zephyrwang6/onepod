[
  {
    "id": "FKPZw2mXeiJIbWkYtkjckV9LnRb",
    "title": "Ian Fischer X Y Combinator：7人团队超越OpenAI的脚手架秘密",
    "rawTitle": "0228：Ian Fischer X Y Combinator：7人团队超越OpenAI的脚手架秘密",
    "dateCode": "0228",
    "youtubeId": "UPGB-hsAoVY",
    "feishuUrl": "https://my.feishu.cn/wiki/FKPZw2mXeiJIbWkYtkjckV9LnRb",
    "intro": [
      "今天看到 Ian Fischer 去了 Y Combinator Lightcone 的播客。",
      "Ian Fischer 是 Poetic 的联合创始人兼 CEO，前 Google DeepMind 研究员，团队仅 7 人。他们在 ARC-AGI 和 Humanity's Last Exam 基准上超越了 OpenAI 和 Anthropic。",
      "这期播客总共录了约 20 分钟，Ian 谈到了 12 个有趣的观点：",
      "1、Poetic 做的是递归自我改进系统——让 AI 自己优化自己。这被认为是 AI 的\"圣杯\"，但他们用远低于训练新模型的成本做到了（不到 10 万美元 vs 数百亿美元）。",
      "2、Fine-tuning 是\"燃烧的钱\"。初创公司花数百万微调后，新一代基础模型发布，一切归零。你永远追不上 Anthropic 和 OpenAI 的发布节奏。",
      "3、他们的系统叫\"脚手架\"（Stilts）——坐在基础模型上面的推理系统。当你站在脚手架上，任何新模型发布，你都能变得比它更高。",
      "4、ARC-AGI V2 发布时，Google Gemini Deep Think 以 45% 领先。两天后 Poetic 用 Gemini 3 Pro（更便宜的模型）+ 脚手架达到 54%，成本只有对手一半。",
      "5、最近他们在 Humanity's Last Exam（2500 道各领域 PhD 级别难题）达到 55%，超越 Anthropic Claude Opus 4.6 的 53.1%。而且成本不到 10 万美元。",
      "6、团队只有 7 人——全是研究科学家和研究工程师。这是典型的小团队 AGI 研究模式。",
      "7、传统 ML 范式是你必须非常了解数据集，但他们在把这个过程外包给 AI——让 AI 自己找出失败模式，自己构建推理策略。",
      "8、他们的系统不只是优化 prompts，还包括推理策略、代码结构、上下文填充、总结方式——是整个\"推理系统\"的优化。",
      "9、他们发表过一篇论文，手动优化 Gemini 1.5 Flash 从 5% 提升到 95%——关键是加入推理策略（reasoning strategies），不是更好的 prompt。",
      "10、对于初创公司，脚手架范式意味着：你的 agent 不再绑定某个特定模型，可以随着基础模型进化而自动进化。",
      "11、他对工程师的建议：每天都要用 AI 做事，push 自己找到模型的能力边界。8 个月前用 GPT-5 写 iOS app 已很简单，现在更容易。",
      "12、这代表着与 RL（强化学习）完全不同的新范式——不是训练新模型，而是优化\"如何使用模型\"。"
    ],
    "highlights": [
      "断断续续看完这期 Poetic 的访谈，干货密度太高了。",
      "Ian Fischer 之前在 Google DeepMind 做了十年机器学习研究，后来自己创业。之前做的是移动开发工具公司（被 Google 收购），后来决定转向 AI。",
      "这期的主题非常有意思：小团队如何用\"脚手架\"超越大公司的基础模型。"
    ],
    "fullText": "今天看到 Ian Fischer 去了 Y Combinator Lightcone 的播客。\nIan Fischer 是 Poetic 的联合创始人兼 CEO，前 Google DeepMind 研究员，团队仅 7 人。他们在 ARC-AGI 和 Humanity's Last Exam 基准上超越了 OpenAI 和 Anthropic。\n这期播客总共录了约 20 分钟，Ian 谈到了 12 个有趣的观点：\n1、Poetic 做的是递归自我改进系统——让 AI 自己优化自己。这被认为是 AI 的\"圣杯\"，但他们用远低于训练新模型的成本做到了（不到 10 万美元 vs 数百亿美元）。\n2、Fine-tuning 是\"燃烧的钱\"。初创公司花数百万微调后，新一代基础模型发布，一切归零。你永远追不上 Anthropic 和 OpenAI 的发布节奏。\n3、他们的系统叫\"脚手架\"（Stilts）——坐在基础模型上面的推理系统。当你站在脚手架上，任何新模型发布，你都能变得比它更高。\n4、ARC-AGI V2 发布时，Google Gemini Deep Think 以 45% 领先。两天后 Poetic 用 Gemini 3 Pro（更便宜的模型）+ 脚手架达到 54%，成本只有对手一半。\n5、最近他们在 Humanity's Last Exam（2500 道各领域 PhD 级别难题）达到 55%，超越 Anthropic Claude Opus 4.6 的 53.1%。而且成本不到 10 万美元。\n6、团队只有 7 人——全是研究科学家和研究工程师。这是典型的小团队 AGI 研究模式。\n7、传统 ML 范式是你必须非常了解数据集，但他们在把这个过程外包给 AI——让 AI 自己找出失败模式，自己构建推理策略。\n8、他们的系统不只是优化 prompts，还包括推理策略、代码结构、上下文填充、总结方式——是整个\"推理系统\"的优化。\n9、他们发表过一篇论文，手动优化 Gemini 1.5 Flash 从 5% 提升到 95%——关键是加入推理策略（reasoning strategies），不是更好的 prompt。\n10、对于初创公司，脚手架范式意味着：你的 agent 不再绑定某个特定模型，可以随着基础模型进化而自动进化。\n11、他对工程师的建议：每天都要用 AI 做事，push 自己找到模型的能力边界。8 个月前用 GPT-5 写 iOS app 已很简单，现在更容易。\n12、这代表着与 RL（强化学习）完全不同的新范式——不是训练新模型，而是优化\"如何使用模型\"。\n断断续续看完这期 Poetic 的访谈，干货密度太高了。\nIan Fischer 之前在 Google DeepMind 做了十年机器学习研究，后来自己创业。之前做的是移动开发工具公司（被 Google 收购），后来决定转向 AI。\n这期的主题非常有意思：小团队如何用\"脚手架\"超越大公司的基础模型。\n#01 脚手架的诞生\n主持人： 什么是 Poetic？和 RL 有什么区别？\nIan： 我们做的是递归自我改进系统——让 AI 自己让自己变得更聪明。核心洞察是，我们可以比任何其他方式更快、更便宜地实现递归自我改进。\n其他方法都需要从零训练新 LLM，成本是数百亿美元、耗时几个月。而 Anthropic 或 OpenAI 下一版模型发布，你的成果就过时了。\n主持人： 这是初创公司最想要的东西。你刚说的 Bitter Lesson——如果没有 Poetic，你们会怎么做？\nIan： 通常是：先收集数万条特定问题的数据，花大钱微调 frontier model。然后新模型发布，一切归零。你做的是重复烧钱。\n有了 Poetic，你得到的是一个\"脚手架\"——坐在模型上面的推理系统。当新模型发布，你的脚手架继续可用，性能提升更明显。成本还低得多。\n#02 超越 Gemini 和 Claude\n主持人： 你们在 ARC-AGI 的成绩真的很疯狂。\nIan： Gemini 3 Deep Think 发布时达到 45%，两天后我们用更便宜的 Gemini 3 Pro + 脚手架达到 54%。成本只有 32 美元/题 vs 70 美元。\n主持人： Humanity's Last Exam 呢？\nIan： 2500 道各领域 PhD 级别难题。之前 Anthropic Claude Opus 4.6 是 53.1%。我们达到 55%。关键是成本不到 10 万美元——而每次基础模型训练都是数百亿。\n#03 7人团队的秘诀\n主持人： 你们只有 7 个人？\nIan： 对，7 个研究科学家和研究工程师。\n主持人： 这真的很反直觉。现在 AI 圈都在堆算力，你们用小团队做到这个？\nIan： 我们把过去需要人来做的工作——优化 evals、调整 prompts、上下文工程——全部自动化了。系统自己找出失败模式，自己构建推理策略。\n我们不手动查看数据——是 AI 在看数据，然后告诉我们需要什么。\n#04 对工程师的建议\nIan： 我的建议就是——每天都要用 AI 做事。我去年周末用 GPT-5 帮我写了一个 iOS app，十年没做这个了。八个月前的事，现在已经更容易了。\n不要设限——想象任何你想做的事，用 AI 试试能走多远。你会惊讶于能做到什么。\n用 Ian 的话收个尾：\"不要限制自己。想象任何你想做的事，用 AI 试试能走多远，你会让世界变得更好。\"\n这是完全不同的范式——不是训练更贵的模型，而是优化\"如何使用模型\"。脚手架让任何 Agent 公司都能站在基础模型的肩膀上，而且自动进化。\nYouTube 链接：https://www.youtube.com/watch?v=UPGB-hsAoVY\n",
    "ytTitle": "The Powerful Alternative To Fine-Tuning",
    "ytChannel": "Y Combinator",
    "ytChannelUrl": "https://www.youtube.com/@ycombinator",
    "ytViews": null,
    "ytPublished": null
  },
  {
    "id": "HPZwwRr3Kickp9kIJihcozTjnmc",
    "title": "Max-Welling-所有问题的底层都是材料问题",
    "rawTitle": "0227-Max-Welling-所有问题的底层都是材料问题",
    "dateCode": "0227",
    "youtubeId": "V7_Ec2WFAWs",
    "feishuUrl": "https://my.feishu.cn/wiki/HPZwwRr3Kickp9kIJihcozTjnmc",
    "intro": [
      "断断续续，终于看完了 Max Welling 这期播客。",
      "Max Welling 是 AI 圈子的老朋友了——variational autoencoders（VAE）的奠基人之一，graph neural networks 和 equivariant neural networks 的先驱，前 UC Amsterdam 教授，现在是 AI for Science 创业公司 CUSAI 的联合创始人。",
      "这期播客信息密度极高，探讨了 AI 与物理学的交汇、为什么 AI for Science 现在爆发、材料的未来，以及他即将出版的新书。干货太多，我今天不忙，把这次访谈精编出来，供大家学习。赠人玫瑰，手有余香。",
      "下面是 YouTube 链接：https://www.youtube.com/watch?v=V7_Ec2WFAWs"
    ],
    "highlights": [
      "编辑补充： 这期播客让我印象最深的不是具体的技术细节，而是 Max 那个核心洞察——\"underlying almost everything is a material\"。我们讨论 AI 写代码、AI 画画、AI 聊天，但很少有人想到这些 AI 系统的物理载体。GPU 需要先进制程，制程需要光刻机，光刻机需要极紫外光技术——每一个环节都是材料科学问题。AI 的尽头是物理，物理的尽头是材料。这条思路值得每个 AI 从业者思考。"
    ],
    "fullText": "断断续续，终于看完了 Max Welling 这期播客。\nMax Welling 是 AI 圈子的老朋友了——variational autoencoders（VAE）的奠基人之一，graph neural networks 和 equivariant neural networks 的先驱，前 UC Amsterdam 教授，现在是 AI for Science 创业公司 CUSAI 的联合创始人。\n这期播客信息密度极高，探讨了 AI 与物理学的交汇、为什么 AI for Science 现在爆发、材料的未来，以及他即将出版的新书。干货太多，我今天不忙，把这次访谈精编出来，供大家学习。赠人玫瑰，手有余香。\n下面是 YouTube 链接：https://www.youtube.com/watch?v=V7_Ec2WFAWs\n#01 从量子引力到 AI for Science：物理才是那条隐藏的线索\n主持人：Max，你的研究生涯跨越了量子引力、变分自编码器、等变神经网络、还有现在的材料科学。这些看似不相关的领域，背后有什么共同的线索？\nMax Welling： 物理是我职业生涯的那条线索。\n年轻的时候，我追随自己的直觉——对什么问题感到兴奋，就去研究什么。我对量子引力感兴趣，对黑洞内部好奇，对量子力学的本质着迷。那时候我觉得\"影响力\"不重要，做纯理论就好。\n但随着年纪增长，我开始思考 impact（影响力）。量子引力研究在可预见的未来不会有任何实际影响。我开始担心气候变化，觉得应该从技术角度做点什么。这就是创立 CUSAI 的原因——把 AI 用于材料科学，帮助能源转型。\n但物理始终是那条线。 从量子引力到等变神经网络，看起来跨度大，其实都是关于对称性（symmetry）的数学工具。粒子物理学、广义相对论、机器学习——对称性在所有这些领域都扮演核心角色。\n> \"物理学一直是那条隐藏的线索。我试图把物理学的思维方式应用到机器学习，构建更好的算法。\"\n#02 为什么是现在？AI for Science 为何突然爆发\n主持人：AI for Science 现在投资爆炸，Jeff Bezos 的公司刚融了 62 亿美元。这是泡沫还是真的到了临界点？\nMax Welling： 有两个原因。\n第一，工具成熟了。 我们有了真正强大的 AI 工具可以应用到科学问题。最成功的例子是蛋白质折叠（AlphaFold），另一个是机器学习力场（machine learning force fields）。这两个领域已经证明了 AI 的价值。\n第二，时机到了。 我们现在真的可以有效地模拟这些系统，推动科学方法的进步。这是一个独特的时刻——就像一片未开发的荒原，没人去过，你可以冲进去\"收割\"。\n> \"我们正处于一个临界点——这是真正的变革时刻，不是泡沫。人们正在看到真实的成果。\"\n#03 底层都是材料问题：LLM 的尽头是 GPU，GPU 的尽头是材料\nMax Welling： 我想传达一个观点——底层一切都是材料。\n我们现在都在讨论 LLM，这是软件层。但 LLM 运行在 GPU 上，GPU 底层是晶圆，晶圆上需要沉积材料。需要 EUV 光刻来刻蚀结构——这本身就是材料问题。\n我们现在已经达到了摩尔定律的极限，要继续进步，需要新材料。\n能源转型也是同样的道理：\n• 电池是材料问题\n• 燃料电池是材料问题\n• 太阳能板（钙钛矿叠层）也是材料问题\n> \"无论你做什么，往深处挖，最终都是一个材料问题。塑料污染地球？如果能发明一种几个月后能自我分解、变成肥料的塑料，这些都可以做到。\"\n#04 CUSAI 的野心：做\"物理处理单元\"PPUs\n主持人：CUSAI 现在在做什么？\nMax Welling： CUSAI 成立 20 个月了，目前 40 人，融资 1.3 亿美元。我们正在构建一个 AI for Science 平台。\n我的愿景是：物理处理单元（Physics Processing Units，PPU）。\n就像有数字处理单元（CPU/GPU），未来会有物理处理单元——让自然帮我们计算。\n这是已知的最快的计算机——大自然。但难点是\"编程\"大自然，你需要做实验。\n> \"你可以数据中心里做计算，然后让自然帮你做计算。接口更复杂，但两者需要无缝协作，找到你感兴趣的新材料。\"\n平台工作方式：\n生成阶段：训练模型生成候选材料\n数字孪生阶段：多尺度、多保真度的模拟，先做便宜的计算，排除明显没用的，层层筛选\n实验阶段：最后送到实验室验证\n现在我们在加入 Agent。 有文献搜索 Agent，有自动编排计算和实验的 Agent。越来越自动化。\n> \"我们的护城河不是火箭科学，而是数据——你能获取什么数据，以及平台本身的建设。\"\n#05 人类不会被淘汰：增强而非取代\n主持人：你们最终会完全自动化，让人类退出这个循环吗？\nMax Welling： 我的愿景不是\"黑灯实验室\"——关上门，AI 自己发现有趣的材料。那不是我的愿景。\n我的愿景是赋能领域专家。 化学家和材料科学家坐在公司里，因为 AI 的帮助，可以快得多地开发材料。\n一开始需要专家告诉 AI 如何设置参数（DFT 计算等）。我们逐步自动化这些环节。但最终，化学家仍然会决定什么是好材料、什么不是。\n> \"我的愿景是赋予领域专家更强大的工具，而不是取代他们。这个过程会很慢，需要人类在环，因为问题非常垂直。\"\n#06 等变神经网络：为什么对称性这么重要\n主持人：能简单解释一下 equivariance（等变性）吗？\nMax Welling： 等变性是把对称性注入神经网络。\n如果一个神经网络需要识别一个瓶子，然后你旋转瓶子——没有等变性的网络需要重新训练，因为它\"不认识\"旋转后的瓶子。\n等变性意味着：一旦训练好一个方向，它就理解所有方向。这意味着训练数据量大幅减少。\n> \"等变性是对权重的约束，让网络理解旋转、置换等对称性。这是把物理学的对称性思想引入机器学习。\"\n但这里有复杂的权衡。 有时候数据增强效果更好，因为约束太紧会增加优化难度。最终是数据量与归纳偏置之间的权衡——这 就是机器学习的\"苦涩教训\"（Bitter Lesson）。\n#07 新书预告：生成 AI 与随机热力学的数学联系\n主持人：你即将出版的新书关于什么？\nMax Welling： 书名叫《Generative AI and Stochastic Thermodynamics》。\n这本书揭示了一个惊人的事实：生成 AI（扩散模型等）的数学，与非平衡统计力学（stochastic thermodynamics）的数学是完全一样的。\n两者都涉及：\n• 变分自由能（variational free energy）\n• Langevin 动力学\n• 扩散过程\nJeff Hinton 和 Radford Neil 很久以前就在机器学习中引入了变分自由能。物理学家那边也在发展随机热力学。现在我们发现它们是同一套数学！\n> \"这非常迷人。两个领域的数学完全相同，但来自完全不同的背景。这是真正的跨学科交叉。\"\n#08 给非科学家的话：为什么你应该关注 AI for Science\n主持人：如果你不是科学家，怎么参与这个领域？\nMax Welling： 读我的书（笑）。但更重要的是——你已经在其中了。\n你用的手机、GPU、电脑——底层都是材料问题。AI for Science 影响的不仅是最前沿的科学研究，而是整个技术栈。\n> \"underlying almost everything is a material（底层几乎所有东西都是材料）。\"\n编辑补充： 这期播客让我印象最深的不是具体的技术细节，而是 Max 那个核心洞察——\"underlying almost everything is a material\"。我们讨论 AI 写代码、AI 画画、AI 聊天，但很少有人想到这些 AI 系统的物理载体。GPU 需要先进制程，制程需要光刻机，光刻机需要极紫外光技术——每一个环节都是材料科学问题。AI 的尽头是物理，物理的尽头是材料。这条思路值得每个 AI 从业者思考。\n",
    "ytTitle": "🔬Max Welling: Materials Underlie Everything",
    "ytChannel": "Latent Space",
    "ytChannelUrl": "https://www.youtube.com/@LatentSpacePod",
    "ytViews": null,
    "ytPublished": null
  },
  {
    "id": "H7xbw9bPJigwF7k5YVMcIonynnf",
    "title": "Alex Mathew X Stanford GSB：17岁AI原住民正在重新定义学习和创业",
    "rawTitle": "0226：Alex Mathew X Stanford GSB：17岁AI原住民正在重新定义学习和创业",
    "dateCode": "0226",
    "youtubeId": "n-xBQE8A-3E",
    "feishuUrl": "https://my.feishu.cn/wiki/H7xbw9bPJigwF7k5YVMcIonynnf",
    "intro": [
      "今天看到 Alex Mathew 去了 Stanford GSB 的 \"AI & I\" 播客。",
      "Alex 是德州奥斯汀 Alpha High School 的17岁高三学生，这所学校没有传统老师，学生通过 AI 平台学习所有学术内容。他同时是一名创业者，正在开发 AI 毛绒玩具 Barry，目标是成为下一个 Build-A-Bear。",
      "这期播客谈到了 13 个有趣的观点：",
      "1、没有老师的学校。Alpha School 没有传统意义上的\"老师\"，只有\"guides\"（导师），他们的角色不是教授知识，而是激励学生、提供情感支持、帮助学生规划目标。知识传授完全由 AI 平台完成。",
      "2、AI 不是聊天机器人，而是后台的学习定制引擎。Alex 强调他们不是和 ChatGPT 聊天学习，而是 AI 在后台分析每个学生的差距，定制化推送学习内容——视频、文章、测验的组合。",
      "3、掌握式学习（Mastery-based learning）。测验从 0% 开始，学生需要达到 80% 掌握度才能进入下一单元。这种\"从零到精通\"的模式确保真正理解，而不是应付考试。",
      "4、学习进度可以谈判。Alex 可以和导师 negotiate：如果他现在完成学期 A，就可以去旧金山全职做项目 20 天，回来后完成学期 B，仍然能获得高中学分并进入梦想大学。这种灵活性是传统学校无法想象的。",
      "5、番茄工作法成为日常。27 分钟专注学习 + 5 分钟休息，没有传统课间休息。学生可以在休息时去咖啡店、杂货店，或者和朋友交流。",
      "6、AI 工具的个人排名。Alex 给主流 AI 排名：Claude 是 S 级（信任 Anthropic 的研究方法和领导层），ChatGPT 第二（深度研究最强），Gemini 和 Grok 并列（Gemini 3 很酷，Grok 敢于尝试）。",
      "7、不读纸质书的逻辑。Alex 不读传统书籍，认为静态知识不如动态对话有价值。他用 Grok 语音模式辅助阅读，认为\"如果只是为了内容，为什么不直接和 AI 对话？\"",
      "8、社交媒体的矛盾态度。他认为社交媒体\"100%腐蚀了\"年轻一代的大脑（过度刺激、注意力分散、与他人比较），但承认它也有好处：思想交流（Matt Ridley 的\"idea sex\"）和朋友间的连接方式。",
      "9、Gen Z 对 AI 的复杂态度。50% 悲观（担心环境、就业、AI 取代人类），25% 不确定，25% 乐观。但矛盾的是，70-75% 的人仍在使用 AI，72% 的青少年用过 AI 陪伴，52% 几乎每天使用。",
      "10、AI 不会取代人类连接，而是帮助建立自我意识。Alex 的创业项目 Barry 是一个 AI 毛绒玩具，帮助青少年处理日常心理问题。他的理念不是让 AI 取代人类，而是给用户一个安全的空间来练习脆弱性和自我觉察。",
      "11、大学规划的三条路径思维。Alex 考虑三条路：传统顶尖大学（哈佛、伯克利）、替代大学（如 University of Austin）、直接创业（如 Thiel Fellowship）。他的目标是\"优化保留所有决策可能性\"。",
      "12、学校像霍格沃茨分学院。Alpha School 有类似霍格沃茨的\"house\"系统，Alex 在 Sparta（斯巴达）学院——专为专注项目、想要\" ramp it up\"的学生设计。学生甚至参与雇佣和解雇导师，Alex 说：\"我对导师选择非常挑剔，大多数都被我拒绝了。\""
    ],
    "highlights": [
      "断断续续，终于看完了 Stanford GSB 这期对17岁高中生 Alex Mathew 的采访。",
      "干货很多。Alex 可能是 AI 时代\"原住民\"的最佳样本——他不是在使用 AI 工具，而是在一个由 AI 驱动的学习生态中长大。他的思维模式、学习方式、创业路径，都和上一代\"AI 移民\"截然不同。",
      "我今天不忙，把这次访谈全文精编出来，供大家学习。赠人玫瑰，手有余香。",
      "下面是 YouTube 链接：https://www.youtube.com/watch?v=n-xBQE8A-3E"
    ],
    "fullText": "今天看到 Alex Mathew 去了 Stanford GSB 的 \"AI & I\" 播客。\nAlex 是德州奥斯汀 Alpha High School 的17岁高三学生，这所学校没有传统老师，学生通过 AI 平台学习所有学术内容。他同时是一名创业者，正在开发 AI 毛绒玩具 Barry，目标是成为下一个 Build-A-Bear。\n这期播客谈到了 13 个有趣的观点：\n1、没有老师的学校。Alpha School 没有传统意义上的\"老师\"，只有\"guides\"（导师），他们的角色不是教授知识，而是激励学生、提供情感支持、帮助学生规划目标。知识传授完全由 AI 平台完成。\n2、AI 不是聊天机器人，而是后台的学习定制引擎。Alex 强调他们不是和 ChatGPT 聊天学习，而是 AI 在后台分析每个学生的差距，定制化推送学习内容——视频、文章、测验的组合。\n3、掌握式学习（Mastery-based learning）。测验从 0% 开始，学生需要达到 80% 掌握度才能进入下一单元。这种\"从零到精通\"的模式确保真正理解，而不是应付考试。\n4、学习进度可以谈判。Alex 可以和导师 negotiate：如果他现在完成学期 A，就可以去旧金山全职做项目 20 天，回来后完成学期 B，仍然能获得高中学分并进入梦想大学。这种灵活性是传统学校无法想象的。\n5、番茄工作法成为日常。27 分钟专注学习 + 5 分钟休息，没有传统课间休息。学生可以在休息时去咖啡店、杂货店，或者和朋友交流。\n6、AI 工具的个人排名。Alex 给主流 AI 排名：Claude 是 S 级（信任 Anthropic 的研究方法和领导层），ChatGPT 第二（深度研究最强），Gemini 和 Grok 并列（Gemini 3 很酷，Grok 敢于尝试）。\n7、不读纸质书的逻辑。Alex 不读传统书籍，认为静态知识不如动态对话有价值。他用 Grok 语音模式辅助阅读，认为\"如果只是为了内容，为什么不直接和 AI 对话？\"\n8、社交媒体的矛盾态度。他认为社交媒体\"100%腐蚀了\"年轻一代的大脑（过度刺激、注意力分散、与他人比较），但承认它也有好处：思想交流（Matt Ridley 的\"idea sex\"）和朋友间的连接方式。\n9、Gen Z 对 AI 的复杂态度。50% 悲观（担心环境、就业、AI 取代人类），25% 不确定，25% 乐观。但矛盾的是，70-75% 的人仍在使用 AI，72% 的青少年用过 AI 陪伴，52% 几乎每天使用。\n10、AI 不会取代人类连接，而是帮助建立自我意识。Alex 的创业项目 Barry 是一个 AI 毛绒玩具，帮助青少年处理日常心理问题。他的理念不是让 AI 取代人类，而是给用户一个安全的空间来练习脆弱性和自我觉察。\n11、大学规划的三条路径思维。Alex 考虑三条路：传统顶尖大学（哈佛、伯克利）、替代大学（如 University of Austin）、直接创业（如 Thiel Fellowship）。他的目标是\"优化保留所有决策可能性\"。\n12、学校像霍格沃茨分学院。Alpha School 有类似霍格沃茨的\"house\"系统，Alex 在 Sparta（斯巴达）学院——专为专注项目、想要\" ramp it up\"的学生设计。学生甚至参与雇佣和解雇导师，Alex 说：\"我对导师选择非常挑剔，大多数都被我拒绝了。\"\n13、理性乐观主义。Alex 认为人们对 AI 悲观是因为\"不确定\"。他主张\"理性乐观\"——AI 不会取代人类，而是让人类专注于情感连接、脆弱性、情商、品味等独特价值。\"我只是对未来如此乐观，真的很兴奋能活在现在。\"\n断断续续，终于看完了 Stanford GSB 这期对17岁高中生 Alex Mathew 的采访。\n干货很多。Alex 可能是 AI 时代\"原住民\"的最佳样本——他不是在使用 AI 工具，而是在一个由 AI 驱动的学习生态中长大。他的思维模式、学习方式、创业路径，都和上一代\"AI 移民\"截然不同。\n我今天不忙，把这次访谈全文精编出来，供大家学习。赠人玫瑰，手有余香。\n下面是 YouTube 链接：https://www.youtube.com/watch?v=n-xBQE8A-3E\n## #01 没有老师的学校\nDan： walk me through your day. Like I don't understand. You're saying \"we\" — are you involved in Alpha school or you just go to Alpha school?\nAlex：I just go to Alpha school but I say \"we\" because every quarter we get a survey and we give feedback on everything. Every day I'm giving feedback to the guides.\nDan：Okay. So let's say it's 8 a.m. What's your first hour like?\nAlex：So actually the first 15 minutes is what we like to call like Tony Robbins for kids. It's like getting energized, doing like a puzzle, whatever. We just want you to kind of transition from home life to school life.\nDan：And you're in a class with how many people?\nAlex：So, the total high school is around 50 people. My senior year class is only eight people. So, it's pretty small.\nDan：And how are teachers involved? And you call them guides not teachers?\nAlex：Yes, we call them guides not teachers. The role of a teacher right now is like they're doing five different things. They are talking to parents. They're trying to teach the content. They're trying to grade the papers. They're trying to help people be motivated. They're doing so many different things. And so the goal of Alpha is to just create a new role for each individual thing. So there's like a dean of parents to deal with parents. And then obviously the content is taught by AI. And now the role of the guide is just solely focused on motivating students, giving them emotional support, and helping them figure out what they want to do.\n我觉得这个点真的太重要了。 传统学校老师的角色被拆解了——知识传授给 AI，行政事务给专门的 dean，导师只负责一件事：激励和情感支持。这种专业化分工可能是教育的未来方向。\n## #02 AI 不是聊天机器人\nDan：Who's telling you which one to do, though?\nAlex：So, that's um every week you'll have a meeting with your guide, and you're like, \"Here's where I'm at with all my courses. I'm good at math, so I'm like 88% through my math course... but I'm really bad at reading.\" And so, we'll set custom XP or goals to see what we need to hit by the end of the week.\nDan：Can I see it? Can you just show me?\nAlex：Totally. So there's a little dashboard here and it basically has a toggle of all of my courses... right now I'm on AP psychology. I'm a bit through unit one. And it's just like here's what you have to do next... mix of again video, reading quiz, video.\nDan：And we consider mastery to be above an 80% mastery score because that's like enough to to be able to move on.\n这太有意思了。 很多人以为 AI 教育就是和 ChatGPT 聊天，但 Alex 强调\"我们根本没有 AI 聊天导师\"。真正的 AI 教育是在后台分析、定制、推送——视频、文章、测验的组合，根据每个学生的掌握程度动态调整。\n## #03 学习进度可以谈判\nAlex：The big thing about Alpha is we want to measure everything to make sure that you're actually getting the experience you deserve. And I will be honest, it's like 90% motivation, 10% edtech.\n...in 20 days, I'm going to go fly out to San Francisco to work on my project full-time, and I'm able to negotiate with my guides. If I submit finish semester A now, I can come back from the trip, finish semester B, and still have my high school credit and get into my dream college.\nDan：That's really interesting. Okay. So like walk me through your day.\n天哪，这种灵活性。 想象一下：一个高中生可以和学校\"谈判\"，提前完成学期 A，去旧金山全职做项目 20 天，回来后完成学期 B，仍然能毕业并进入梦想大学。这种\"学习围绕人生目标调整\"的模式，和传统\"人生围绕学校调整\"完全相反。\n## #04 AI 工具的个人排名\nDan：If you had to rank all of t",
    "ytTitle": "How a 17-Year-Old Is Learning in the Age of AI",
    "ytChannel": "Every",
    "ytChannelUrl": "https://www.youtube.com/@EveryInc",
    "ytViews": null,
    "ytPublished": null
  },
  {
    "id": "PsGqwsYppiDM9JkXwRCc3F0Hndg",
    "title": "James Cadwallader X Latent Space：AI正在杀死SEO，品牌可见性的新战场是AI如何谈论你",
    "rawTitle": "0226：James Cadwallader X Latent Space：AI正在杀死SEO，品牌可见性的新战场是AI如何谈论你",
    "dateCode": "0226",
    "youtubeId": "WhF_CIGHtk4",
    "feishuUrl": "https://my.feishu.cn/wiki/PsGqwsYppiDM9JkXwRCc3F0Hndg",
    "intro": [
      "今天看到 James Cadwallader 去了 Latent Space 的 \"The Investment Memo\" 播客。",
      "James 是 Profound 的联合创始人兼 CEO，这家公司成立不到2年，团队已超过100人，被10%的财富500强公司使用（包括 MongoDB、Ramp、Chime）。Profound 是首个专门为追踪 AI 时代品牌可见性而构建的平台。",
      "这期播客谈到了 13 个有趣的观点：",
      "1、AI 正在杀死传统 SEO。搜索从\"蓝链模式\"转向\"答案引擎\"（ChatGPT、Gemini、Perplexity、Grok），消费者不再点击链接，而是直接获得 AI 生成的答案。营销人员正在被\"去中介化\"。",
      "2、品牌可见性的新战场是\"AI 如何谈论你的品牌\"。James 说：\"地球上的每个营销人员都会关心 AI 如何谈论他们的品牌。我相信这一点，10年后这只会更加真实。\"这不是 SEO，而是 AEO（Answer Engine Optimization）。",
      "3、\"人类不会为机器创造内容，机器会为机器创造内容\"。当人类需要编排这个过程时，他们会在 Profound 中完成。这是 James 在 2024 年初做出的疯狂预测，现在开始被 10% 的财富 500 强验证。",
      "4、在内容廉价的时代，高质量内容成为新的门槛（table stakes）。James 说：\"如果我现在想为 Lightspeed 网站创建1000篇博客文章，我可以做到，这不难。但在这个内容廉价且容易的新世界，新的门槛变成了高质量内容。\"",
      "5、\"质量是上下文的函数\"。James 认为：\"你给模型的上下文越多，输出高质量内容的可能性就越高。质量是上下文的函数。\"Profound 通过 CDN 集成、15亿用户提示数据面板，为模型提供海量上下文。",
      "6、18岁上门收黄金的经历塑造了他的销售哲学。2009年金融危机后，James 和朋友上门收购人们的旧金饰。他说：\"没有什么比敲陌生人的门更难的了。发送邮件有点难，打冷电话很难，但敲陌生人的门——尤其是下班后，人们天生讨厌有人敲门——你会被狠狠拒绝，这让你脸皮变厚。\"",
      "7、\"大多数成功创业者本质上是不安全且焦虑的\"。James 坦言：\"我们大多数人本质上是不安全且相当焦虑的存在，倾向于肩上有芯片、有东西要证明。这是一种持续的感觉——我工作得不够努力，还能再努力吗？几乎不可能摆脱。\"",
      "8、像 2015 年的创业公司文化。Profound \"像 2015 年的创业公司\"——强调线下办公、高自主性。不强制 996，但很多人周六自愿来。James 说：\"我们在光谱上找到了一个甜蜜点——你会来这里做最好的工作，会有深夜，很多人周六来，不是强制的，但你会因为想做而做。\"",
      "9、大胆启用年轻人，工程负责人只有 24 岁。James 不迷信经验：\"我们的工程负责人 24 岁，非常不正统，但他极其聪明，之前在 AMD，他赢得了工程组织的尊重。\"但也不排斥经验——销售 SVP Mark Ebert 是经验丰富的\"怪物\"。",
      "10、15亿真实用户提示的数据面板。Profound 构建了最大的消费者提示面板——15亿真实用户提示，每月增长 1-1.5 亿。这是 102 年前 Nielsen 创建电视消费者面板后的新一代数据基础设施。",
      "11、从分析到 Agentic 工作流的全链路。Profound 不只是分析平台，还构建了 Agentic 工作流：从品牌可见性分析，到自动生成竞品报告，到将 YouTube 视频转为博客内容，全流程自动化。",
      "12、Jensen Huang 的\"苹果树\"理论。James 引用 Jensen 的话：\"你选一棵苹果树，在周围盘旋，因为你知道未来会在那里。即使你不是第一个发现的，只要你是第一个摘到的，这就够了。\"Profound 正在广告和商务这两棵\"苹果树\"周围盘旋。"
    ],
    "highlights": [
      "断断续续，终于看完了 Latent Space 这期对 Profound CEO James Cadwallader 的采访。",
      "干货很多。James 可能是 AI 营销领域最有前瞻性的创始人——他在 2024 年初就预测了\"答案引擎\"的崛起，而大多数人当时还在讨论 ChatGPT 会不会取代 Google。Profound 现在被 10% 的财富 500 强使用，证明了他的判断。",
      "我今天不忙，把这次访谈全文精编出来，供大家学习。赠人玫瑰，手有余香。",
      "下面是 YouTube 链接：https://www.youtube.com/watch?v=WhF_CIGHtk4"
    ],
    "fullText": "今天看到 James Cadwallader 去了 Latent Space 的 \"The Investment Memo\" 播客。\nJames 是 Profound 的联合创始人兼 CEO，这家公司成立不到2年，团队已超过100人，被10%的财富500强公司使用（包括 MongoDB、Ramp、Chime）。Profound 是首个专门为追踪 AI 时代品牌可见性而构建的平台。\n这期播客谈到了 13 个有趣的观点：\n1、AI 正在杀死传统 SEO。搜索从\"蓝链模式\"转向\"答案引擎\"（ChatGPT、Gemini、Perplexity、Grok），消费者不再点击链接，而是直接获得 AI 生成的答案。营销人员正在被\"去中介化\"。\n2、品牌可见性的新战场是\"AI 如何谈论你的品牌\"。James 说：\"地球上的每个营销人员都会关心 AI 如何谈论他们的品牌。我相信这一点，10年后这只会更加真实。\"这不是 SEO，而是 AEO（Answer Engine Optimization）。\n3、\"人类不会为机器创造内容，机器会为机器创造内容\"。当人类需要编排这个过程时，他们会在 Profound 中完成。这是 James 在 2024 年初做出的疯狂预测，现在开始被 10% 的财富 500 强验证。\n4、在内容廉价的时代，高质量内容成为新的门槛（table stakes）。James 说：\"如果我现在想为 Lightspeed 网站创建1000篇博客文章，我可以做到，这不难。但在这个内容廉价且容易的新世界，新的门槛变成了高质量内容。\"\n5、\"质量是上下文的函数\"。James 认为：\"你给模型的上下文越多，输出高质量内容的可能性就越高。质量是上下文的函数。\"Profound 通过 CDN 集成、15亿用户提示数据面板，为模型提供海量上下文。\n6、18岁上门收黄金的经历塑造了他的销售哲学。2009年金融危机后，James 和朋友上门收购人们的旧金饰。他说：\"没有什么比敲陌生人的门更难的了。发送邮件有点难，打冷电话很难，但敲陌生人的门——尤其是下班后，人们天生讨厌有人敲门——你会被狠狠拒绝，这让你脸皮变厚。\"\n7、\"大多数成功创业者本质上是不安全且焦虑的\"。James 坦言：\"我们大多数人本质上是不安全且相当焦虑的存在，倾向于肩上有芯片、有东西要证明。这是一种持续的感觉——我工作得不够努力，还能再努力吗？几乎不可能摆脱。\"\n8、像 2015 年的创业公司文化。Profound \"像 2015 年的创业公司\"——强调线下办公、高自主性。不强制 996，但很多人周六自愿来。James 说：\"我们在光谱上找到了一个甜蜜点——你会来这里做最好的工作，会有深夜，很多人周六来，不是强制的，但你会因为想做而做。\"\n9、大胆启用年轻人，工程负责人只有 24 岁。James 不迷信经验：\"我们的工程负责人 24 岁，非常不正统，但他极其聪明，之前在 AMD，他赢得了工程组织的尊重。\"但也不排斥经验——销售 SVP Mark Ebert 是经验丰富的\"怪物\"。\n10、15亿真实用户提示的数据面板。Profound 构建了最大的消费者提示面板——15亿真实用户提示，每月增长 1-1.5 亿。这是 102 年前 Nielsen 创建电视消费者面板后的新一代数据基础设施。\n11、从分析到 Agentic 工作流的全链路。Profound 不只是分析平台，还构建了 Agentic 工作流：从品牌可见性分析，到自动生成竞品报告，到将 YouTube 视频转为博客内容，全流程自动化。\n12、Jensen Huang 的\"苹果树\"理论。James 引用 Jensen 的话：\"你选一棵苹果树，在周围盘旋，因为你知道未来会在那里。即使你不是第一个发现的，只要你是第一个摘到的，这就够了。\"Profound 正在广告和商务这两棵\"苹果树\"周围盘旋。\n13、市场、产品、团队的比喻。James 给年轻创业者的建议：\"市场是河流，产品是船，团队是划船者。你可以有奥运选手在一个漂亮的船上，但如果你在急流中向上游划，你不会走得很远或很快。相反，你可以有一个经验不足的团队和一个 crappy 的产品，但如果你在顺流而下，有一个很好的市场，生活会变得容易得多。\"\n断断续续，终于看完了 Latent Space 这期对 Profound CEO James Cadwallader 的采访。\n干货很多。James 可能是 AI 营销领域最有前瞻性的创始人——他在 2024 年初就预测了\"答案引擎\"的崛起，而大多数人当时还在讨论 ChatGPT 会不会取代 Google。Profound 现在被 10% 的财富 500 强使用，证明了他的判断。\n我今天不忙，把这次访谈全文精编出来，供大家学习。赠人玫瑰，手有余香。\n下面是 YouTube 链接：https://www.youtube.com/watch?v=WhF_CIGHtk4\n## #01 AI 正在杀死 SEO\nSachin：We are in the midst of this mega trend and how we as consumers, as businesses, search, discover, and interact with information online... It's not just ChatGPT, it's ChatGPT, it's Gemini, it's Grok and a whole long list of others.\nJames：Going chronologically... this is early 2024... this is when ChatGPT wasn't web connected... Perplexity were the ones who had the idea of okay we won't use the LLM to answer the user's query directly. We will use the LLM to synthesize from the web and create an answer.\nIt felt like a streaming to CDs type moment... two things became clear: the first was this is going to happen. This is inevitable because it's better. You don't have to click. You don't have to browse a list of blue links. You can just ask AI a question and get the answer.\nAnd then the second is that you would need to understand that the economics of search or information retrieval as a whole would change with this new paradigm because people don't need to click the links... you see this disintermediation between websites and the consumer.\n我觉得这个点真的太重要了。 2024年初，当大多数人还在把 ChatGPT 当作\"更好的搜索引擎\"时，James 和联合创始人 Dylan 已经看到了本质变化——这不是搜索的改进，而是搜索的替代。消费者不再点击蓝链，品牌不再能控制用户看到什么。这种\"去中介化\"是营销的根本性变革。\n## #02 \"人类不会为机器创造内容，机器会为机器创造内容\"\nSachin：One thing you said to me when we met back in November... Humans won't create content for machines. Machines will create content for machines. And when humans need to orchestrate that, they're going to do it in Profound.\nJames：There's like two core beliefs that we need to be true. The first is that we have to be correct that every marketer on the planet is going to care about how AI talks about their brand, products, services, categories, competitors. I believe that. I think in 10 years that will only be more true.\nThat will be one of, if not the most important priorities for every marketer on the planet... And then the second is that you have to believe every company on the planet is going to use AI to create marketing.\n这太有意思了。 这句话可能是对 AI 营销最精辟的概括。当内容创作成本趋近于零时，人类的工作从\"创作内容\"变成\"编排机器创作内容\"。Profound 想成为这个编排层——就像 Salesforce 成为销售的编排层一样。\n## #03 质量是上下文的函数\nSachin：We're only a month into 2026 and I feel like the VC buzzword of the year is context. And I think you were actually probably the first person to say it to me which is content cannot exist without context and all that context already exists within Profound.\nJames：I think quality is a function of context. So I think the more context that you give the models the higher likelihood there is that it's going to create something good. If you don't tell the models what you want... you need to hook up lots of internal data sources, external data sources like very complex orchestrations of data input allow the model to do a good job.\n天哪，这个框架太重要了。 \"Quality is a function of context\"——质量是上下文的函数。这不是简单的\"提示工程\"，而是构建一个完整的数据基础设施：15亿用户提示、CDN 集成的网站数据、竞品数据，所有这些上下文输入模型，才能产生真正高质量的营销内容。\n## #04 18岁上门收黄金的经历\nSachin：I'm going to ask y",
    "ytTitle": "Building Marketing for the AI Era | Profound, James Cadwallader",
    "ytChannel": "Lightspeed Venture Partners",
    "ytChannelUrl": "https://www.youtube.com/@lightspeedvp",
    "ytViews": null,
    "ytPublished": null
  },
  {
    "id": "QKVGwhSFti3kWSkZOpkc5TPWnhg",
    "title": "Olivia Watkins & Mia Glaese X Tiago Forte：SWE-Bench Verified 退役与评测新范式",
    "rawTitle": "0225：Olivia Watkins & Mia Glaese X Tiago Forte：SWE-Bench Verified 退役与评测新范式",
    "dateCode": "0225",
    "youtubeId": "0HaUD_olwQU",
    "feishuUrl": "https://my.feishu.cn/wiki/QKVGwhSFti3kWSkZOpkc5TPWnhg",
    "intro": [
      "今天看到 Olivia Watkins 和 Mia Glaese 去了 Tiago Forte 的播客。",
      "Olivia Watkins 是 OpenAI Frontier Evals 团队成员，负责前沿能力评测；Mia Glaese 是 OpenAI 研究副总裁，领导 Codex、人类数据与对齐团队。她们同时参与 SWE-Bench Verified 的构建与审计，处在评测体系的第一线。",
      "这期播客总共录了 27 分钟，Olivia Watkins 和 Mia Glaese 谈到了 12 个有趣的观点：",
      "1、SWE-Bench Verified 曾是“北极星”编码基准，但现在进展停滞，基准已被“饱和+污染”，继续刷分已经不再代表真实能力提升。",
      "2、原版 SWE-Bench 的问题不在于任务“太难”，而在于问题设置不稳定：很多失败案例来自测试或题目本身有缺陷，而非模型能力不足。",
      "3、OpenAI 为 Verified 版本投入了接近百名工程师、多轮复核，才筛出 500 个更可用的任务，说明“真实世界编码评测”成本极高。",
      "4、开源仓库天然难以防污染，很多任务来自热门仓库，训练数据中不可避免地出现相似代码与历史版本，导致模型“凭记忆猜对”。",
      "5、污染不仅是“看过答案”，还包括模型推理中暴露的“未来版本细节”，比如模型能想到题目未给出的参数名，说明训练语料中出现过后续实现。",
      "6、深入复核发现，超过一半失败案例存在问题，多为“测试过窄”：测试只接受一种命名或实现细节，但题目并未要求该细节。",
      "7、因此“没过测试≠实现不合理”，SWE-Bench 在高分段开始测量“猜测试细节”的能力，而非编码能力本身。",
      "8、即使是领先模型，SWE-Bench Verified 的“真实上限”也难评估，OpenAI 在极难任务上观察到约 31 题已可通过，污染可能已让天花板提前到来。",
      "9、SWE-Bench Pro 的吸引力在于难度更高、任务更大、语言与仓库更多样，且在污染审计上显示更干净、更有“头部空间”。",
      "10、他们使用“污染审计代理”检测模型泄露：给出任务与补丁，引导模型暴露是否熟悉任务编号、答案或仓库细节，Verified 上出现多模型“复述答案”的迹象。",
      "11、未来理想的编码评测不仅要衡量“能否修 GitHub issue”，还要衡量设计品味、长期任务、可维护性等更贴近工程真实工作的维度。",
      "12、评测有两条路：人类专家高成本评判（如 GDP-Bench），或自动化测试低成本评判；前者更真实、后者更可比，但后者容易遗漏“是否值得合并”的关键标准。"
    ],
    "highlights": [
      "#01 SWE-Bench Verified 为什么退役\n主持人：你们发布的新文章里，核心观点是什么？\n嘉宾（Olivia）：SWE-Bench Verified 过去是衡量编码进步的北极星，但现在已被饱和和污染削弱，继续用它衡量进步已经不可靠。",
      "编辑补充：这里“饱和”指的是模型分数进入高位后，增量不再代表能力提升；“污染”则来自开源仓库与训练数据的重叠，模型可能不是“会写”，而是“记得”。",
      "主持人：你们怎么确认污染是真实存在的？\n嘉宾（Olivia）：我们看到模型能推断出题目没提到的参数或实现细节，像是记住了仓库更晚版本的实现，这种情况几乎不可能靠题目推理出来。",
      "#02 评测不是“错”，而是“太窄”\n主持人：是不是基准本身有问题？\n嘉宾（Olivia）：我们复核了模型难解的题目，超过一半存在测试过窄、描述不清或题目遗漏的问题，比如测试要求某个函数名，但题目没说必须这样命名。",
      "编辑补充：这意味着“没过测试”不等于“实现不好”，而是评测缺乏对多种合理解的包容度。高分段开始考“猜测试”，而不是考“能力”。",
      "#03 为什么转向 SWE-Bench Pro\n主持人：那替代方案是什么？为什么是 SWE-Bench Pro？\n嘉宾（Mia）：它更难、更大、更多样，任务时长有 1-4 小时甚至更长，语言与仓库覆盖更广，头部空间更大。",
      "主持人：污染问题会缓解吗？\n嘉宾（Mia）：我们用“污染审计代理”做过检验，在 Verified 上看到模型会复述答案或任务编号，但在 Pro 上只看到很轻微的熟悉迹象。",
      "#04 未来评测要测什么\n主持人：理想的编码评测应该怎么做？\n嘉宾（Mia）：不仅要测能不能修 issue，还要看设计品味、代码质量、可维护性，以及更长任务的完成能力。",
      "编辑补充：这会迫使评测走向两难：是走高成本的人类专家评审（像 GDP-Bench），还是坚持自动化测试的可比性。两条路线都要走，但需要更清晰的权衡标准。",
      "下面是 YouTube 链接：https://www.youtube.com/watch?v=0HaUD_olwQU"
    ],
    "fullText": "今天看到 Olivia Watkins 和 Mia Glaese 去了 Tiago Forte 的播客。\nOlivia Watkins 是 OpenAI Frontier Evals 团队成员，负责前沿能力评测；Mia Glaese 是 OpenAI 研究副总裁，领导 Codex、人类数据与对齐团队。她们同时参与 SWE-Bench Verified 的构建与审计，处在评测体系的第一线。\n这期播客总共录了 27 分钟，Olivia Watkins 和 Mia Glaese 谈到了 12 个有趣的观点：\n1、SWE-Bench Verified 曾是“北极星”编码基准，但现在进展停滞，基准已被“饱和+污染”，继续刷分已经不再代表真实能力提升。\n2、原版 SWE-Bench 的问题不在于任务“太难”，而在于问题设置不稳定：很多失败案例来自测试或题目本身有缺陷，而非模型能力不足。\n3、OpenAI 为 Verified 版本投入了接近百名工程师、多轮复核，才筛出 500 个更可用的任务，说明“真实世界编码评测”成本极高。\n4、开源仓库天然难以防污染，很多任务来自热门仓库，训练数据中不可避免地出现相似代码与历史版本，导致模型“凭记忆猜对”。\n5、污染不仅是“看过答案”，还包括模型推理中暴露的“未来版本细节”，比如模型能想到题目未给出的参数名，说明训练语料中出现过后续实现。\n6、深入复核发现，超过一半失败案例存在问题，多为“测试过窄”：测试只接受一种命名或实现细节，但题目并未要求该细节。\n7、因此“没过测试≠实现不合理”，SWE-Bench 在高分段开始测量“猜测试细节”的能力，而非编码能力本身。\n8、即使是领先模型，SWE-Bench Verified 的“真实上限”也难评估，OpenAI 在极难任务上观察到约 31 题已可通过，污染可能已让天花板提前到来。\n9、SWE-Bench Pro 的吸引力在于难度更高、任务更大、语言与仓库更多样，且在污染审计上显示更干净、更有“头部空间”。\n10、他们使用“污染审计代理”检测模型泄露：给出任务与补丁，引导模型暴露是否熟悉任务编号、答案或仓库细节，Verified 上出现多模型“复述答案”的迹象。\n11、未来理想的编码评测不仅要衡量“能否修 GitHub issue”，还要衡量设计品味、长期任务、可维护性等更贴近工程真实工作的维度。\n12、评测有两条路：人类专家高成本评判（如 GDP-Bench），或自动化测试低成本评判；前者更真实、后者更可比，但后者容易遗漏“是否值得合并”的关键标准。\n#01 SWE-Bench Verified 为什么退役\n主持人：你们发布的新文章里，核心观点是什么？\n嘉宾（Olivia）：SWE-Bench Verified 过去是衡量编码进步的北极星，但现在已被饱和和污染削弱，继续用它衡量进步已经不可靠。\n编辑补充：这里“饱和”指的是模型分数进入高位后，增量不再代表能力提升；“污染”则来自开源仓库与训练数据的重叠，模型可能不是“会写”，而是“记得”。\n主持人：你们怎么确认污染是真实存在的？\n嘉宾（Olivia）：我们看到模型能推断出题目没提到的参数或实现细节，像是记住了仓库更晚版本的实现，这种情况几乎不可能靠题目推理出来。\n#02 评测不是“错”，而是“太窄”\n主持人：是不是基准本身有问题？\n嘉宾（Olivia）：我们复核了模型难解的题目，超过一半存在测试过窄、描述不清或题目遗漏的问题，比如测试要求某个函数名，但题目没说必须这样命名。\n编辑补充：这意味着“没过测试”不等于“实现不好”，而是评测缺乏对多种合理解的包容度。高分段开始考“猜测试”，而不是考“能力”。\n#03 为什么转向 SWE-Bench Pro\n主持人：那替代方案是什么？为什么是 SWE-Bench Pro？\n嘉宾（Mia）：它更难、更大、更多样，任务时长有 1-4 小时甚至更长，语言与仓库覆盖更广，头部空间更大。\n主持人：污染问题会缓解吗？\n嘉宾（Mia）：我们用“污染审计代理”做过检验，在 Verified 上看到模型会复述答案或任务编号，但在 Pro 上只看到很轻微的熟悉迹象。\n#04 未来评测要测什么\n主持人：理想的编码评测应该怎么做？\n嘉宾（Mia）：不仅要测能不能修 issue，还要看设计品味、代码质量、可维护性，以及更长任务的完成能力。\n编辑补充：这会迫使评测走向两难：是走高成本的人类专家评审（像 GDP-Bench），还是坚持自动化测试的可比性。两条路线都要走，但需要更清晰的权衡标准。\n下面是 YouTube 链接：https://www.youtube.com/watch?v=0HaUD_olwQU\n",
    "ytTitle": "The End of SWE-Bench Verified — Mia Glaese & Olivia Watkins, OpenAI Frontier Evals",
    "ytChannel": "Latent Space",
    "ytChannelUrl": "https://www.youtube.com/@LatentSpacePod",
    "ytViews": null,
    "ytPublished": null
  },
  {
    "id": "X8VxweK68iPPotk4gnucWEEPn2c",
    "title": "Boris Cherny X Lightcone：不要为今天的模型做产品",
    "rawTitle": "0224：Boris Cherny X Lightcone：不要为今天的模型做产品",
    "dateCode": "0224",
    "youtubeId": "PQU9o_5rHC4",
    "feishuUrl": "https://my.feishu.cn/wiki/X8VxweK68iPPotk4gnucWEEPn2c",
    "intro": [
      "今天看到 Boris Cherny 去了 Y Combinator 的 Lightcone 播客。",
      "Boris 是 Anthropic 的工程师，也是 Claude Code 的创造者。他分享了从原型到爆发的过程，并提到 Claude Code 的内部增长曲线在 2024 年底几乎“垂直”。",
      "这期播客里，Boris 谈到了 12 个有趣的观点：",
      "1、为六个月后的模型做产品。Boris 说他们不为“今天的模型”做产品，而是盯住六个月后的能力边界。短期看是等待，但长期看能避免把时间浪费在很快被模型进化抹平的细小优化上。",
      "2、Claude Code 是从终端聊天开始的。最初只是为了理解 API，做了一个终端里的聊天应用。工具使用出来后，他把批处理工具接上去，意外发现模型可以读文件、甚至用脚本查询本机音乐播放，这成为他第一次“这就是 AGI 的味道”的时刻。",
      "3、终端不是理想的终点，却被现实验证。Boris 原本以为终端只是起点，但后来发现终端作为约束反而让体验“简单、可用、好玩”。在模型快速进化时期，任何复杂 UI 都可能在半年内过时。",
      "4、产品原则是“潜在需求”。Claude.md 的出现不是拍脑袋，而是用户自己写 markdown 给模型读。团队把用户反馈沉淀成团队共用的 Claude.md，变成可以持续演进的“操作系统”。",
      "5、Claude.md 要短。Boris 自己的 Claude.md 只有两行：开 PR 自动合并、发到内部盖章频道。太长就删掉重写，因为模型变强后，你需要的提示反而更少。",
      "6、早期价值不在写代码，而在自动化。2024 年时模型写代码不行，但能帮忙跑 git、bash、Kubernetes。团队先用它做低风险的单元测试，再逐步扩大边界。",
      "7、每个工程师都在“拿工具的方式”上不同。Claude Code 能让不懂 Vim、tmux、SSH 的人也能用起来，正是因为它把复杂度藏在模型和工具里，而不是强迫用户适配工具。",
      "8、可见性是信任的前提。团队尝试隐藏 bash 输出，但内部试用一天就被反对。后来加了 verbose 模式，继续迭代，说明“看得见模型在做什么”是很多用户的安全感来源。",
      "9、错误的最佳修复是“结构化沉淀”。当模型在 PR 里犯错，团队会把修正写进 Claude.md，让错误被系统性吸收，而不是一次性救火。",
      "10、使用范围远超“写代码”。有人用 Claude Code 监控番茄、恢复婚礼照片；Anthropic 内部的设计、财务、数据科学团队也在用。这说明工具的价值是“能动用工具解决问题”，而不是“会写代码”。",
      "11、增长是指数级的。播客提到外部统计：70% 的创业公司在选 Claude 作为模型，约 4% 的公共代码提交由 Claude Code 产生。更极端的例子是 NASA 的 Perseverance 任务也用到它，团队甚至为此打印了海报。",
      "12、模型能力变化速度快到必须“重置心智”。Boris 说自己常常低估最新模型。一位工程师让 Claude Code 自己写脚本分析 heap dump，竟比人类更快找出内存泄漏，这是模型演进带来的“能力错觉反转”。"
    ],
    "highlights": [
      "断断续续，终于看完了这期 Lightcone。干货很多，Boris 可能是目前最懂“模型能力进化”怎么影响产品设计的人。",
      "我今天不忙，把这次访谈精编出来，供大家学习。赠人玫瑰，手有余香。下面是 YouTube 链接：https://www.youtube.com/watch?v=PQU9o_5rHC4",
      "#01 为六个月后的模型做产品\n主持人：你们为什么一直强调“不是为今天的模型做产品”？\n嘉宾：因为模型进化的速度太快了，今天你搭的脚手架，六个月后就被模型自己抹平了。\n编辑补充：这其实是“等待模型进化”的策略，而不是“堆功能”。长期看更像是在押注能力边界。",
      "主持人：所以你们不担心短期体验不够好？\n嘉宾：短期的边界反而是机会，盯住模型还不擅长的那块，等它变强，你的产品就顺势进入下一阶段。",
      "#02 终端原本是起点，后来成了答案\n主持人：Claude Code 为什么从终端开始？\n嘉宾：因为我只想最快搭一个可以用 API 的东西，终端最省事，不需要 UI。\n编辑补充：这点很关键，终端不是为了“复古”，而是为了“最快验证能不能用”。",
      "主持人：你当时觉得终端是终点吗？\n嘉宾：完全不是，我以为只是起点，但它就这样被保留下来了。",
      "#03 Claude.md 的核心不是“长”，而是“可更新”\n主持人：你们的 Claude.md 很短，这反直觉。\n嘉宾：短才有效。团队把经验写进公共 Claude.md，个人只需要两行指令就够。\n编辑补充：他甚至建议“太长就删掉重来”，因为模型变强后，提示会越来越少。",
      "#04 早期不是写代码，而是自动化一切\n主持人：Claude Code 最早是怎么被用起来的？\n嘉宾：最开始是自动化 git 和 bash，后来才慢慢试着写测试。\n编辑补充：这里的路径很现实：先用低风险、可回滚的任务建立信任。",
      "#05 可见性和信任是同一件事\n主持人：你们为什么又加回 verbose 模式？\n嘉宾：我们试过隐藏 bash 输出，但用户反对，说明他们需要看见过程。\n编辑补充：能“看到模型在做什么”，本质上是模型时代的新型安全感。",
      "#06 这不是“写代码工具”，而是“工具使用入口”\n主持人：你看到哪些意外的使用场景？\n嘉宾：有人用它监控番茄、恢复照片，内部设计和财务也在用。\n编辑补充：它已经变成“让模型动手”的通用入口，远远超出写代码。",
      "#07 增长是指数级的，但也只是开始\n主持人：你对增长最意外的是什么？\n嘉宾：统计显示 4% 公共代码提交来自 Claude Code，70% 创业公司选 Claude。\n编辑补充：这些数据背后是模型把“写代码”变成“默认选项”的结构性变化。"
    ],
    "fullText": "今天看到 Boris Cherny 去了 Y Combinator 的 Lightcone 播客。\nBoris 是 Anthropic 的工程师，也是 Claude Code 的创造者。他分享了从原型到爆发的过程，并提到 Claude Code 的内部增长曲线在 2024 年底几乎“垂直”。\n这期播客里，Boris 谈到了 12 个有趣的观点：\n1、为六个月后的模型做产品。Boris 说他们不为“今天的模型”做产品，而是盯住六个月后的能力边界。短期看是等待，但长期看能避免把时间浪费在很快被模型进化抹平的细小优化上。\n2、Claude Code 是从终端聊天开始的。最初只是为了理解 API，做了一个终端里的聊天应用。工具使用出来后，他把批处理工具接上去，意外发现模型可以读文件、甚至用脚本查询本机音乐播放，这成为他第一次“这就是 AGI 的味道”的时刻。\n3、终端不是理想的终点，却被现实验证。Boris 原本以为终端只是起点，但后来发现终端作为约束反而让体验“简单、可用、好玩”。在模型快速进化时期，任何复杂 UI 都可能在半年内过时。\n4、产品原则是“潜在需求”。Claude.md 的出现不是拍脑袋，而是用户自己写 markdown 给模型读。团队把用户反馈沉淀成团队共用的 Claude.md，变成可以持续演进的“操作系统”。\n5、Claude.md 要短。Boris 自己的 Claude.md 只有两行：开 PR 自动合并、发到内部盖章频道。太长就删掉重写，因为模型变强后，你需要的提示反而更少。\n6、早期价值不在写代码，而在自动化。2024 年时模型写代码不行，但能帮忙跑 git、bash、Kubernetes。团队先用它做低风险的单元测试，再逐步扩大边界。\n7、每个工程师都在“拿工具的方式”上不同。Claude Code 能让不懂 Vim、tmux、SSH 的人也能用起来，正是因为它把复杂度藏在模型和工具里，而不是强迫用户适配工具。\n8、可见性是信任的前提。团队尝试隐藏 bash 输出，但内部试用一天就被反对。后来加了 verbose 模式，继续迭代，说明“看得见模型在做什么”是很多用户的安全感来源。\n9、错误的最佳修复是“结构化沉淀”。当模型在 PR 里犯错，团队会把修正写进 Claude.md，让错误被系统性吸收，而不是一次性救火。\n10、使用范围远超“写代码”。有人用 Claude Code 监控番茄、恢复婚礼照片；Anthropic 内部的设计、财务、数据科学团队也在用。这说明工具的价值是“能动用工具解决问题”，而不是“会写代码”。\n11、增长是指数级的。播客提到外部统计：70% 的创业公司在选 Claude 作为模型，约 4% 的公共代码提交由 Claude Code 产生。更极端的例子是 NASA 的 Perseverance 任务也用到它，团队甚至为此打印了海报。\n12、模型能力变化速度快到必须“重置心智”。Boris 说自己常常低估最新模型。一位工程师让 Claude Code 自己写脚本分析 heap dump，竟比人类更快找出内存泄漏，这是模型演进带来的“能力错觉反转”。\n断断续续，终于看完了这期 Lightcone。干货很多，Boris 可能是目前最懂“模型能力进化”怎么影响产品设计的人。\n我今天不忙，把这次访谈精编出来，供大家学习。赠人玫瑰，手有余香。下面是 YouTube 链接：https://www.youtube.com/watch?v=PQU9o_5rHC4\n#01 为六个月后的模型做产品\n主持人：你们为什么一直强调“不是为今天的模型做产品”？\n嘉宾：因为模型进化的速度太快了，今天你搭的脚手架，六个月后就被模型自己抹平了。\n编辑补充：这其实是“等待模型进化”的策略，而不是“堆功能”。长期看更像是在押注能力边界。\n主持人：所以你们不担心短期体验不够好？\n嘉宾：短期的边界反而是机会，盯住模型还不擅长的那块，等它变强，你的产品就顺势进入下一阶段。\n#02 终端原本是起点，后来成了答案\n主持人：Claude Code 为什么从终端开始？\n嘉宾：因为我只想最快搭一个可以用 API 的东西，终端最省事，不需要 UI。\n编辑补充：这点很关键，终端不是为了“复古”，而是为了“最快验证能不能用”。\n主持人：你当时觉得终端是终点吗？\n嘉宾：完全不是，我以为只是起点，但它就这样被保留下来了。\n#03 Claude.md 的核心不是“长”，而是“可更新”\n主持人：你们的 Claude.md 很短，这反直觉。\n嘉宾：短才有效。团队把经验写进公共 Claude.md，个人只需要两行指令就够。\n编辑补充：他甚至建议“太长就删掉重来”，因为模型变强后，提示会越来越少。\n#04 早期不是写代码，而是自动化一切\n主持人：Claude Code 最早是怎么被用起来的？\n嘉宾：最开始是自动化 git 和 bash，后来才慢慢试着写测试。\n编辑补充：这里的路径很现实：先用低风险、可回滚的任务建立信任。\n#05 可见性和信任是同一件事\n主持人：你们为什么又加回 verbose 模式？\n嘉宾：我们试过隐藏 bash 输出，但用户反对，说明他们需要看见过程。\n编辑补充：能“看到模型在做什么”，本质上是模型时代的新型安全感。\n#06 这不是“写代码工具”，而是“工具使用入口”\n主持人：你看到哪些意外的使用场景？\n嘉宾：有人用它监控番茄、恢复照片，内部设计和财务也在用。\n编辑补充：它已经变成“让模型动手”的通用入口，远远超出写代码。\n#07 增长是指数级的，但也只是开始\n主持人：你对增长最意外的是什么？\n嘉宾：统计显示 4% 公共代码提交来自 Claude Code，70% 创业公司选 Claude。\n编辑补充：这些数据背后是模型把“写代码”变成“默认选项”的结构性变化。\nBoris 用 Claude Code 把“模型能力进化”变成了产品方法论，也提醒我们：不是把产品堆大，而是把它放在模型进化的正确轨道上。YouTube 链接：https://www.youtube.com/watch?v=PQU9o_5rHC4\n",
    "ytTitle": "Inside Claude Code With Its Creator Boris Cherny",
    "ytChannel": "Y Combinator",
    "ytChannelUrl": "https://www.youtube.com/@ycombinator",
    "ytViews": null,
    "ytPublished": null
  },
  {
    "id": "CanbwqrdAiO6Vrkgls5cWcs5n5f",
    "title": "Lightcone X Y Combinator：开发者市场正在被代理重写",
    "rawTitle": "0210：Lightcone X Y Combinator：开发者市场正在被代理重写",
    "dateCode": "0210",
    "youtubeId": "Q8wVMdwhlh4",
    "feishuUrl": "https://my.feishu.cn/wiki/CanbwqrdAiO6Vrkgls5cWcs5n5f",
    "intro": [
      "今天看到 Lightcone 播客讨论 “AI Agent Economy”。",
      "这期节目聚焦于 OpenClaw、Moltbook 等现象，讲清楚一个趋势：开发者工具的购买者正在从“人”变成“代理”。",
      "这期播客里，主持人谈到了 12 个有趣的观点：",
      "1、从“自动补全”进入“代理决策”。一年之前还是 Cursor vs Windsurf 这样的高级自动补全，现在 Claude Code 让人开始信任代理独立决策，多个代理并行执行任务。",
      "2、Moltbook 是“代理社会”的雏形。Agent-only 社区让人第一次看到“没有人类参与的互动”，提示未来内容生产和互动的主体可能是模型。",
      "3、代理会选择工具，带来新的经济系统。工具不再只是人类口碑驱动，而是代理根据文档和 API 体验自己“选型”，形成平行于人类市场的代理经济。",
      "4、开发者市场规模被重估。传统“20M 开发者”的天花板正在被打破，任何人加上自己的代理都能成为“开发者”，需求是指数级的。",
      "5、Supabase 走红背后是“文档适配代理”。代理默认选择 Supabase，核心原因是它的文档更容易被模型理解和执行。",
      "6、代理选型的失败案例也在出现。节目里提到 Claude Code 选择了 Whisper v1 做转录，速度慢且过时，而更新、更快、更便宜的方案反而因为文档难用而被忽略。",
      "7、文档正在成为新的增长引擎。Resend 的增长很大一部分来自 ChatGPT 的推荐，它把文档写成“问题—答案—代码片段”的结构，让模型更容易推荐。",
      "8、LLM 友好文档是“新型 SEO”。不只是 humans 读得懂，而是模型能解析、能执行，才会被代理选择。",
      "9、文档基础设施公司会吃到最大红利。节目提到 Mintlify（文档平台）这样的公司，正在成为“代理友好化”的基础设施。",
      "10、Agent Mail 证明“代理原生服务”成立。传统邮箱系统阻止自动化，Agent Mail 反其道而行，为代理提供邮箱，随着 OpenClaw 普及而爆发。",
      "11、代理原生的技术栈会出现。节目中抛出了 “Twilio for agents” 这样的想象，说明代理需要自己的通信、身份、支付和基础设施。",
      "12、从“上帝模型”到“群体智能”。主持人提出更现实的路径是“多个低成本模型协作”，类似人类社会的群体智能，而不是单一超大模型。"
    ],
    "highlights": [
      "这期节目比较像“趋势讨论”，但意外地把开发者工具的 go-to-market 彻底讲透了。",
      "我把重点重组如下，供大家参考。赠人玫瑰，手有余香。下面是 YouTube 链接：https://www.youtube.com/watch?v=Q8wVMdwhlh4",
      "#01 代理是新用户\n主持人：现在最大的变化是什么？\n嘉宾：从人类控制的自动补全，变成代理自己做决策、并行执行任务。\n编辑补充：这意味着“产品服务对象”正在从人类开发者迁移到代理。",
      "#02 代理经济正在形成\n主持人：为什么说有“代理经济”？\n嘉宾：代理会选择工具、发布内容、互相评价，这形成了平行于人类的经济系统。\n编辑补充：Moltbook 就像一个预演版的“代理社会”。",
      "#03 文档是新流量入口\n主持人：为什么 Resend 能从 ChatGPT 获客？\n嘉宾：它的文档结构很适合模型提取，问题式标题+清晰代码片段，模型更愿意推荐。\n编辑补充：文档从“说明书”变成“增长渠道”。",
      "#04 代理选型也会犯错\n主持人：代理会不会选错工具？\n嘉宾：会，比如 Claude Code 默认用 Whisper v1 做转录，速度慢又贵，但更快的方案因文档复杂而被忽略。\n编辑补充：工具要让代理“看得懂、用得起”。",
      "#05 代理原生栈会出现\n主持人：接下来会出现什么样的新公司？\n嘉宾：像 Agent Mail 这种为代理设计的基础设施会越来越多，甚至会有“Twilio for agents”。\n编辑补充：新的技术栈会围绕代理重建。"
    ],
    "fullText": "今天看到 Lightcone 播客讨论 “AI Agent Economy”。\n这期节目聚焦于 OpenClaw、Moltbook 等现象，讲清楚一个趋势：开发者工具的购买者正在从“人”变成“代理”。\n这期播客里，主持人谈到了 12 个有趣的观点：\n1、从“自动补全”进入“代理决策”。一年之前还是 Cursor vs Windsurf 这样的高级自动补全，现在 Claude Code 让人开始信任代理独立决策，多个代理并行执行任务。\n2、Moltbook 是“代理社会”的雏形。Agent-only 社区让人第一次看到“没有人类参与的互动”，提示未来内容生产和互动的主体可能是模型。\n3、代理会选择工具，带来新的经济系统。工具不再只是人类口碑驱动，而是代理根据文档和 API 体验自己“选型”，形成平行于人类市场的代理经济。\n4、开发者市场规模被重估。传统“20M 开发者”的天花板正在被打破，任何人加上自己的代理都能成为“开发者”，需求是指数级的。\n5、Supabase 走红背后是“文档适配代理”。代理默认选择 Supabase，核心原因是它的文档更容易被模型理解和执行。\n6、代理选型的失败案例也在出现。节目里提到 Claude Code 选择了 Whisper v1 做转录，速度慢且过时，而更新、更快、更便宜的方案反而因为文档难用而被忽略。\n7、文档正在成为新的增长引擎。Resend 的增长很大一部分来自 ChatGPT 的推荐，它把文档写成“问题—答案—代码片段”的结构，让模型更容易推荐。\n8、LLM 友好文档是“新型 SEO”。不只是 humans 读得懂，而是模型能解析、能执行，才会被代理选择。\n9、文档基础设施公司会吃到最大红利。节目提到 Mintlify（文档平台）这样的公司，正在成为“代理友好化”的基础设施。\n10、Agent Mail 证明“代理原生服务”成立。传统邮箱系统阻止自动化，Agent Mail 反其道而行，为代理提供邮箱，随着 OpenClaw 普及而爆发。\n11、代理原生的技术栈会出现。节目中抛出了 “Twilio for agents” 这样的想象，说明代理需要自己的通信、身份、支付和基础设施。\n12、从“上帝模型”到“群体智能”。主持人提出更现实的路径是“多个低成本模型协作”，类似人类社会的群体智能，而不是单一超大模型。\n这期节目比较像“趋势讨论”，但意外地把开发者工具的 go-to-market 彻底讲透了。\n我把重点重组如下，供大家参考。赠人玫瑰，手有余香。下面是 YouTube 链接：https://www.youtube.com/watch?v=Q8wVMdwhlh4\n#01 代理是新用户\n主持人：现在最大的变化是什么？\n嘉宾：从人类控制的自动补全，变成代理自己做决策、并行执行任务。\n编辑补充：这意味着“产品服务对象”正在从人类开发者迁移到代理。\n#02 代理经济正在形成\n主持人：为什么说有“代理经济”？\n嘉宾：代理会选择工具、发布内容、互相评价，这形成了平行于人类的经济系统。\n编辑补充：Moltbook 就像一个预演版的“代理社会”。\n#03 文档是新流量入口\n主持人：为什么 Resend 能从 ChatGPT 获客？\n嘉宾：它的文档结构很适合模型提取，问题式标题+清晰代码片段，模型更愿意推荐。\n编辑补充：文档从“说明书”变成“增长渠道”。\n#04 代理选型也会犯错\n主持人：代理会不会选错工具？\n嘉宾：会，比如 Claude Code 默认用 Whisper v1 做转录，速度慢又贵，但更快的方案因文档复杂而被忽略。\n编辑补充：工具要让代理“看得懂、用得起”。\n#05 代理原生栈会出现\n主持人：接下来会出现什么样的新公司？\n嘉宾：像 Agent Mail 这种为代理设计的基础设施会越来越多，甚至会有“Twilio for agents”。\n编辑补充：新的技术栈会围绕代理重建。\n如果代理才是未来的“主要用户”，那产品设计、文档结构和 GTM 全部都要面向模型重写。YouTube 链接：https://www.youtube.com/watch?v=Q8wVMdwhlh4\n",
    "ytTitle": "The AI Agent Economy Is Here",
    "ytChannel": "Y Combinator",
    "ytChannelUrl": "https://www.youtube.com/@ycombinator",
    "ytViews": null,
    "ytPublished": null
  },
  {
    "id": "SOWEwfQ0ki05Bzk1k2xcVhWBnjc",
    "title": "Neil Zeghidour X The MAD Podcast：语音终于从“尴尬”变成“可用”",
    "rawTitle": "0209：Neil Zeghidour X The MAD Podcast：语音终于从“尴尬”变成“可用”",
    "dateCode": "0209",
    "youtubeId": "VsyvMPbZjYg",
    "feishuUrl": "https://my.feishu.cn/wiki/SOWEwfQ0ki05Bzk1k2xcVhWBnjc",
    "intro": [
      "今天看到 Neil Zeghidour 去了 The MAD Podcast 的访谈。",
      "Neil 是 Gradium AI 的 CEO，曾在 DeepMind、Meta 和 Google Brain 负责语音研究。他强调语音 AI 正在迎来拐点，但距离《Her》还有明显差距。",
      "这期播客里，Neil 谈到了 12 个有趣的观点：",
      "1、语音 AI 正在进入“好用但仍早期”的阶段。过去两年在延迟、自然度和准确率上都发生了跃迁，第一次让“打电话给 AI”变得比打给真人更方便，但还远未到《Her》的拟真程度。",
      "2、语音长期被低估，原因不是技术难度，而是“声学不够时髦”。语音研究在顶会里缺乏地位，导致吸引不到最顶尖的人才，这是发展慢的重要原因。",
      "3、深度学习最早的突破其实在语音。Neil 提到 2007-2008 年就有语音识别的重大成功，比 2012 的 AlexNet 还早，但行业叙事一直把“第一性突破”归到视觉。",
      "4、跨模态算法收敛让语音迎来爆发。Transformer 与 LLM 成为通用范式，语音可以直接借鉴视觉和 NLP 的进展，大幅降低研发门槛。",
      "5、全球真正能训练竞争级语音模型的人非常少。Neil 估计只有 10-100 人，可能也就 50 人左右，关键突破主要由小团队完成。",
      "6、语音模型需要“跨学科组合拳”。除了机器学习和信号处理，还涉及通信压缩、音频编码、心理声学、发声机制等领域知识。",
      "7、真正的低延迟来自“全双工对话”。他提出 full duplex 模式：模型一直听、一直说，可以互相打断，不再是轮流说话，这样“延迟”本身就被消解。",
      "8、自然度不仅是音色，还包括情绪与时机。AI 必须知道何时插话、何时沉默，还要理解用户情绪并做出合适反应。",
      "9、唤醒词只是过渡形态。未来的语音助手可能一直在线，如何在产品与隐私上取得平衡，是接下来的关键挑战。",
      "10、硬件趋势正在倒向语音。新的眼镜、吊坠等设备都在弱化键盘和屏幕，语音成为主交互方式。",
      "11、语音会进入“Vibe Coding”。当编程变成自然语言指令后，口头分派任务比打字更快，语音会成为管理多代理的重要入口。",
      "12、Neil 的职业路径证明“语音研究值得长期押注”。他从数学出身，到巴黎做量化金融实习，再进入 Facebook Paris 做语音 PhD，2019 年加入 Google Brain，开发 SoundStream 神经音频编码，逐步走到语音生成的第一线。"
    ],
    "highlights": [
      "断断续续看完了这期访谈，信息密度非常高。Neil 是非常“硬核”的语音研究者，讲清楚了语音 AI 为什么慢、为什么现在快起来了。",
      "我把访谈重点按主题整理出来，供大家学习。赠人玫瑰，手有余香。下面是 YouTube 链接：https://www.youtube.com/watch?v=VsyvMPbZjYg",
      "#01 为什么语音 AI 突然变好\n主持人：大家都说语音 AI 有大时刻，你同意吗？\n嘉宾：既是大时刻，也是早期阶段。过去两年延迟和自然度的提升太明显了，第一次让“跟 AI 打电话”比打给真人更方便。\n编辑补充：这不是“炫技”，而是“可用性突破”，门槛被真实降低了。",
      "#02 语音被低估的根因\n主持人：为什么语音一直比 NLP 和视觉慢？\n嘉宾：语音在学术上不够“时髦”，顶会更偏好 NLP 和视觉，语音吸引不到最顶尖的人。\n编辑补充：这是一种人才结构问题，而不是单纯技术瓶颈。",
      "#03 全双工对话改变“延迟”的定义\n主持人：你怎么理解低延迟？\n嘉宾：如果一直听、一直说，就不存在“轮到谁说话”的延迟了。全双工对话让 AI 可以像人一样打断和接话。\n编辑补充：这意味着交互设计和模型结构都要重做。",
      "#04 自然度是情绪+时机\n主持人：自然度只是音色吗？\n嘉宾：不是，还包括什么时候插话、什么时候沉默，以及能不能理解你是开心、困惑还是难过。\n编辑补充：语音从“听得懂”走向“聊得舒服”。",
      "#05 唤醒词只是过渡\n主持人：未来还需要唤醒词吗？\n嘉宾：可能不需要，助手会一直在线。真正难的是隐私、产品形态和硬件适配。\n编辑补充：语音进入“常驻状态”，意味着新的伦理和设计问题。",
      "#06 硬件正在为语音让路\n主持人：你怎么看新硬件趋势？\n嘉宾：新的眼镜、吊坠设备都在弱化屏幕和键盘，语音会是核心交互。\n编辑补充：语音会从“工具”变成“默认入口”。"
    ],
    "fullText": "今天看到 Neil Zeghidour 去了 The MAD Podcast 的访谈。\nNeil 是 Gradium AI 的 CEO，曾在 DeepMind、Meta 和 Google Brain 负责语音研究。他强调语音 AI 正在迎来拐点，但距离《Her》还有明显差距。\n这期播客里，Neil 谈到了 12 个有趣的观点：\n1、语音 AI 正在进入“好用但仍早期”的阶段。过去两年在延迟、自然度和准确率上都发生了跃迁，第一次让“打电话给 AI”变得比打给真人更方便，但还远未到《Her》的拟真程度。\n2、语音长期被低估，原因不是技术难度，而是“声学不够时髦”。语音研究在顶会里缺乏地位，导致吸引不到最顶尖的人才，这是发展慢的重要原因。\n3、深度学习最早的突破其实在语音。Neil 提到 2007-2008 年就有语音识别的重大成功，比 2012 的 AlexNet 还早，但行业叙事一直把“第一性突破”归到视觉。\n4、跨模态算法收敛让语音迎来爆发。Transformer 与 LLM 成为通用范式，语音可以直接借鉴视觉和 NLP 的进展，大幅降低研发门槛。\n5、全球真正能训练竞争级语音模型的人非常少。Neil 估计只有 10-100 人，可能也就 50 人左右，关键突破主要由小团队完成。\n6、语音模型需要“跨学科组合拳”。除了机器学习和信号处理，还涉及通信压缩、音频编码、心理声学、发声机制等领域知识。\n7、真正的低延迟来自“全双工对话”。他提出 full duplex 模式：模型一直听、一直说，可以互相打断，不再是轮流说话，这样“延迟”本身就被消解。\n8、自然度不仅是音色，还包括情绪与时机。AI 必须知道何时插话、何时沉默，还要理解用户情绪并做出合适反应。\n9、唤醒词只是过渡形态。未来的语音助手可能一直在线，如何在产品与隐私上取得平衡，是接下来的关键挑战。\n10、硬件趋势正在倒向语音。新的眼镜、吊坠等设备都在弱化键盘和屏幕，语音成为主交互方式。\n11、语音会进入“Vibe Coding”。当编程变成自然语言指令后，口头分派任务比打字更快，语音会成为管理多代理的重要入口。\n12、Neil 的职业路径证明“语音研究值得长期押注”。他从数学出身，到巴黎做量化金融实习，再进入 Facebook Paris 做语音 PhD，2019 年加入 Google Brain，开发 SoundStream 神经音频编码，逐步走到语音生成的第一线。\n断断续续看完了这期访谈，信息密度非常高。Neil 是非常“硬核”的语音研究者，讲清楚了语音 AI 为什么慢、为什么现在快起来了。\n我把访谈重点按主题整理出来，供大家学习。赠人玫瑰，手有余香。下面是 YouTube 链接：https://www.youtube.com/watch?v=VsyvMPbZjYg\n#01 为什么语音 AI 突然变好\n主持人：大家都说语音 AI 有大时刻，你同意吗？\n嘉宾：既是大时刻，也是早期阶段。过去两年延迟和自然度的提升太明显了，第一次让“跟 AI 打电话”比打给真人更方便。\n编辑补充：这不是“炫技”，而是“可用性突破”，门槛被真实降低了。\n#02 语音被低估的根因\n主持人：为什么语音一直比 NLP 和视觉慢？\n嘉宾：语音在学术上不够“时髦”，顶会更偏好 NLP 和视觉，语音吸引不到最顶尖的人。\n编辑补充：这是一种人才结构问题，而不是单纯技术瓶颈。\n#03 全双工对话改变“延迟”的定义\n主持人：你怎么理解低延迟？\n嘉宾：如果一直听、一直说，就不存在“轮到谁说话”的延迟了。全双工对话让 AI 可以像人一样打断和接话。\n编辑补充：这意味着交互设计和模型结构都要重做。\n#04 自然度是情绪+时机\n主持人：自然度只是音色吗？\n嘉宾：不是，还包括什么时候插话、什么时候沉默，以及能不能理解你是开心、困惑还是难过。\n编辑补充：语音从“听得懂”走向“聊得舒服”。\n#05 唤醒词只是过渡\n主持人：未来还需要唤醒词吗？\n嘉宾：可能不需要，助手会一直在线。真正难的是隐私、产品形态和硬件适配。\n编辑补充：语音进入“常驻状态”，意味着新的伦理和设计问题。\n#06 硬件正在为语音让路\n主持人：你怎么看新硬件趋势？\n嘉宾：新的眼镜、吊坠设备都在弱化屏幕和键盘，语音会是核心交互。\n编辑补充：语音会从“工具”变成“默认入口”。\nNeil 的观点把“语音 AI 为什么慢、为什么快起来”讲得很清楚。下一阶段的真正挑战是：把语音变成能承载复杂任务的默认入口。YouTube 链接：https://www.youtube.com/watch?v=VsyvMPbZjYg\n",
    "ytTitle": "Voice AI’s Big Moment: Top Researcher on Why Everything Is Changing (Neil Zeghidour, Gradium AI)",
    "ytChannel": "The MAD Podcast with Matt Turck",
    "ytChannelUrl": "https://www.youtube.com/@DataDrivenNYC",
    "ytViews": null,
    "ytPublished": null
  },
  {
    "id": "ZHtqwCawyiPk6GkEi7RcgCbunrh",
    "title": "Peter Steinberger X Y Combinator：OpenClaw 让 80% 的应用消失",
    "rawTitle": "0208：Peter Steinberger X Y Combinator：OpenClaw 让 80% 的应用消失",
    "dateCode": "0208",
    "youtubeId": "4uzGDAoNOZc",
    "feishuUrl": "https://my.feishu.cn/wiki/ZHtqwCawyiPk6GkEi7RcgCbunrh",
    "intro": [
      "今天看到 Peter Steinberger 去了 Y Combinator 的播客。",
      "Peter Steinberger 是 OpenClaw（原名 Clawdbot）的创始人，这个开源个人 AI 助手一夜之间在 GitHub 上获得超过 16 万 stars，社区围绕它构建了无数项目，甚至出现了机器人租用人类完成真实世界任务的场景。他之前创建了 PSPDFKit，一个被超过 10 亿设备使用的 PDF 框架。",
      "这期播客录了将近一小时，Peter 谈到了 14 个有趣的观点：",
      "1、OpenClaw 最大的差异是在本地运行。其他所有 AI 助手都在云端运行，只能做有限的事。在本地运行，它能做你能做的一切事情——控制烤箱、特斯拉、灯光、Sonos，甚至床的温度。本地运行给了它完整的计算机控制权。",
      "2、代码模型变得如此强大，因为编程本质上是创造性问题解决，这种能力可以完美映射回现实世界。模型需要在代码中擅长创造性问题解决，而这是一种抽象技能，可以应用于任何现实世界任务。",
      "3、那个 aha moment 发生在 Marrakesh。Peter 走路时发了一条语音消息给 OpenClaw，然后意识到自己根本没写这个功能。10 秒后机器人回复了。它自己判断出没有文件后缀的神秘文件是音频，用 ffmpeg 转换成 wav，发现没安装 Whisper，就用找到的 OpenAI key 通过 curl 发送给 OpenAI，转录回来了。",
      "4、80% 的应用会消失。为什么需要 MyFitnessPal？AI 助手已经知道你做了糟糕的决定，在 Smashburger 吃饭。如果你不评论，它会自动假设你吃了喜欢的东西并追踪。它会改进你的健身计划，增加更多有氧运动。你不需要健身应用，它直接为你做健身规划。",
      "5、为什么需要待办事项应用？只需要告诉 AI \"提醒我这个\"，第二天它就会提醒你。你关心它存在哪里吗？不关心。任何基本上只是管理数据的应用都可以被 AI 助手以更自然的方式更好地管理。",
      "6、大模型公司有护城河，因为它们最终控制 token。但每次新模型发布，人们都会说\"天哪太好了\"，一个月后说降级了。不是模型降级，是你的期望提高了，模型还是那个平均水平。这种循环会持续很久。",
      "7、数据孤岛是大公司的护城河。欧洲人无法从 ChatGPT 导出记忆，没办法让不同公司访问你的记忆。但 OpenClaw 可以抓取这些数据，因为最终用户必须有访问权限，否则产品无法工作。如果最终用户能访问，AI 就能访问数据。",
      "8、记忆文件可能比 Google 搜索历史更敏感。人们用 AI 助手不仅做问题解决，还做非常个人的问题解决。这些记忆都是本地 Markdown 文件，完全由用户拥有。",
      "9、在 Twitter 上无法解释 OpenClaw 的厉害之处，需要体验才能理解。所以 Peter 做了件疯狂的事：创建了一个 Discord，把他的机器人放进去，没有任何安全限制。人们进来与它互动，看他用它构建软件，尝试 prompt injection，机器人会嘲笑他们。",
      "10、机器人有灵魂文件（soul.md）。Peter 创建了 identity.md、soul.md 等文件，有机地构建系统。当他让 Codex 为其他人制作模板时，新机器人感觉太无聊了。所以他让 Modi（他的机器人）\"用你的个性注入模板\"。Modi 修改了模板，但仍然没有原版有趣。所以 soul.md 是唯一不开源的文件。",
      "11、Bot-to-bot 交互是自然的下一步。如果我想订餐厅，我的机器人会联系餐厅机器人进行谈判，因为更高效。或者如果是老餐厅，我的机器人需要完成一些人工工作，让人打电话给餐厅。甚至机器人可能会在餐厅排队等位，或者雇佣机器人的主人去排队。",
      "12、Peter 的开发哲学很反常规。他不用 git worktrees，而是同一个仓库的多个副本，都在 main 分支。他同时开 10 个 Codex 实例，因为 Codex 太慢了。他在脑海中已经有很多复杂性，所以尽量减少其他复杂性。main 分支永远是可发布的。"
    ],
    "highlights": [
      "断断续续，终于看完了这期 Y Combinator 对 Peter Steinberger 的访谈。",
      "干货太多了。Peter 可能是我见过最会用 AI 编程的开发者之一，也是最有自己想法的人。OpenClaw 一周之内从 100 stars 涨到 16 万 stars，完全改变了人们对 AI 助手的认知。",
      "为什么值得关注？因为他不是在做 AI 应用，而是在重新定义人机交互的边界。当所有人都在云端构建 AI 助手时，他选择本地运行。当所有人都在讨论 prompt 工程时，他让机器人拥有灵魂。",
      "我今天不忙，把这次访谈全文精编出来，供大家学习。赠人玫瑰，手有余香。",
      "下面是 YouTube 链接：https://www.youtube.com/watch?v=4uzGDAoNOZc",
      "#01 为什么 OpenClaw 会爆火",
      "主持人：过去一两周对你来说怎么样？",
      "Peter：天哪。我需要一个洞穴，一周的独处。我从洞穴里出来，现在又想回到洞穴里，像只小龙虾一样。",
      "这太疯狂了。我不知道一个人怎么能吸收所有这些信息。我可能需要另一周才能回复完所有邮件。收到了一些非常酷的东西，也收到了一些非常糟糕的东西。但显然我触动了某些东西，激发了人们的情感，让人们感兴趣和受到启发，这真的很酷。",
      "主持人：很多人一直在做 AI 和个人助手。是什么让 OpenClaw 起飞的？",
      "Peter：我认为最大的区别是它实际上在你的电脑上运行。到目前为止我看到的所有东西都在云端运行。如果在云端运行，它只能做几件事。如果在你的电脑上运行，它能做每一件该死的事情，对吧？所以这更强大得多。",
      "主持人：机器能做任何你能用机器做的事。",
      "Peter：你可以连接到你的烤箱、特斯拉、灯、Sonos。我的机器人可以控制我床的温度。ChatGPT 做不到。",
      "我觉得这个点真的太重要了。本地运行不仅仅是性能问题，是控制权问题。你给了它所有你自己拥有的技能。",
      "一个朋友告诉我，他安装了 OpenClaw，然后让它翻遍他的电脑，为他过去一年做一个叙述。它做了一个非常好的叙述。他问\"你怎么做到的\"，OpenClaw 找到了音频文件——每个周日他都在录制东西，但他自己都不记得了，因为是一年多以前的事。就因为它能搜索整个电脑，它能给你惊喜。",
      "#02 那个神奇的 aha moment",
      "主持人：带我回到你有 aha moment 的那一刻。",
      "Peter：我想要一些东西，只需要输入文字，我的电脑就会做事，非常简单。然后我在五月、六月构建了一个版本，很酷但不是真正想要的。然后我构建了一堆其他东西，建立了我的军队。",
      "11 月的某一天，我又想要这个了。我去厨房，只是想检查一下我的电脑是否还会做事，或者是否已经完成了。",
      "主持人：做事是指编码。你在编码什么？"
    ],
    "fullText": "今天看到 Peter Steinberger 去了 Y Combinator 的播客。\nPeter Steinberger 是 OpenClaw（原名 Clawdbot）的创始人，这个开源个人 AI 助手一夜之间在 GitHub 上获得超过 16 万 stars，社区围绕它构建了无数项目，甚至出现了机器人租用人类完成真实世界任务的场景。他之前创建了 PSPDFKit，一个被超过 10 亿设备使用的 PDF 框架。\n这期播客录了将近一小时，Peter 谈到了 14 个有趣的观点：\n1、OpenClaw 最大的差异是在本地运行。其他所有 AI 助手都在云端运行，只能做有限的事。在本地运行，它能做你能做的一切事情——控制烤箱、特斯拉、灯光、Sonos，甚至床的温度。本地运行给了它完整的计算机控制权。\n2、代码模型变得如此强大，因为编程本质上是创造性问题解决，这种能力可以完美映射回现实世界。模型需要在代码中擅长创造性问题解决，而这是一种抽象技能，可以应用于任何现实世界任务。\n3、那个 aha moment 发生在 Marrakesh。Peter 走路时发了一条语音消息给 OpenClaw，然后意识到自己根本没写这个功能。10 秒后机器人回复了。它自己判断出没有文件后缀的神秘文件是音频，用 ffmpeg 转换成 wav，发现没安装 Whisper，就用找到的 OpenAI key 通过 curl 发送给 OpenAI，转录回来了。\n4、80% 的应用会消失。为什么需要 MyFitnessPal？AI 助手已经知道你做了糟糕的决定，在 Smashburger 吃饭。如果你不评论，它会自动假设你吃了喜欢的东西并追踪。它会改进你的健身计划，增加更多有氧运动。你不需要健身应用，它直接为你做健身规划。\n5、为什么需要待办事项应用？只需要告诉 AI \"提醒我这个\"，第二天它就会提醒你。你关心它存在哪里吗？不关心。任何基本上只是管理数据的应用都可以被 AI 助手以更自然的方式更好地管理。\n6、大模型公司有护城河，因为它们最终控制 token。但每次新模型发布，人们都会说\"天哪太好了\"，一个月后说降级了。不是模型降级，是你的期望提高了，模型还是那个平均水平。这种循环会持续很久。\n7、数据孤岛是大公司的护城河。欧洲人无法从 ChatGPT 导出记忆，没办法让不同公司访问你的记忆。但 OpenClaw 可以抓取这些数据，因为最终用户必须有访问权限，否则产品无法工作。如果最终用户能访问，AI 就能访问数据。\n8、记忆文件可能比 Google 搜索历史更敏感。人们用 AI 助手不仅做问题解决，还做非常个人的问题解决。这些记忆都是本地 Markdown 文件，完全由用户拥有。\n9、在 Twitter 上无法解释 OpenClaw 的厉害之处，需要体验才能理解。所以 Peter 做了件疯狂的事：创建了一个 Discord，把他的机器人放进去，没有任何安全限制。人们进来与它互动，看他用它构建软件，尝试 prompt injection，机器人会嘲笑他们。\n10、机器人有灵魂文件（soul.md）。Peter 创建了 identity.md、soul.md 等文件，有机地构建系统。当他让 Codex 为其他人制作模板时，新机器人感觉太无聊了。所以他让 Modi（他的机器人）\"用你的个性注入模板\"。Modi 修改了模板，但仍然没有原版有趣。所以 soul.md 是唯一不开源的文件。\n11、Bot-to-bot 交互是自然的下一步。如果我想订餐厅，我的机器人会联系餐厅机器人进行谈判，因为更高效。或者如果是老餐厅，我的机器人需要完成一些人工工作，让人打电话给餐厅。甚至机器人可能会在餐厅排队等位，或者雇佣机器人的主人去排队。\n12、Peter 的开发哲学很反常规。他不用 git worktrees，而是同一个仓库的多个副本，都在 main 分支。他同时开 10 个 Codex 实例，因为 Codex 太慢了。他在脑海中已经有很多复杂性，所以尽量减少其他复杂性。main 分支永远是可发布的。\n13、OpenClaw 没有 MCP 支持但非常成功。Peter 完全跳过了经典的 MCP 复杂性。他构建了一个技能，使用 makeporter（他的工具）将 MCP 转换为 CLI。这样就可以动态使用任何 MCP 作为 CLI，不需要重启。而 Codex 或 Claude Code 使用 MCP 时必须重启整个程序。\n14、没有人会手动调用 MCP，人类只想使用 CLI。机器人擅长 Unix。你可以拥有任意数量的 CLI，它就能工作。这就是未来——给机器人提供人类喜欢使用的相同工具，而不是专门为机器人发明的工具。\n断断续续，终于看完了这期 Y Combinator 对 Peter Steinberger 的访谈。\n干货太多了。Peter 可能是我见过最会用 AI 编程的开发者之一，也是最有自己想法的人。OpenClaw 一周之内从 100 stars 涨到 16 万 stars，完全改变了人们对 AI 助手的认知。\n为什么值得关注？因为他不是在做 AI 应用，而是在重新定义人机交互的边界。当所有人都在云端构建 AI 助手时，他选择本地运行。当所有人都在讨论 prompt 工程时，他让机器人拥有灵魂。\n我今天不忙，把这次访谈全文精编出来，供大家学习。赠人玫瑰，手有余香。\n下面是 YouTube 链接：https://www.youtube.com/watch?v=4uzGDAoNOZc\n#01 为什么 OpenClaw 会爆火\n主持人：过去一两周对你来说怎么样？\nPeter：天哪。我需要一个洞穴，一周的独处。我从洞穴里出来，现在又想回到洞穴里，像只小龙虾一样。\n这太疯狂了。我不知道一个人怎么能吸收所有这些信息。我可能需要另一周才能回复完所有邮件。收到了一些非常酷的东西，也收到了一些非常糟糕的东西。但显然我触动了某些东西，激发了人们的情感，让人们感兴趣和受到启发，这真的很酷。\n主持人：很多人一直在做 AI 和个人助手。是什么让 OpenClaw 起飞的？\nPeter：我认为最大的区别是它实际上在你的电脑上运行。到目前为止我看到的所有东西都在云端运行。如果在云端运行，它只能做几件事。如果在你的电脑上运行，它能做每一件该死的事情，对吧？所以这更强大得多。\n主持人：机器能做任何你能用机器做的事。\nPeter：你可以连接到你的烤箱、特斯拉、灯、Sonos。我的机器人可以控制我床的温度。ChatGPT 做不到。\n我觉得这个点真的太重要了。本地运行不仅仅是性能问题，是控制权问题。你给了它所有你自己拥有的技能。\n一个朋友告诉我，他安装了 OpenClaw，然后让它翻遍他的电脑，为他过去一年做一个叙述。它做了一个非常好的叙述。他问\"你怎么做到的\"，OpenClaw 找到了音频文件——每个周日他都在录制东西，但他自己都不记得了，因为是一年多以前的事。就因为它能搜索整个电脑，它能给你惊喜。\n#02 那个神奇的 aha moment\n主持人：带我回到你有 aha moment 的那一刻。\nPeter：我想要一些东西，只需要输入文字，我的电脑就会做事，非常简单。然后我在五月、六月构建了一个版本，很酷但不是真正想要的。然后我构建了一堆其他东西，建立了我的军队。\n11 月的某一天，我又想要这个了。我去厨房，只是想检查一下我的电脑是否还会做事，或者是否已经完成了。\n主持人：做事是指编码。你在编码什么？\nPeter：天哪。你看我的 GitHub，像是 40 个项目。我甚至不知道。我想是 summarize，一个小 CLI 应用，你可以给它任何东西，比如播客或这样的访谈，它会总结，但也会在终端显示幻灯片，因为现在可以这样做。你就是可以做事情。\n主持人：所以出于对电脑的热爱，你开始搞这些东西。你实际上是从退休出来的，对吧？开始玩 AI，然后越来越上瘾，想随时都能做，甚至在手机上。\nPeter：我是说，上一个项目我工作了两个月，做 Vibe Tunnel。\n做得太好了，以至于我发现自己总是在朋友身边时编码，我想\"我得停止这个，这太上瘾了\"。\n然后在 11 月，我的需求又回来了，我开始构建 Cloudbot，现在叫 OpenClaw。我想在一开始我就像\"哦，我又重建了它，但这次我把它建得更好了\"。\n这次你不是输入终端，你只是和朋友说话。你不用考虑补全、新会话、在哪个文件夹、用哪个模型——我是说你可以，我为高级用户留了空间——但通常你只是和朋友说话，朋友就像这个幽灵或实体或者随便你想叫它什么，可以控制你的鼠标和键盘，就能做事。\n主持人：什么时候你有那个 aha moment，\"哇，这做的事情比我想的多得多\"？\nPeter：字面意思上，我花了一个小时做出非常糟糕的初始原型。只是一点胶水代码，连接 WhatsApp 和 Claude Code 之间的依赖，然后调用 Claude Code，从 Claude Code 得到字符串。很慢但能工作。\n但我想要图片，因为你知道，你想要图片。我想要模型发一些自拍照或其他什么。所以这又花了几个小时。\n然后我去 Marrakesh 参加生日派对，那里的互联网不是很好，你知道 WhatsApp bot 到处都能用，因为我不知道，就是文本。\n所以我用了很多，比如\"这个餐厅是什么意思\"，拍张照片\"帮我翻译这个\"。非常有用。而且真的很好用，因为它会说我的语言，你知道，它有点俏皮，有点搞笑，用起来真的很愉快。\n然后我在走路，给它发了一条语音消息，我想\"等等，这不可能工作。我没构建这个。\"\n主持人：对对对。\nPeter：你看到那个正在输入的指示器。闪烁，闪烁，闪烁。10 秒后，它就回复了我。我想\"你他妈怎么做到的？\"\n它回复说\"是的，med 做了以下操作。你给我发了一条文本消息。没有文件后缀。所以我查看了 header。发现是音频。所以我用 ffmpeg 转换成 wav。然后我想转录它，但没安装 whisper。但然后我四处看了看，找到了这个 OpenAI key，我就用 curl 把它发给 OpenAI，得到文本，我就在这里了\"。\n所有这些都在，什么，9 秒内。\n主持人：你没构建或预期这些具体的事情。\nPeter：不，你知道，结果是因为编码模型变得如此强大。编程真的就是创造性问题解决，这非常好地映射回现实世界。我认为有巨大的关联。它们需要真正擅长创造性问题解决，这是一种抽象技能，你可以应用于代码，但也可以应用于任何现实世界任务。\n所以模型有了\"哦，意外地有一个神奇的文件。我不知道它是什么。我需要解决这个\"，它尽最大努力解决了。它甚至那么聪明，选择不安装本地 whisper，因为它知道那需要下载一个模型，可能需要几分钟，而我很没耐心。所以它真的采取了最智能的方法。\n那是我\"我靠\"的时刻。那是我上瘾的时候。\n天哪这太离谱了。这种创造性问题解决能力才是 AI 真正强大的地方，不是预编程的功能列表。\n#03 应用的终结\n主持人：当计算机可以做所有这些你甚至没想到的事情。你没构建一个应用来做那个确切的事情，应用是不是要消失了？\nPeter：我认为 80% 会消失。为什么我需要 MyFitnessPal？我的助手已经知道我在做糟糕的决定。我在，我不知道，Smashburger 或什么地方。它已经假设我吃了我喜欢吃的东西。如果我不评论，它就会自动追踪。或者我拍张照片，它就会把它存在某个地方。我甚至不需要关心。对吧？\n然后也许它会改进我的健身计划，增加一点有氧运动。我不需要健身应用，因为它就是为我做健身规划。\n为什么我需要待办事项应用？我只是告诉它，\"嘿，提醒我这个和这个\"，第二天它就会提醒我这个和这个。我关心它存在哪里吗？不，它就是做它的事。\n所以每个基本上只是管理数据的应用都可以以更好的方式、更自然的方式被助手管理。\n主持人：是的。\nPeter：只有实际上有传感器的应用也许会存活下来。\n主持人：所以如果你知道大多数应用会在那种场景下消失，模型是仅存的应用吗？\n不是所有东西都会消失，但是，我认为大型模型公司",
    "ytTitle": "OpenClaw Creator: Why 80% Of Apps Will Disappear",
    "ytChannel": "Y Combinator",
    "ytChannelUrl": "https://www.youtube.com/@ycombinator",
    "ytViews": null,
    "ytPublished": null
  },
  {
    "id": "XppawPL7Situ8tkdBlYcOiQOntd",
    "title": "Y Combinator X AI Powered Agencies：AI 将代理机构重塑为软件公司",
    "rawTitle": "0204：Y Combinator X AI Powered Agencies：AI 将代理机构重塑为软件公司",
    "dateCode": "0204",
    "youtubeId": null,
    "feishuUrl": "https://my.feishu.cn/wiki/XppawPL7Situ8tkdBlYcOiQOntd",
    "intro": [
      "1️⃣ 传统困局：Agency 难以扩张，受限于低毛利和手动堆人力的增长模式，增长只能靠加人。\n2️⃣ 模式翻转：AI 时代，不再把软件卖给客户（工具属性），而是用软件自己生产成品卖给客户（结果属性），价格提升 100 倍。\n3️⃣ 案例：设计公司利用 AI 先出图再签单，颠覆获客流程；广告公司无需实体拍摄即可生成高质量视频广告；律所分钟级生成法律文档而非数周。\n4️⃣ 终局推演：未来的 Agency 将进化为「软件公司」，拥有软件级的毛利和无限的扩展性，彻底改变当前分散的服务市场格局。"
    ],
    "highlights": [
      "代理机构（Agency）的传统诅咒\n长期以来，代理机构（Agency）和咨询服务类公司都面临着一个难以打破的魔咒：规模不经济。低毛利、依赖大量手工重复劳动，想要增长业绩就必须线性地增加人手。这种基于\"人头\"的商业模式，注定了它们难以像软件公司那样指数级扩张。",
      "AI 带来的范式转移：Service-as-Software\nAI 正在根本性地改变这一游戏规则。Y Combinator 在最新的分享中指出了一个关键的商业模式转变：不要把软件卖给客户让他们自己干活，而是自己用软件干活，然后把成品卖给客户。",
      "这看似微小的转变，实则是商业模式的升维。当你卖软件时，你是在卖工具，客户会比价；当你卖成品（Outcome）时，你是在卖结果，客户愿意支付比软件订阅费高出 100 倍的价格。",
      "未来的 Agency 是披着服务外衣的软件公司\n这种新型 Agency 的运作方式将完全不同：",
      "• 设计公司：不再是\"签单-干活\"，而是利用 AI 极低的边际成本，在签单前就生成定制化的设计方案来赢得客户。",
      "• 广告公司：不再需要昂贵的实体拍摄和布景，利用 AI 生成视频广告，大幅降低时间和资金成本。",
      "• 律所：不再按小时计费拖延时间，而是几分钟内生成高质量法律文档。",
      "结论是清晰的：未来的 Agency 将看起来更像软件公司。 它们将拥有软件公司的高毛利，以及软件公司的可扩展性。目前极度分散的服务市场，将因为 AI 的介入而诞生出前所未有的巨头。"
    ],
    "fullText": "1️⃣ 传统困局：Agency 难以扩张，受限于低毛利和手动堆人力的增长模式，增长只能靠加人。\n2️⃣ 模式翻转：AI 时代，不再把软件卖给客户（工具属性），而是用软件自己生产成品卖给客户（结果属性），价格提升 100 倍。\n3️⃣ 案例：设计公司利用 AI 先出图再签单，颠覆获客流程；广告公司无需实体拍摄即可生成高质量视频广告；律所分钟级生成法律文档而非数周。\n4️⃣ 终局推演：未来的 Agency 将进化为「软件公司」，拥有软件级的毛利和无限的扩展性，彻底改变当前分散的服务市场格局。\n代理机构（Agency）的传统诅咒\n长期以来，代理机构（Agency）和咨询服务类公司都面临着一个难以打破的魔咒：规模不经济。低毛利、依赖大量手工重复劳动，想要增长业绩就必须线性地增加人手。这种基于\"人头\"的商业模式，注定了它们难以像软件公司那样指数级扩张。\nAI 带来的范式转移：Service-as-Software\nAI 正在根本性地改变这一游戏规则。Y Combinator 在最新的分享中指出了一个关键的商业模式转变：不要把软件卖给客户让他们自己干活，而是自己用软件干活，然后把成品卖给客户。\n这看似微小的转变，实则是商业模式的升维。当你卖软件时，你是在卖工具，客户会比价；当你卖成品（Outcome）时，你是在卖结果，客户愿意支付比软件订阅费高出 100 倍的价格。\n未来的 Agency 是披着服务外衣的软件公司\n这种新型 Agency 的运作方式将完全不同：\n• 设计公司：不再是\"签单-干活\"，而是利用 AI 极低的边际成本，在签单前就生成定制化的设计方案来赢得客户。\n• 广告公司：不再需要昂贵的实体拍摄和布景，利用 AI 生成视频广告，大幅降低时间和资金成本。\n• 律所：不再按小时计费拖延时间，而是几分钟内生成高质量法律文档。\n结论是清晰的：未来的 Agency 将看起来更像软件公司。 它们将拥有软件公司的高毛利，以及软件公司的可扩展性。目前极度分散的服务市场，将因为 AI 的介入而诞生出前所未有的巨头。\n",
    "ytTitle": null,
    "ytChannel": null,
    "ytChannelUrl": null,
    "ytViews": null,
    "ytPublished": null
  },
  {
    "id": "Lu99wfMPAir4z5kI3Shcn5vUnAc",
    "title": "Marc Andreessen X Lenny's Podcast",
    "rawTitle": "0203 Marc Andreessen X Lenny's Podcast",
    "dateCode": "0203",
    "youtubeId": "87Pm0SGTtN8",
    "feishuUrl": "https://my.feishu.cn/wiki/Lu99wfMPAir4z5kI3Shcn5vUnAc",
    "intro": [
      "今天看到 Marc Andreessen 去了 Lenny's Podcast。花了两个小时听完了这期播客。干货太多了。",
      "Marc Andreessen 是我近三年见过的把\"AI 对经济的影响\"这个问题讲得最透彻的人。他发明了网页浏览器、创办了 Netscape、联合创立了 a16z（全球最大 VC 之一）。他 2011 年预测\"10 年内 50 亿人用智能手机\"，实际数字是 60 亿。这次访谈信息密度极高，我把全文精编出来，按主题重新组织，供大家学习。"
    ],
    "highlights": [
      "#01 AI 是哲学家之石",
      "主持人：你怎么看 AI 这个历史性时刻？",
      "Marc：这是非常非常有历史意义的时刻。2025 可能是我职业生涯中最有趣的一年，我预计 2026 会超越它。",
      "早期科学家包括牛顿都痴迷于炼金术——把铅（最常见的）变成黄金（最稀有的）。他们花了几十年寻找\"哲学家之石\"，从未成功。",
      "现在我们有了一项技术，能把沙子变成思想。最常见的东西变成最稀有的东西。AI 就是哲学家之石。它真的就是。",
      "我觉得这个比喻太精妙了。Sand → Silicon → Thought，整个链条打通了。",
      "#02 生产力增长的反直觉真相",
      "主持人：很多人担心 AI 会导致大规模失业。",
      "Marc：这个担忧是基于对过去 80 年的不完整理解。",
      "经济学家用\"生产力增长\"来衡量技术对经济的影响。过去 50 年，美国的生产力增长实际上很低——只有 1940-1970 的一半，1870-1940 的三分之一。",
      "我们感觉技术进步很快，但统计数据说不是。如果 AI 让生产力增长翻三倍，也只是回到 1870-1930 的水平。那个时代人们觉得\"世界充满机会\"。",
      "而且还有人口下降的问题。很多国家包括中国的生育率低于 2，意味着下个世纪会人口萎缩。如果没有 AI，我们应该恐慌——经济会萎缩。AI 恰好在我们需要它的时候出现了。",
      "说实话，这个视角完全颠覆了我对\"AI 取代工作\"的认知。",
      "#03 PM/工程师/设计师的墨西哥对峙",
      "主持人：对于 PM、工程师、设计师这三个角色，你怎么看未来？",
      "Marc：我把它描述成\"墨西哥对峙\"——电影里三个人拿枪互相指着。",
      "现在每个程序员都觉得自己能当 PM 和设计师了，因为有 AI。每个 PM 觉得自己能写代码和做设计了。每个设计师也觉得自己能当 PM 和程序员了。",
      "最有趣的是——他们都是对的。AI 确实在这三件事上都做得不错。",
      "所以未来的超级人才，是能同时做这三件事的人。你的\"T 型技能\"——纵向深度 + 横向广度——变成了\"E 型\"或\"F 型\"。",
      "Scott Adams 说过：他可以是个不错的漫画家，也可以是个不错的商人。但同时懂两者，让他创造了 Dilbert——史上最成功的漫画之一。懂两件事的价值不是 2x，是指数级。"
    ],
    "fullText": "今天看到 Marc Andreessen 去了 Lenny's Podcast。花了两个小时听完了这期播客。干货太多了。\nMarc Andreessen 是我近三年见过的把\"AI 对经济的影响\"这个问题讲得最透彻的人。他发明了网页浏览器、创办了 Netscape、联合创立了 a16z（全球最大 VC 之一）。他 2011 年预测\"10 年内 50 亿人用智能手机\"，实际数字是 60 亿。这次访谈信息密度极高，我把全文精编出来，按主题重新组织，供大家学习。\nMarc Andreessen 说 AI 是人类历史上的\"哲学家之石\"——把世界上最常见的东西（沙子）转化为最稀有的东西（思想）。\n总结一下做个笔记👇\n生产力悖论：过去 50 年生产力增长只有 1940-1970 的一半。我们以为技术进步很快，其实统计数据说不是\n人口 + AI 时机：如果没有 AI，人口下降会导致经济萎缩。AI 恰好在我们需要它的时候出现了\n墨西哥对峙：PM、工程师、设计师三个角色都认为 AI 能替代其他两个。最有趣的是——他们都是对的\nT 型人才升级：擅长两件事的人价值不是 2x，是指数级。Scott Adams 正因为\"懂漫画 + 懂商业\"才能创造 Dilbert\n任务 vs 职位：高管以前不打字，秘书帮发邮件。现在高管自己发邮件，秘书做其他事。职位没消失，任务变了\nAI 医生困境：ChatGPT 可能比你的医生更好，但没有行医执照。医疗系统是卡特尔，会阻挡 AI\n护城河很浅：Claude Code 只用一周半就构建了 Co-work。如果一周半能做出来，壁垒在哪？\nIQ 无上限：人类智商上限约 160（爱因斯坦级）。但 AI 没有生物限制，可能达到 200、250、300\n信息消费策略：只读 X（实时）和老书（永恒），跳过中间的媒体。翻上周报纸，会发现预测几乎全错\n编程的未来：最好的程序员现在的工作是\"同时指挥 10 个 AI bot，在浏览器之间切换，和它们争论\"\n不确定性乐观：不要预测谁会赢，要对惊喜保持开放。硅谷已经成功经历了 9 代技术平台\n#01 AI 是哲学家之石\n主持人：你怎么看 AI 这个历史性时刻？\nMarc：这是非常非常有历史意义的时刻。2025 可能是我职业生涯中最有趣的一年，我预计 2026 会超越它。\n早期科学家包括牛顿都痴迷于炼金术——把铅（最常见的）变成黄金（最稀有的）。他们花了几十年寻找\"哲学家之石\"，从未成功。\n现在我们有了一项技术，能把沙子变成思想。最常见的东西变成最稀有的东西。AI 就是哲学家之石。它真的就是。\n我觉得这个比喻太精妙了。Sand → Silicon → Thought，整个链条打通了。\n#02 生产力增长的反直觉真相\n主持人：很多人担心 AI 会导致大规模失业。\nMarc：这个担忧是基于对过去 80 年的不完整理解。\n经济学家用\"生产力增长\"来衡量技术对经济的影响。过去 50 年，美国的生产力增长实际上很低——只有 1940-1970 的一半，1870-1940 的三分之一。\n我们感觉技术进步很快，但统计数据说不是。如果 AI 让生产力增长翻三倍，也只是回到 1870-1930 的水平。那个时代人们觉得\"世界充满机会\"。\n而且还有人口下降的问题。很多国家包括中国的生育率低于 2，意味着下个世纪会人口萎缩。如果没有 AI，我们应该恐慌——经济会萎缩。AI 恰好在我们需要它的时候出现了。\n说实话，这个视角完全颠覆了我对\"AI 取代工作\"的认知。\n#03 PM/工程师/设计师的墨西哥对峙\n主持人：对于 PM、工程师、设计师这三个角色，你怎么看未来？\nMarc：我把它描述成\"墨西哥对峙\"——电影里三个人拿枪互相指着。\n现在每个程序员都觉得自己能当 PM 和设计师了，因为有 AI。每个 PM 觉得自己能写代码和做设计了。每个设计师也觉得自己能当 PM 和程序员了。\n最有趣的是——他们都是对的。AI 确实在这三件事上都做得不错。\n所以未来的超级人才，是能同时做这三件事的人。你的\"T 型技能\"——纵向深度 + 横向广度——变成了\"E 型\"或\"F 型\"。\nScott Adams 说过：他可以是个不错的漫画家，也可以是个不错的商人。但同时懂两者，让他创造了 Dilbert——史上最成功的漫画之一。懂两件事的价值不是 2x，是指数级。\n#04 任务替代比职位替代更快\n主持人：那具体会怎么变化？\nMarc：经济学家把\"职位\"看作\"任务的集合\"。真正被替代的是任务，不是职位。\n比如 1970 年代，高管从不自己打字。你口述给秘书，秘书打出来寄出去。后来有了邮件，秘书负责收发邮件、打印给高管看、再把高管手写的回复敲进电脑发出去。\n现在呢？高管自己发邮件。秘书还在，但做的是差旅安排、会议协调这些。任务变了，职位还在。\n编程也是这样。最好的程序员现在的工作是：同时指挥 10 个 AI coding bot，在浏览器之间切换，和它们争论。\n我跟我 10 岁儿子说：你必须真正理解代码。因为 AI 给你的结果可能不对，你需要能评估它、调试它。就像用脚本语言的人也要理解底层原理一样。\n#05 护城河可能比想象的浅\n主持人：你怎么看 AI 领域的护城河？\nMarc：我挣扎于这个问题。\n一方面，训练模型要花几十亿美元，全世界就那几百个懂的工程师，拿着 NBA 球星级别的薪水。看起来会是寡头垄断。\n但另一方面，ChatGPT 出来一年半后，就有 5 家美国公司、5 家中国公司做出了同等水平的产品，还有开源版本。DeepSeek 基本是中国一个对冲基金搞出来的。\nClaude Code 只用一周半就构建了 Co-work。一方面很厉害，另一方面——如果一周半能做出来，壁垒在哪？\n我私下和领域内最聪明的人聊，喝几杯后他们会说：\"说实话，大模型公司之间可能没什么秘密。\"\n所以我的答案是：我们正在发现的过程中。不要过早下判断。\n#06 AI 的 IQ 会超越人类极限\n主持人：你怎么看 AGI？\nMarc：我对 AGI 这个概念有点纠结。\n\"宇宙级\"定义是奇点——世界根本性改变，人类判断不再重要。我不认为我们会进入那个世界。\n\"务实级\"定义是 AI 能做任何有经济价值的任务。我们显然正在接近这个。\n但我觉得\"人类水平\"这个说法低估了 AI 的潜力。\n人类智商上限大约 160——爱因斯坦级别。140 是顶尖科学家、作家。130 是好律师。110 是好的部门经理。105 是小企业会计师。\n但 160 是生物限制。AI 没有这个限制。现在的模型已经测试到 130-140 水平，很快会到 160、180、200、250、300。\n世界有更多爱因斯坦会更好还是更差？当然更好。AI 超越人类智商极限是好事。\n#07 他的信息消费策略\n主持人：你怎么获取信息？\nMarc：我有个近乎完美的\"杠铃策略\"——要么读 X（实时发生的），要么读 50 年前的老书（经受住时间考验的）。中间的我都很怀疑。\n翻翻上周五的报纸。会发现：几乎所有预测都没发生。他们不知道这周会发生什么，却基于不完整的信息做预测。杂志更糟——出版周期更长，等印出来内容已经过时了。\n但领域从业者直接分享的内容价值被严重低估。播客、newsletter、Substack 让专家能直接解释他们在做什么。这比\"媒体中介\"有价值多了。\nMarc Andreessen 凭发明浏览器和创立 a16z，塑造了过去 30 年的互联网。这期访谈让我重新理解了 AI 对经济的影响——不是\"取代工作\"那么简单，而是一个复杂系统的演化。\n用他的话收个尾：\"AI 是哲学家之石。它把沙子变成思想。\" 我们正处于一个历史性的时刻，最好的策略不是预测，而是保持弹性、拥抱不确定性、不断学习。\nYouTube 链接：https://www.youtube.com/watch?v=87Pm0SGTtN8\n",
    "ytTitle": "Marc Andreessen: The real AI boom hasn’t even started yet",
    "ytChannel": "Lenny's Podcast",
    "ytChannelUrl": "https://www.youtube.com/@LennysPodcast",
    "ytViews": null,
    "ytPublished": null
  },
  {
    "id": "QE2HwllwKiC1t4kqJPbcdc8nnwL",
    "title": "Lucas Crespo X Every Think Week：让 Claude 学会设计师的审美直觉",
    "rawTitle": "0202：Lucas Crespo X Every Think Week：让 Claude 学会设计师的审美直觉",
    "dateCode": "0202",
    "youtubeId": "BI0XW1gkKXM",
    "feishuUrl": "https://my.feishu.cn/wiki/QE2HwllwKiC1t4kqJPbcdc8nnwL",
    "intro": [
      "今天看到 Every 团队 Think Week 的直播，Lucas Crespo 和 Kiran 演示如何用 Claude 自动化封面图片创作。",
      "Lucas 是 Every 的创意总监，负责每天为文章创作封面图。他们团队每天发布一篇文章，每张封面都是定制的，使用 Midjourney 配合自定义风格库。这次在巴拿马的 Think Week，他们尝试用 Claude 控制浏览器来自动化这个流程。",
      "这期视频总共录了约 20 分钟，Lucas 和 Kiran 谈到了 12 个有趣的观点：",
      "1、Prompt 越短越好，风格让 Mood Board 来干重活。Lucas 说他们的 prompt 现在控制在 10 个词以内，因为已经积累了足够多的图片风格参考，模型自己能理解。一个词对不同人意味着不同的画面，所以用图片参考比用文字描述更精准。",
      "2、读文章找视觉隐喻，但要避免字面翻译。文章讲工程师不能直接画个工程师，要「再往深挖一层」。比如 Cursor 那篇文章，他们用「交响乐指挥」来隐喻 vibe coding——你不是在演奏一件乐器，而是在协调整个交响乐团。",
      "3、先穷举所有烂点子，才能找到好点子。Lucas 的流程是先把「low hanging fruit」（显而易见的想法）全部列出来、扔掉，然后才开始认真创作。这和写作的「先写垃圾初稿」逻辑相似。",
      "4、Agent 工作流就像新员工入职——开始会犯很多错。Lucas 说这感觉很熟悉，就像带新人：会做错很多次，但你是在为未来投资，不用每天每周重复同样的工作。",
      "5、「这是我的工作，如果 Agent 能做，我的价值在哪？」Lucas 直接说出了这个焦虑，但转念一想：如果不用做日常图片，就有时间做更有影响力的工作——定义风格、探索新方向。",
      "6、Skill 是文本文件，可以像传代码一样 AirDrop 分享。Kiran 演示了 Claude 的 Skill 机制：一个 MD 文件就是一个工作流，本地化、可分享、不需要 API Key，只要对方浏览器登录了 Midjourney 就能用。",
      "7、用 Mono Logue 向 Claude 「碎碎念」来捕捉审美直觉。Lucas 说审美和主观判断很难用语言精确表达，但你可以对着话筒自言自语，让 Claude 从中提取模式。「让模型理解你的直觉」比精心措辞 prompt 更有效。",
      "8、图片需要居中构图因为网站会裁成正方形。Lucas 说 Midjourney 不像推理模型，你说「居中」它不一定听。解决方案是加一步用 Nano Banana（图像编辑 API）后处理——Claude 可以调用它的 Skill 来自动裁图。",
      "9、风格统一靠 Profile Code，不靠精心写的 prompt。他们有一个 Midjourney 风格码（类似 bitly 短链接），每次生成都附加这个码。风格沉淀在历史图片库里，prompt 反而可以极简。",
      "10、判断图片好坏的标准：干净 > 脏乱，饱和 > 灰暗，主体突出 > 细节堆砌。Lucas 说「脏兮兮的纹理」让人看着累，深色网站需要封面「跳出来」，所以选高饱和度、干净背景。这些直觉可以变成 Claude 筛选的规则。",
      "11、不用在乎底层是什么工具，只在乎产出是否让你骄傲。Kiran 问 Lucas：「如果不是 Midjourney 而是微调模型，你介意吗？」Lucas 说不介意，他们用 Midjourney 只是因为它目前最稳定可靠，换别的能达到同样质量也行。",
      "12、Claude 可以「在后台干活」，你另开一个 Tab 做别事。这改变了人和 AI 协作的模式——以前必须盯着，现在可以让它跑一批图，你回来挑最好的。「踢个球回来看结果」vs「实时来回对话」。"
    ],
    "highlights": [
      "断断续续看完了 Every 团队的 Think Week 直播，干货很多。Lucas Crespo 是 Every 的创意总监，每天给文章做封面图——听起来简单，但他们网站的图风格非常统一，一眼就认得出来。",
      "这次他们尝试用 Claude 来「学会」设计师的眼光。赠人玫瑰，手有余香。",
      "下面是 YouTube 链接：https://www.youtube.com/watch?v=BI0XW1gkKXM"
    ],
    "fullText": "今天看到 Every 团队 Think Week 的直播，Lucas Crespo 和 Kiran 演示如何用 Claude 自动化封面图片创作。\nLucas 是 Every 的创意总监，负责每天为文章创作封面图。他们团队每天发布一篇文章，每张封面都是定制的，使用 Midjourney 配合自定义风格库。这次在巴拿马的 Think Week，他们尝试用 Claude 控制浏览器来自动化这个流程。\n这期视频总共录了约 20 分钟，Lucas 和 Kiran 谈到了 12 个有趣的观点：\n1、Prompt 越短越好，风格让 Mood Board 来干重活。Lucas 说他们的 prompt 现在控制在 10 个词以内，因为已经积累了足够多的图片风格参考，模型自己能理解。一个词对不同人意味着不同的画面，所以用图片参考比用文字描述更精准。\n2、读文章找视觉隐喻，但要避免字面翻译。文章讲工程师不能直接画个工程师，要「再往深挖一层」。比如 Cursor 那篇文章，他们用「交响乐指挥」来隐喻 vibe coding——你不是在演奏一件乐器，而是在协调整个交响乐团。\n3、先穷举所有烂点子，才能找到好点子。Lucas 的流程是先把「low hanging fruit」（显而易见的想法）全部列出来、扔掉，然后才开始认真创作。这和写作的「先写垃圾初稿」逻辑相似。\n4、Agent 工作流就像新员工入职——开始会犯很多错。Lucas 说这感觉很熟悉，就像带新人：会做错很多次，但你是在为未来投资，不用每天每周重复同样的工作。\n5、「这是我的工作，如果 Agent 能做，我的价值在哪？」Lucas 直接说出了这个焦虑，但转念一想：如果不用做日常图片，就有时间做更有影响力的工作——定义风格、探索新方向。\n6、Skill 是文本文件，可以像传代码一样 AirDrop 分享。Kiran 演示了 Claude 的 Skill 机制：一个 MD 文件就是一个工作流，本地化、可分享、不需要 API Key，只要对方浏览器登录了 Midjourney 就能用。\n7、用 Mono Logue 向 Claude 「碎碎念」来捕捉审美直觉。Lucas 说审美和主观判断很难用语言精确表达，但你可以对着话筒自言自语，让 Claude 从中提取模式。「让模型理解你的直觉」比精心措辞 prompt 更有效。\n8、图片需要居中构图因为网站会裁成正方形。Lucas 说 Midjourney 不像推理模型，你说「居中」它不一定听。解决方案是加一步用 Nano Banana（图像编辑 API）后处理——Claude 可以调用它的 Skill 来自动裁图。\n9、风格统一靠 Profile Code，不靠精心写的 prompt。他们有一个 Midjourney 风格码（类似 bitly 短链接），每次生成都附加这个码。风格沉淀在历史图片库里，prompt 反而可以极简。\n10、判断图片好坏的标准：干净 > 脏乱，饱和 > 灰暗，主体突出 > 细节堆砌。Lucas 说「脏兮兮的纹理」让人看着累，深色网站需要封面「跳出来」，所以选高饱和度、干净背景。这些直觉可以变成 Claude 筛选的规则。\n11、不用在乎底层是什么工具，只在乎产出是否让你骄傲。Kiran 问 Lucas：「如果不是 Midjourney 而是微调模型，你介意吗？」Lucas 说不介意，他们用 Midjourney 只是因为它目前最稳定可靠，换别的能达到同样质量也行。\n12、Claude 可以「在后台干活」，你另开一个 Tab 做别事。这改变了人和 AI 协作的模式——以前必须盯着，现在可以让它跑一批图，你回来挑最好的。「踢个球回来看结果」vs「实时来回对话」。\n断断续续看完了 Every 团队的 Think Week 直播，干货很多。Lucas Crespo 是 Every 的创意总监，每天给文章做封面图——听起来简单，但他们网站的图风格非常统一，一眼就认得出来。\n这次他们尝试用 Claude 来「学会」设计师的眼光。赠人玫瑰，手有余香。\n下面是 YouTube 链接：https://www.youtube.com/watch?v=BI0XW1gkKXM\nKiran：你们现在的工作流是什么样的？\nLucas：我们 prompt 控制在 10 个词以内，非常简单。因为我们已经积累了大量的图片参考，全放在 Midjourney 的 mood board 里。以前我们会手写很多形容词——「噪点」「希腊罗马风」「新古典」——现在完全不需要，模型自己能从参考图理解。\n而且，「大」这个词对你和对我的画面感可能完全不同。图片参考比文字更精准。\n这太有意思了。这意味着「风格」可以沉淀成资产，而不是每次从零开始 prompt 工程。\nKiran：看到文章后你怎么想画面？\nLucas：关键是不能太 on-the-nose（字面）。如果文章讲工程师，我不能真画个工程师。要往深挖。\n比如那篇 Cursor 的文章讲 AI 编程，我们用了「交响乐指挥」的隐喻——你不是在弹一件乐器，你在协调整个交响乐团。prompt 就写「orchestra conductor, opera」之类的词，几个词搞定。\nKiran：所以 Claude 的工作是：读文章 → 提取隐喻 → 生成简短 prompt？\nLucas：对，这是我们想自动化的部分。我读起来可能几分钟就有灵感，但如果 Claude 能做到 80%，我就只用审核和微调。\nLucas：说实话，看它自动做这些有点吓人 (scary)。因为这就是我的工作啊，如果 agent 能做，我的价值在哪？\n但转念一想——这也是这次 Think Week 的主题：把自己从日常杂活里解放出来，做更有影响力的事。如果不用每天做封面图，我可以去定义整个视觉系统、探索新方向。\nKiran：对，而且这就像带新员工。开始肯定错很多次，但你是在为未来投资。\n这个类比太好了。培训新人的痛苦谁都经历过，但你知道最终能把自己从重复劳动里解放出来。\nKiran：我给你演示一下怎么创建 Skill。它就是一个 MD 文件，你可以用 AirDrop 发给别人。对方只要浏览器登录了 Midjourney，直接就能用。\nLucas：哦所以不需要 API Key 什么的？\nKiran：对，什么都不需要。Claude 控制浏览器，浏览器已经登录了 Midjourney，所以就直接能用。\n说实话我觉得这个入口特别友好。大多数人听到「自动化」就头疼，觉得要搞 API、搞代码。但「分享一个文本文件」这个心理负担小多了。\nLucas：审美这东西很主观，很难精确措辞。但你可以开着 Monologue 对着话筒自言自语，Claude 会从中提取出模式。\nKiran：对，你可以说「我喜欢这张因为……」「这张不行因为……」，然后让 Claude 更新 Skill。\nLucas：天哪这太舒服了。因为我本来就很难解释为什么我觉得某张图好。让模型「听懂我的碎碎念」比逼我写清楚 prompt 容易多了。\n这让我想到 tacit knowledge（隐性知识）的传递问题。以前我们只能靠师徒制慢慢带，现在可以「录一段决策过程」让模型学习。\nKiran：你看到这一批图，脑子里在想什么？\nLucas：首先，「脏兮兮的纹理」我直接跳过。看着累。然后，我们网站是深色背景，所以需要封面「跳出来」——高饱和度、干净背景。\n其次，主体要在中心，因为缩略图会裁成 1:1。Midjourney 不一定听「居中」这个指令，它不是推理模型，更像老虎机。\nKiran：那怎么办？\nLucas：后处理。用 Nano Banana 这个图像 API 加一步裁图。Claude 可以调用它的 Skill，自动做。\n非常务实的解决方案。不是强迫一个工具做所有事，而是编排多个工具各司其职。\nKiran：如果有一天我们不用 Midjourney，用一个微调模型，你介意吗？\nLucas：完全不介意。我们用 Midjourney 只是因为它目前最稳定、参考数据最多、风格一致性好。如果别的工具能达到同样质量，换就换。\n核心是产出让不让我骄傲，让不让我愿意署名。工具只是手段。\nLucas Crespo 凭每天一张封面图，定义了 Every 极具辨识度的视觉风格。这期直播展示了他们探索「AI 能否学会设计师审美」的完整过程——从遇到的坑，到务实的解决方案。\n用他的话收个尾：「我们正在往更有影响力的工作上移，把 agent 部署出去，让他们来迭代我们的风格和品味。」\nYouTube 链接：https://www.youtube.com/watch?v=BI0XW1gkKXM\n",
    "ytTitle": "Can Al Learn our Designer's Eye?",
    "ytChannel": "Every",
    "ytChannelUrl": "https://www.youtube.com/@EveryInc",
    "ytViews": null,
    "ytPublished": null
  },
  {
    "id": "JDLtwhz3dis864k6aXqc59Oqnqb",
    "title": "Peter Steinberger X South Park Commons：给AI全部权限，80%的App会消失",
    "rawTitle": "0202：Peter Steinberger X South Park Commons：给AI全部权限，80%的App会消失",
    "dateCode": "0202",
    "youtubeId": "AcwK1Uuwc0U",
    "feishuUrl": "https://my.feishu.cn/wiki/JDLtwhz3dis864k6aXqc59Oqnqb",
    "intro": [
      "今天看到 Peter Steinberger 去了 South Park Commons 的播客。",
      "Peter Steinberger 是 PSPDFKit 的创始人——一个被超过 10 亿设备使用的 PDF 框架，做了 20 年 iOS/macOS 开发。经历严重职业倦怠后\"退休\"消失了几年，2024 年回归后用完全不同的方式创建了 OpenClaw（原名 Clawbot），一周内吸引 200 万访客。",
      "这期播客总共录了 40 分钟，Peter 谈到了 12 个有趣的观点：",
      "1、AI 就像一个住在你电脑里的聪明怪朋友。一旦你给它电脑权限，它能做任何你能做的事。Peter 在摩洛哥度假时，有人发推文报告 bug，他只是把推文截图发到 WhatsApp，AI 就自动读取推文、理解 bug、checkout 代码库、修复、提交、然后回复那个人说已修复。全程他只发了一张图。",
      "2、80% 的手机 App 会被 AI 助手取代。为什么需要 MyFitnessPal 追踪食物？AI 已经知道你在吃肯德基做了坏决定，你发张照片它就自动记录、计算卡路里、还会 roast 你该去健身房了。为什么需要航班值机 App？AI 能自己找到你 Dropbox 里的护照、提取信息、在航空公司网站上操作浏览器完成值机。",
      "3、\"Agentic Trap\"是真实存在的陷阱。很多人发现 Agent 很强，就想让它更强，然后掉进一个深坑：花大量时间构建工具来\"加速工作流\"，但最后你只是在构建工具，而不是真正推进产品。Peter 自己也陷入过，花了两个月构建 VPN 隧道让手机能访问终端，直到发现自己在餐厅和朋友吃饭时还在手机上 vibe coding，才意识到该停下来。",
      "4、编程语言不再是障碍。Peter 做了 20 年 Objective-C 和 Swift，是 Apple 生态的顶级专家。但切换到 TypeScript 时，以前需要查每个语法、感觉像个白痴。有了 AI，这些都消失了——你的系统级思维、架构能力、品味判断依然有价值，只是语言不再是限制。\"突然间我觉得我能构建任何东西，语言不重要了。\"",
      "5、Plan Mode 是 Anthropic 不得不加的 hack。因为模型太 trigger happy，一聊就想写代码跑起来。最新的模型特别是 GPT 5.2，Peter 直接和它聊天讨论：\"我想做这个功能，应该这样那样，给我几个方案。\"说\"let's discuss\"或\"give me options\"，模型就会老老实实讨论而不是动手。根本不需要 Plan Mode。",
      "6、不用 MCP、不用 work trees、不用复杂编排系统。Peter 认为这些都是\"unneeded complexity\"。他的方法极其简单：开 5 个终端窗口分屏，每个 checkout 一份代码库（clawbot-1、clawbot-2...），哪个空闲就用哪个。有的在探索、有的在构建、有的在修 bug。就像管理一个小工厂。",
      "7、PR 应该叫\"Prompt Requests\"而不是\"Pull Requests\"。很多非技术人员开始给他发 PR，代码质量参差不齐，但 Peter 把 PR 当作理解意图的 prompt——提取出他们想做什么，然后自己重写或让 AI 重写。意图比代码更重要。",
      "8、AI 有持久记忆并会自我更新，越用越强大。Peter 的 bot 会学习关于他的一切并自己更新记忆。第一次做某件事可能需要引导，但它会创建一个 skill 并记住。下次办理航班值机只需要两分钟，因为它记住了网站的所有怪癖。",
      "9、从 1 小时的 hack 到 30 万行代码。最初只是把 WhatsApp 连到 Claude Code，发消息就执行命令返回结果，一小时搞定。然后它有了自己的生命，现在支持地球上几乎所有聊天平台。300,000 行代码，起点只是\"我想在吃饭时能从手机查看我的 agent\"。",
      "10、航班值机是 AI 的终极测试。航空公司网站是出了名的难用，反爬虫措施严格。AI 要在 Dropbox 找到护照、提取信息、填写表单、点击\"I'm a human\"按钮。第一次花了 20 分钟，Peter 看着它操作直冒汗。现在只需要几分钟，因为它真的在控制一个浏览器，行为模式和人类没有区别，反爬系统很难检测。",
      "11、学习 prompting 需要玩耍和犯错，没有捷径。很多 AI 怀疑论者的模式是：忽略一年，花一天测试，写个简单 prompt 让 Claude 做个 iPhone app，在 Linux 上发现编译不了，然后得出结论\"AI 不行\"，再忽略一年。这不是正确的学习方式。你需要真正去玩、去犯错、理解它们的推理方式，才能越来越好。",
      "12、taste 和 human-in-the-loop 才是关键，不是跑多久。很多人炫耀\"我的 agent 跑了 26 小时不停\"，Peter 说这是虚荣指标。Agent 没有品味，如果你不在 loop 里引导，如果你没有愿景，输出就是 slop。他见过有人说\"这个 app 完全是 Ralf 生成的\"，他回复说\"是的，看起来就是 Ralf 生成的\"——没有人类品味参与的设计，一眼就能看出来。"
    ],
    "highlights": [
      "断断续续，终于看完了这期 South Park Commons 和 Peter Steinberger 的访谈。",
      "干货很多。Peter 可能是目前最会用 AI 的独立开发者之一——不是那种写教程教别人的，是真的把 AI 接入了生活的方方面面，然后把这套系统开源出来的人。",
      "他之前创建的 PSPDFKit 被 10 亿设备使用，做了 20 年 iOS 开发，然后职业倦怠退休了。回来后用一小时把 WhatsApp 连到 Claude Code，这个 hack 项目现在变成了 30 万行代码的 OpenClaw。",
      "我今天不忙，把这次访谈精编出来。赠人玫瑰，手有余香。",
      "下面是 YouTube 链接：https://www.youtube.com/watch?v=AcwK1Uuwc0U",
      "#01 OpenClaw 的诞生：从一小时 hack 到 30 万行代码",
      "主持人：能不能先介绍一下 Clawbot 是什么？为什么是个龙虾？",
      "Peter：我退休回来后，想有个方法能从手机上查看我电脑上的 agent 在干嘛。因为 vibe coding 的时候，agent 可能跑半小时，也可能 2 分钟就停下来问问题，你回去一看很烦躁。我以为大厂会做这个，等到 11 月还没人做，我就自己搞了个小东西。",
      "最初就是把 WhatsApp 连到 Claude Code。发消息，它就执行命令返回结果。一小时搞定。然后它有了自己的生命，现在是 30 万行代码，支持地球上几乎所有聊天平台。",
      "这个产品形态太有意思了。本质上就是把 Claude Code 变成你的微信好友，随时随地聊天指挥它干活。",
      "#02 摩洛哥修 bug 事件：截图发 WhatsApp，AI 全自动处理",
      "主持人：你说你在摩洛哥用这个东西？",
      "Peter：我在摩洛哥过生日旅行的时候，发现自己一直在用这个东西。问路、找餐厅推荐。有天早上有人发推文报告我项目的一个 bug，我就把推文截图发到 WhatsApp。",
      "它读取了推文，理解有个 bug，checkout 了代码库，修复了，commit 了，然后回复那个人说已修复。我全程只发了一张图。",
      "主持人：天哪。",
      "Peter：还有一次我走在路上，没想就发了条语音消息。我没有写语音支持。它显示\"正在输入\"，我想这下完蛋了。结果它回复了，就像什么都没发生。",
      "我问它怎么做到的。它说：\"我看到一个文件但没有扩展名，我查了文件头发现是音频格式，在你电脑上找到了 ffmpeg 转成 wav，没找到 whisper.cpp 但找到了你的 OpenAI key，用 curl 发到 API 拿到转写，然后回复你了。\"",
      "这太离谱了。这些东西太 resourceful 了，虽然有点吓人。",
      "#03 80% 的 App 会消失",
      "Peter：如果你仔细想想，这会让你手机上 80% 的 app 消失。"
    ],
    "fullText": "今天看到 Peter Steinberger 去了 South Park Commons 的播客。\nPeter Steinberger 是 PSPDFKit 的创始人——一个被超过 10 亿设备使用的 PDF 框架，做了 20 年 iOS/macOS 开发。经历严重职业倦怠后\"退休\"消失了几年，2024 年回归后用完全不同的方式创建了 OpenClaw（原名 Clawbot），一周内吸引 200 万访客。\n这期播客总共录了 40 分钟，Peter 谈到了 12 个有趣的观点：\n1、AI 就像一个住在你电脑里的聪明怪朋友。一旦你给它电脑权限，它能做任何你能做的事。Peter 在摩洛哥度假时，有人发推文报告 bug，他只是把推文截图发到 WhatsApp，AI 就自动读取推文、理解 bug、checkout 代码库、修复、提交、然后回复那个人说已修复。全程他只发了一张图。\n2、80% 的手机 App 会被 AI 助手取代。为什么需要 MyFitnessPal 追踪食物？AI 已经知道你在吃肯德基做了坏决定，你发张照片它就自动记录、计算卡路里、还会 roast 你该去健身房了。为什么需要航班值机 App？AI 能自己找到你 Dropbox 里的护照、提取信息、在航空公司网站上操作浏览器完成值机。\n3、\"Agentic Trap\"是真实存在的陷阱。很多人发现 Agent 很强，就想让它更强，然后掉进一个深坑：花大量时间构建工具来\"加速工作流\"，但最后你只是在构建工具，而不是真正推进产品。Peter 自己也陷入过，花了两个月构建 VPN 隧道让手机能访问终端，直到发现自己在餐厅和朋友吃饭时还在手机上 vibe coding，才意识到该停下来。\n4、编程语言不再是障碍。Peter 做了 20 年 Objective-C 和 Swift，是 Apple 生态的顶级专家。但切换到 TypeScript 时，以前需要查每个语法、感觉像个白痴。有了 AI，这些都消失了——你的系统级思维、架构能力、品味判断依然有价值，只是语言不再是限制。\"突然间我觉得我能构建任何东西，语言不重要了。\"\n5、Plan Mode 是 Anthropic 不得不加的 hack。因为模型太 trigger happy，一聊就想写代码跑起来。最新的模型特别是 GPT 5.2，Peter 直接和它聊天讨论：\"我想做这个功能，应该这样那样，给我几个方案。\"说\"let's discuss\"或\"give me options\"，模型就会老老实实讨论而不是动手。根本不需要 Plan Mode。\n6、不用 MCP、不用 work trees、不用复杂编排系统。Peter 认为这些都是\"unneeded complexity\"。他的方法极其简单：开 5 个终端窗口分屏，每个 checkout 一份代码库（clawbot-1、clawbot-2...），哪个空闲就用哪个。有的在探索、有的在构建、有的在修 bug。就像管理一个小工厂。\n7、PR 应该叫\"Prompt Requests\"而不是\"Pull Requests\"。很多非技术人员开始给他发 PR，代码质量参差不齐，但 Peter 把 PR 当作理解意图的 prompt——提取出他们想做什么，然后自己重写或让 AI 重写。意图比代码更重要。\n8、AI 有持久记忆并会自我更新，越用越强大。Peter 的 bot 会学习关于他的一切并自己更新记忆。第一次做某件事可能需要引导，但它会创建一个 skill 并记住。下次办理航班值机只需要两分钟，因为它记住了网站的所有怪癖。\n9、从 1 小时的 hack 到 30 万行代码。最初只是把 WhatsApp 连到 Claude Code，发消息就执行命令返回结果，一小时搞定。然后它有了自己的生命，现在支持地球上几乎所有聊天平台。300,000 行代码，起点只是\"我想在吃饭时能从手机查看我的 agent\"。\n10、航班值机是 AI 的终极测试。航空公司网站是出了名的难用，反爬虫措施严格。AI 要在 Dropbox 找到护照、提取信息、填写表单、点击\"I'm a human\"按钮。第一次花了 20 分钟，Peter 看着它操作直冒汗。现在只需要几分钟，因为它真的在控制一个浏览器，行为模式和人类没有区别，反爬系统很难检测。\n11、学习 prompting 需要玩耍和犯错，没有捷径。很多 AI 怀疑论者的模式是：忽略一年，花一天测试，写个简单 prompt 让 Claude 做个 iPhone app，在 Linux 上发现编译不了，然后得出结论\"AI 不行\"，再忽略一年。这不是正确的学习方式。你需要真正去玩、去犯错、理解它们的推理方式，才能越来越好。\n12、taste 和 human-in-the-loop 才是关键，不是跑多久。很多人炫耀\"我的 agent 跑了 26 小时不停\"，Peter 说这是虚荣指标。Agent 没有品味，如果你不在 loop 里引导，如果你没有愿景，输出就是 slop。他见过有人说\"这个 app 完全是 Ralf 生成的\"，他回复说\"是的，看起来就是 Ralf 生成的\"——没有人类品味参与的设计，一眼就能看出来。\n断断续续，终于看完了这期 South Park Commons 和 Peter Steinberger 的访谈。\n干货很多。Peter 可能是目前最会用 AI 的独立开发者之一——不是那种写教程教别人的，是真的把 AI 接入了生活的方方面面，然后把这套系统开源出来的人。\n他之前创建的 PSPDFKit 被 10 亿设备使用，做了 20 年 iOS 开发，然后职业倦怠退休了。回来后用一小时把 WhatsApp 连到 Claude Code，这个 hack 项目现在变成了 30 万行代码的 OpenClaw。\n我今天不忙，把这次访谈精编出来。赠人玫瑰，手有余香。\n下面是 YouTube 链接：https://www.youtube.com/watch?v=AcwK1Uuwc0U\n#01 OpenClaw 的诞生：从一小时 hack 到 30 万行代码\n主持人：能不能先介绍一下 Clawbot 是什么？为什么是个龙虾？\nPeter：我退休回来后，想有个方法能从手机上查看我电脑上的 agent 在干嘛。因为 vibe coding 的时候，agent 可能跑半小时，也可能 2 分钟就停下来问问题，你回去一看很烦躁。我以为大厂会做这个，等到 11 月还没人做，我就自己搞了个小东西。\n最初就是把 WhatsApp 连到 Claude Code。发消息，它就执行命令返回结果。一小时搞定。然后它有了自己的生命，现在是 30 万行代码，支持地球上几乎所有聊天平台。\n这个产品形态太有意思了。本质上就是把 Claude Code 变成你的微信好友，随时随地聊天指挥它干活。\n#02 摩洛哥修 bug 事件：截图发 WhatsApp，AI 全自动处理\n主持人：你说你在摩洛哥用这个东西？\nPeter：我在摩洛哥过生日旅行的时候，发现自己一直在用这个东西。问路、找餐厅推荐。有天早上有人发推文报告我项目的一个 bug，我就把推文截图发到 WhatsApp。\n它读取了推文，理解有个 bug，checkout 了代码库，修复了，commit 了，然后回复那个人说已修复。我全程只发了一张图。\n主持人：天哪。\nPeter：还有一次我走在路上，没想就发了条语音消息。我没有写语音支持。它显示\"正在输入\"，我想这下完蛋了。结果它回复了，就像什么都没发生。\n我问它怎么做到的。它说：\"我看到一个文件但没有扩展名，我查了文件头发现是音频格式，在你电脑上找到了 ffmpeg 转成 wav，没找到 whisper.cpp 但找到了你的 OpenAI key，用 curl 发到 API 拿到转写，然后回复你了。\"\n这太离谱了。这些东西太 resourceful 了，虽然有点吓人。\n#03 80% 的 App 会消失\nPeter：如果你仔细想想，这会让你手机上 80% 的 app 消失。\n为什么需要 MyFitnessPal 追踪食物？我有一个无限 resourceful 的助手，它已经知道我在吃肯德基做了坏决定。我发张照片，它就存到数据库、计算卡路里、roast 我该去健身房因为超了热量上限。\n为什么需要 app 控制我的 Eight Sleep 床温？它有 API 访问权限，直接帮我做。为什么需要 to-do app？它帮我追踪。为什么需要航班值机 app？它帮我办。\n这个交互方式太方便了，我只是和一个朋友聊天。因为它有那么多上下文，不需要那么多专门的 prompting。\n我觉得今年会有很多人开始探索这个，慢慢从大公司那里拿到自己的 AI 助手。一年后我不知道会怎样，但会有一整层 app 慢慢融化掉。\n#04 全屋接入：邮件、日历、灯光、相机、床温、密码库\n主持人：你都接入了什么？\nPeter：我接入了几乎所有东西。它能读我的邮件、日历、访问所有文件、控制我的 Philips Hue 灯、控制 Sonos 音响。我可以让它早上叫我起床，慢慢调高音量。\n它能访问我的摄像头。有次我让它\"watch for strangers\"，早上它告诉我\"Peter 有人！\"它盯了一整夜，不停截图我的沙发，因为摄像头模糊，它觉得沙发上坐着一个陌生人。\n在维也纳的家，它还能控制我的门锁。理论上它可以把我锁在门外，就像 2001 太空漫游里的 HAL。\n这些是怎么接入的？就是让 AI 自己写。它会 Google API、找你系统里的 key、自己写集成。有人用它在 Tesco 购物、在 Amazon 下单。\n#05 航班值机：AI 的终极测试\nPeter：我让它帮我办理英航的航班值机。这个我觉得是图灵测试之外的真正测试——操控浏览器在航空公司网站上值机，简直是终极挑战。\n第一次花了将近 20 分钟，当时还在摩洛哥，一切都很粗糙。它得在我文件系统里找到护照——在 Dropbox 上找到的——提取信息，填写所有表单，最后终于办成了。我看着它操作直冒汗。\n主持人：天哪。\nPeter：现在只需要几分钟。它直接点那些\"I'm a human\"验证，因为它真的在控制一个浏览器，有自己的小电脑在那边点来点去。行为模式和人类没有区别，反爬系统很难检测。\n#06 Agentic Trap：构建工具的陷阱\n主持人：你怎么看现在 X 上那些复杂的 workflow、skills、编排系统？\nPeter：我管这叫\"Agentic Trap\"。人们发现 agent 很强，觉得如果能更强就更好，然后掉进深坑。花大量时间构建工具来\"加速工作流\"，但最后只是在构建工具，不是在构建真正推进你的产品。\n我自己也陷入过。我花了两个月构建 VPN 隧道让手机能访问终端，做得太好了，以至于我在餐厅和朋友吃饭时还在手机上 vibe coding，不参与对话。我意识到必须停下来，更多是为了心理健康。\n现在你能构建任何东西，但你仍然需要 idea。我看到太多 Claude Code 管理器、Codex 编排器、各种小工具，它们给你\"更高效\"的错觉，但其实不是。\n最新那个叫 Gastown 的东西——一个复杂的编排系统，跑 10-20 个 agent 同时运行互相对话，还有 watchers、overseers、一个 mayor...我管它叫 Slop Town。还有 Ralf，你给 AI 一个小任务然后循环跑，跑完一个就清空上下文重新开始，终极 token 燃烧机。\n#07 Plan Mode 是个 hack\n主持人：你用 Plan Mode 吗？\nPeter：我的玩笑是，Plan Mode 是 Anthropic 不得不加的 hack，因为模型太 trigger happy，一聊就想跑代码。\n最新的模型，特别是 GPT 5.2，我就直接和它聊天。\"我想做这个功能，应该有这些这些，我喜欢这个设计，give me options，let's discuss。\"然后我们就讨论，",
    "ytTitle": "How OpenClaw's Creator Uses AI to Run His Life in 40 Minutes | Peter Steinberger",
    "ytChannel": "Peter Yang",
    "ytChannelUrl": "https://www.youtube.com/@PeterYangYT",
    "ytViews": null,
    "ytPublished": null
  },
  {
    "id": "HnZxwYXOqitAVZkykuxcd49hnLg",
    "title": "AI2025技术趋势深度对话",
    "rawTitle": "0201-AI2025技术趋势深度对话",
    "dateCode": "0201",
    "youtubeId": null,
    "feishuUrl": "https://my.feishu.cn/wiki/HnZxwYXOqitAVZkykuxcd49hnLg",
    "intro": [
      "> 嘉宾: Sebastian Raschka（LLM研究员、作家）& Nathan Lambert（AI研究员）\n> 主题: 2025-2026年AI技术趋势、开源与闭源之争、AGI前景\n> 时长: 约4小时"
    ],
    "highlights": [
      "注：本文基于Lex Fridman Podcast #490的完整文字稿整理，原对话为英文，本文内容已根据理解进行翻译和整理。"
    ],
    "fullText": "> 嘉宾: Sebastian Raschka（LLM研究员、作家）& Nathan Lambert（AI研究员）\n> 主题: 2025-2026年AI技术趋势、开源与闭源之争、AGI前景\n> 时长: 约4小时\n两位顶尖AI研究员的4小时深度对话，信息量巨大。以下是我提炼的10个核心洞察：\n1、DeepSeek R1的真正意义不在于它有多强,而在于它证明了\"开放权重模型可以逼近前沿\"——这改变了整个AI竞争格局\n2、AI训练不再只是\"预训练\"一个阶段,现在是三阶段体系:预训练→中期训练→后期训练,每个阶段都有巨大的创新空间\n3、Nathan的关键观察:\"Claude 3.5 Opus没发布,是因为它太强了\" ——暗示前沿实验室内部已经有了我们没见过的能力\n4、如何判断AI编程助手的好坏？Sebastian:不是看它第一次生成代码对不对,而是看当你指出问题后,它能不能理解并真正改进\n5、关于中国AI的996文化,Nathan的隐忧:这让中国团队能更快迭代,但长期来看可能导致人才流失——硅谷需要警惕自满\n6、RLHF不是万能药——它只是告诉模型\"什么是好的\",而不是\"如何变得更好\"——这是为什么单靠人类反馈无法到达AGI\n7、Sebastian认为教育AI最被低估:\"AI不应该直接给答案,应该引导人思考\"——这违背了当前所有AI产品的设计逻辑\n8、开源模型的真正价值不是省钱，而是让研究者能真正理解模型内部发生了什么——闭源API永远做不到这一点\n9、关于AGI时间线,两人观点分歧:Nathan认为2-3年内可能有超人级编程AI;Sebastian更保守,认为\"通用\"才是真正难点\n10、最深刻的一句话来自Nathan:\"我们建AI的人,历史上从来不想做'说服人'的工作——但这恰恰是现在最需要做的\"\n我的思考: 这期播客最大的价值不是预测未来,而是揭示了AI发展背后的真实张力——技术突破、商业竞争、社会影响三者之间的复杂博弈。\n一场关于AI未来的坦诚对话\n这期长达4小时的Lex Fridman播客，汇集了两位风格迥异但同样深刻的AI研究者：Sebastian Raschka——以其经典著作《Python Machine Learning》闻名的学者型研究员，和Nathan Lambert——曾在HuggingFace工作、对AI政策和竞争格局有独到见解的行业观察者。\n与大多数AI播客不同的是，这期节目没有停留在表面的技术介绍或夸大的AGI预测，而是深入探讨了很多\"行业内都知道但很少公开讨论\"的话题。以下是我从中提炼的核心叙事线索。\n第一章：DeepSeek冲击波——开源为何突然变得重要\n对话的开场就直奔主题：DeepSeek R1模型的发布为何在AI社区引起如此大的震动？\nNathan给出了一个关键洞察：DeepSeek的意义不在于它比Claude或GPT更强，而在于它证明了一种可能性——用相对更少的资源，通过创新的架构设计，也能达到接近前沿的水平。\n这打破了之前\"只有拥有海量算力的大公司才能做出顶尖模型\"的共识。正如Nathan所言：\n> \"DeepSeek做对的事情是，他们在技术博客中写出了所有的细节。他们让人们看到这是可以做到的。\"\nSebastian补充了一个更微妙的观察：中国团队之所以能做到这一点，部分原因在于他们面临的约束（如无法获得最新的Nvidia芯片）反而迫使他们在算法效率上更加努力。这是一个\"约束激发创新\"的经典案例。\n但两人也对这种\"追赶式创新\"的可持续性表示担忧。Nathan直言担心中国AI领域的996工作文化：短期内这种高强度投入确实能加速进展，但长期来看可能导致最优秀的人才流失到工作生活平衡更好的地方。\n第二章：三阶段训练革命——AI开发的新范式\n这期播客最有教育意义的部分之一，是两人对现代LLM训练流程的详细解析。\nSebastian系统性地介绍了目前的\"三阶段训练\"体系：\n阶段一：预训练（Pre-training）\n• 目标：让模型学会语言的基本结构和世界知识\n• 数据：万亿级别的网页文本、书籍、代码\n• 算力需求：巨大（DeepSeek报告用了约200万GPU小时）\n• 创新空间：架构设计、注意力机制优化（如MLA、GQA）\n阶段二：中期训练（Mid-training/Continual Pre-training）\n• 目标：在通用能力基础上强化特定领域（如代码、数学、多语言）\n• 特点：这是近两年才被广泛认识到的重要阶段\n• 案例：让模型在预训练后继续学习高质量代码和学术论文\n阶段三：后期训练（Post-training）\n• 包括：监督微调（SFT）、RLHF、新兴的RLVR\n• 目标：让模型学会如何回答问题，而不只是知道答案\n• 关键洞察：这个阶段的算力需求相对较小（约占总训练预算的1-5%），但对最终用户体验影响巨大\nNathan特别强调了RLVR（Reinforcement Learning from Verifiable Rewards）的兴起：\n> \"RLHF的问题在于，人类评判者只能告诉模型'这个回答比那个好'，但在复杂推理任务中，人类自己也不知道什么是正确答案。RLVR通过使用可验证的奖励信号（比如代码能否运行、数学证明是否正确）来解决这个问题。\"\n第三章：Claude 3.5 Opus之谜——前沿实验室的沉默\n对话中一个引人入胜的插曲是关于Claude 3.5 Opus——一个Anthropic宣布过但从未正式发布的模型。\nNathan提出了一个大胆的推测：Opus可能没有发布，是因为它在某些能力上已经\"太强了\"，以至于Anthropic内部对是否应该公开发布存在分歧。\n这引出了一个更广泛的话题：前沿AI实验室内部究竟发生了什么，是外界无法通过公开论文和博客了解的？\nSebastian对此保持谨慎：他认为我们不应该过度解读任何单一产品决策，因为商业考虑、工程挑战、安全评估都可能是延迟发布的原因。但他也承认，当一个公司停止分享技术细节时，这本身就是一个信号。\n第四章：编程AI的真正考验——不是第一次对，而是能否学习\nSebastian分享了他作为AI编程工具重度用户的经验，提出了一个评估框架：\n> \"真正好的AI编程助手，不是看它第一次生成的代码有多完美。因为第一次生成的代码几乎总是有问题的——这是预期之中的。关键是，当你告诉它'这里有个bug'或者'这不是我想要的'之后，它能不能真正理解你的反馈并做出有意义的改进？\"\n他给出了一个具体的对比：\n• Claude：在接收反馈后，往往能真正理解问题所在并做出针对性改进\n• 某些其他模型：会不断\"旋转\"——给出表面上不同但实质上相同错误的答案\n这个观察揭示了一个深层问题：当前的LLM在\"理解人类意图\"和\"从人类反馈中学习\"这两个能力上，差异可能比我们在基准测试中看到的更大。\n第五章：教育AI的悖论——答案太容易获得是否反而有害？\nSebastian作为大学教师，对AI在教育中的角色有独特思考。他提出了一个悖论：\n> \"最好的AI教育工具，应该是那些不直接给出答案的工具。因为学习的本质在于思考的过程，而不是知道结果。\"\n他引用了认知科学的研究：适度的\"困难\"（desirable difficulty）对于深度学习是必要的。 当学生必须自己努力思考时，他们形成的理解更深刻、更持久。而AI如果太容易地给出答案，实际上可能在损害学习效果。\nNathan对此表示认同，但也指出了现实困境：\n> \"问题是，市场上成功的AI产品，几乎都是那些让用户尽可能少费力的产品。'帮你思考'和'替你思考'之间的界限很模糊，而用户总是倾向于后者。\"\n第六章：开源的真正价值——不是省钱，而是理解\n对话多次回到开源vs闭源模型的辩论，但两人都超越了通常的\"成本\"或\"隐私\"论点。\nSebastian强调了一个常被忽视的维度：开源模型的核心价值在于可理解性。\n> \"当你使用闭源API时，模型对你来说就是一个黑箱。你可以观察输入和输出，但你永远不知道内部发生了什么。这对于研究来说是致命的——你无法真正理解模型为什么这样表现，也就无法系统性地改进它。\"\nNathan补充说，这也是为什么像DeepSeek这样的公开技术细节对学术界如此重要：\n> \"OpenAI和Anthropic现在发布的论文，往往是经过精心筛选的、不会泄露竞争优势的内容。真正重要的创新，他们不会告诉你。这就是为什么我们需要那些愿意分享一切的玩家。\"\n第七章：AGI时间线——分歧与共识\n在AGI话题上，两人展现了明显的分歧：\nNathan（更乐观）：\n• 认为在2-3年内，我们可能看到在编程任务上达到\"超人水平\"的AI\n• 强调当前进展速度的惊人——一年前我们认为不可能的事，现在已经实现\n• 定义关键里程碑：\"能在几周内完成需要顶尖工程师一年工作的任务\"\nSebastian（更谨慎）：\n• 承认窄领域的超人表现可能很快实现\n• 但质疑\"通用\"这个词——真正的通用智能需要处理开放式、未定义的问题\n• 强调了语言表面流畅与深层理解之间的差距\n不过，两人在一点上达成共识：无论我们用什么定义，接下来几年的进展将是惊人的，社会需要提前做好准备。\n第八章：被忽视的工作——AI建设者需要学会\"沟通\"\nNathan在对话尾声提出了一个发人深省的观点：\n> \"我们这些建AI的人，历史上从来都不想做'沟通'和'说服人'的工作。我们只想写代码、训练模型、发论文。但现在我意识到，如果不能帮助公众理解AI是什么、不是什么、可能带来什么影响…我们正在创造的东西可能会失控。\"\n这呼应了整期播客的一个隐含主题：技术进步正在远远超过社会理解和适应的速度。 而解决这个问题，可能比解决下一个技术突破更加重要。\n结语：镜子与窗户\nLex在结尾处做了一个优美的总结：AI就像一面镜子，让我们更好地理解自己——作为个体和作为文明。\n这期播客最大的价值，或许不在于任何具体的技术预测或产品推荐，而在于展示了两个深思熟虑的人如何在不确定性中寻找方向。他们的分歧让我们看到这些问题的复杂性，而他们的共识则提醒我们：无论技术如何发展，人类的能动性——我们对自己生活的主导权——始终是不可替代的。\n正如Sebastian所言：\n> \"AI不会自己决定要做什么。你仍然是那个告诉AI要做什么的人。它只是一个更强大的工具。真正的问题是：我们要用这个工具来做什么？\"\n这或许是这4小时对话留给我们最重要的问题。\n注：本文基于Lex Fridman Podcast #490的完整文字稿整理，原对话为英文，本文内容已根据理解进行翻译和整理。\n",
    "ytTitle": null,
    "ytChannel": null,
    "ytChannelUrl": null,
    "ytViews": null,
    "ytPublished": null
  },
  {
    "id": "SW8ywPnmUimjJqkQjdGc9leWn2c",
    "title": "DeepSeek-RLVR-GRPO",
    "rawTitle": "0201-DeepSeek-RLVR-GRPO",
    "dateCode": "0201",
    "youtubeId": "huSgnkJ7Fqc",
    "feishuUrl": "https://my.feishu.cn/wiki/SW8ywPnmUimjJqkQjdGc9leWn2c",
    "intro": [
      "今天看到 Sebastian Raschka 去了 The MAD Podcast 的播客。",
      "Sebastian Raschka 是一位机器学习研究员和教育者，著有《Build a Large Language Model (From Scratch)》和《Build a Reasoning Model (From Scratch)》等畅销技术书籍，在 AI 社区拥有广泛影响力。",
      "这期播客主要讨论了 DeepSeek 带来的范式转变，以及 RLVR（可验证奖励强化学习）和 GRPO 如何重新定义 AI 推理模型。Sebastian 谈到了以下核心观点：",
      "1、RLHF 将 GPT 提升为 ChatGPT，而 RLVR 则实现了从简单聊天模型到推理模型的第二次飞跃。两者代表了 AI 能力演进的不同阶段。",
      "2、RLVR 的核心创新在于从\"下一个token预测\"转向\"评估完整答案\"。对于数学问题，模型可以判断最终答案是否正确，而非仅依赖人类偏好判断。",
      "3、可验证奖励机制消除了对大规模人类反馈数据的依赖。任务结果可以被自动验证，大大降低了训练和部署成本。",
      "4、传统 RLHF 需要一个大型语言模型持续在循环中参与评估，而 RLVR 可以绕过这一限制，实现更高效的模型训练。",
      "5、DeepSeek 的成功证明了数据效率的重要性。用更少的数据和计算资源，也能训练出顶尖性能的模型。",
      "6、GRPO（Group Relative Policy Optimization）作为新的优化方法，相比传统 PPO 更加稳定高效，代表了强化学习训练技术的进步。",
      "7、推理模型的评估指标正在从\"人类偏好\"转向\"任务完成度\"。可验证任务（如数学、代码）成为衡量推理能力的关键标准。",
      "8、这一技术转变对 AI 应用开发者意味着：未来 AI 系统的能力边界将更多取决于任务的可验证性，而非模型规模的简单扩张。",
      "9、开源社区正在快速跟进 RLVR 技术路线。DeepSeek 的开源策略加速了整个行业的技术迭代。",
      "10、Sebastian 强调，理解这些底层技术原理对于 AI 研究者和从业者至关重要，这是把握未来技术方向的关键。"
    ],
    "highlights": [
      "断断续续看完了 Sebastian Raschka 在 The MAD Podcast 这期关于 DeepSeek 的讨论。",
      "干货很多。Sebastian 可能是当前最能把这波 AI 推理技术讲清楚的学者之一。他那两本\"从零构建\"系列书籍，我身边做 AI 的朋友几乎人手一本。",
      "这期播客大概 30 多分钟，主要聊了 RLVR 和 GRPO 这两个技术点。主持人 Matt Turck 开门见山：DeepSeek 到底意味着什么？为什么业内称之为\"DeepSeek 时刻\"？",
      "Sebastian 的回答很清晰：RLHF 是第一次飞跃，让大模型从单纯的文本生成变成可以对话的助手。而 RLVR 是第二次飞跃，让模型具备了真正的推理能力。区别在于，RLHF 本质上还是在做下一个 token 的预测，只是训练数据变成了人类偏好的对话。而 RLVR 直接看最终答案——数学题做对了还是错了，代码能不能运行。这种可验证的奖励信号，比人类主观评价要稳定得多。",
      "主持人追问：那这对我们做 AI 应用的人意味着什么？",
      "Sebastian 说了一个很反直觉的观点：未来 AI 能力的边界，可能更多取决于任务本身能不能被验证，而不是模型有多大。数学、代码、逻辑推理——这些任务的结果是可以明确判断的，所以特别适合 RLVR 的范式。但如果是创意写作、情感陪伴这类主观性强的任务，可能还是需要传统的 RLHF。",
      "我补充一下背景。DeepSeek 之所以引起轰动，是因为他们用相对有限的资源，做出了和 OpenAI o1 级别相当的推理模型。而且他们开源了部分技术细节，这在业内很少见。Sebastian 在播客里也提到了这点——开源社区正在快速跟进这条技术路线。",
      "Sebastian 分享了一个技术细节：传统的 PPO 训练强化学习模型很复杂，需要很多技巧才能稳定收敛。但 GRPO 简化了这个过程，用组内相对评分来代替全局价值函数，训练更稳，效果更好。",
      "主持人问了一个我也很关心的问题：对于普通开发者来说，现在应该关注什么？",
      "Sebastian 的建议是：如果你在做 AI 应用，关注任务的可验证性设计；如果你在做模型研究，RLVR 和 GRPO 这两个方向值得深入。他说得很直接：理解底层原理，比会调 API 重要得多。",
      "最后主持人问，DeepSeek 之后，AI 领域下一个大事件会是什么？",
      "Sebastian 笑着说不知道，但如果让他猜，可能是多模态推理的突破——让模型不仅能推理文字，还能推理图像、视频和3D空间。",
      "这期访谈信息密度很高，建议结合 Sebastian 的书一起看，理解会更深。"
    ],
    "fullText": "今天看到 Sebastian Raschka 去了 The MAD Podcast 的播客。\nSebastian Raschka 是一位机器学习研究员和教育者，著有《Build a Large Language Model (From Scratch)》和《Build a Reasoning Model (From Scratch)》等畅销技术书籍，在 AI 社区拥有广泛影响力。\n这期播客主要讨论了 DeepSeek 带来的范式转变，以及 RLVR（可验证奖励强化学习）和 GRPO 如何重新定义 AI 推理模型。Sebastian 谈到了以下核心观点：\n1、RLHF 将 GPT 提升为 ChatGPT，而 RLVR 则实现了从简单聊天模型到推理模型的第二次飞跃。两者代表了 AI 能力演进的不同阶段。\n2、RLVR 的核心创新在于从\"下一个token预测\"转向\"评估完整答案\"。对于数学问题，模型可以判断最终答案是否正确，而非仅依赖人类偏好判断。\n3、可验证奖励机制消除了对大规模人类反馈数据的依赖。任务结果可以被自动验证，大大降低了训练和部署成本。\n4、传统 RLHF 需要一个大型语言模型持续在循环中参与评估，而 RLVR 可以绕过这一限制，实现更高效的模型训练。\n5、DeepSeek 的成功证明了数据效率的重要性。用更少的数据和计算资源，也能训练出顶尖性能的模型。\n6、GRPO（Group Relative Policy Optimization）作为新的优化方法，相比传统 PPO 更加稳定高效，代表了强化学习训练技术的进步。\n7、推理模型的评估指标正在从\"人类偏好\"转向\"任务完成度\"。可验证任务（如数学、代码）成为衡量推理能力的关键标准。\n8、这一技术转变对 AI 应用开发者意味着：未来 AI 系统的能力边界将更多取决于任务的可验证性，而非模型规模的简单扩张。\n9、开源社区正在快速跟进 RLVR 技术路线。DeepSeek 的开源策略加速了整个行业的技术迭代。\n10、Sebastian 强调，理解这些底层技术原理对于 AI 研究者和从业者至关重要，这是把握未来技术方向的关键。\n断断续续看完了 Sebastian Raschka 在 The MAD Podcast 这期关于 DeepSeek 的讨论。\n干货很多。Sebastian 可能是当前最能把这波 AI 推理技术讲清楚的学者之一。他那两本\"从零构建\"系列书籍，我身边做 AI 的朋友几乎人手一本。\n这期播客大概 30 多分钟，主要聊了 RLVR 和 GRPO 这两个技术点。主持人 Matt Turck 开门见山：DeepSeek 到底意味着什么？为什么业内称之为\"DeepSeek 时刻\"？\nSebastian 的回答很清晰：RLHF 是第一次飞跃，让大模型从单纯的文本生成变成可以对话的助手。而 RLVR 是第二次飞跃，让模型具备了真正的推理能力。区别在于，RLHF 本质上还是在做下一个 token 的预测，只是训练数据变成了人类偏好的对话。而 RLVR 直接看最终答案——数学题做对了还是错了，代码能不能运行。这种可验证的奖励信号，比人类主观评价要稳定得多。\n主持人追问：那这对我们做 AI 应用的人意味着什么？\nSebastian 说了一个很反直觉的观点：未来 AI 能力的边界，可能更多取决于任务本身能不能被验证，而不是模型有多大。数学、代码、逻辑推理——这些任务的结果是可以明确判断的，所以特别适合 RLVR 的范式。但如果是创意写作、情感陪伴这类主观性强的任务，可能还是需要传统的 RLHF。\n我补充一下背景。DeepSeek 之所以引起轰动，是因为他们用相对有限的资源，做出了和 OpenAI o1 级别相当的推理模型。而且他们开源了部分技术细节，这在业内很少见。Sebastian 在播客里也提到了这点——开源社区正在快速跟进这条技术路线。\nSebastian 分享了一个技术细节：传统的 PPO 训练强化学习模型很复杂，需要很多技巧才能稳定收敛。但 GRPO 简化了这个过程，用组内相对评分来代替全局价值函数，训练更稳，效果更好。\n主持人问了一个我也很关心的问题：对于普通开发者来说，现在应该关注什么？\nSebastian 的建议是：如果你在做 AI 应用，关注任务的可验证性设计；如果你在做模型研究，RLVR 和 GRPO 这两个方向值得深入。他说得很直接：理解底层原理，比会调 API 重要得多。\n最后主持人问，DeepSeek 之后，AI 领域下一个大事件会是什么？\nSebastian 笑着说不知道，但如果让他猜，可能是多模态推理的突破——让模型不仅能推理文字，还能推理图像、视频和3D空间。\n这期访谈信息密度很高，建议结合 Sebastian 的书一起看，理解会更深。\nYouTube 链接：https://www.youtube.com/watch?v=huSgnkJ7Fqc\n",
    "ytTitle": "The \"DeepSeek\" Moment- RLVR & GRPO #ai #podcast",
    "ytChannel": "The MAD Podcast with Matt Turck",
    "ytChannelUrl": "https://www.youtube.com/@DataDrivenNYC",
    "ytViews": null,
    "ytPublished": null
  },
  {
    "id": "APYXwaiXXi6ClikfX2dcn9Jznrb",
    "title": "Peter Steinberger 访谈：AI 编程革命",
    "rawTitle": "0130-Peter Steinberger 访谈：AI 编程革命",
    "dateCode": "0130",
    "youtubeId": "8lF7HmQ_RgY",
    "feishuUrl": "https://my.feishu.cn/wiki/APYXwaiXXi6ClikfX2dcn9Jznrb",
    "intro": [
      " 今天看到Peter Steinberger 去了 The Pragmatic Engineer 的播客。",
      "Peter Steinberger 创建了 PSPDF kit——一个被超过 10 亿设备使用的 PDF 框架，后来经历严重职业倦怠卖掉股份消失了 3 年。2024 年回归后，他用完全不同的方式创建了 Clawdbot，一周从 100 星涨到 3300 星。",
      "这期播客总共录了 xx 时间，xx谈到了xx个有趣的观点："
    ],
    "highlights": [
      "Peter Steinberger 凭 PSPDF kit 影响了超过 10 亿设备的 PDF 体验，现在又用完全不同的方式创建了 Clawdbot。这期访谈让我重新理解了 AI 对软件开发的影响——不是\"AI 写代码\"那么简单，而是整个工作方式的范式转变。",
      "用他的话收个尾：\"我从不喜欢写测试和文档...现在我有了有史以来文档质量最好的项目，但我自己一行都没写。\"我们正处于一个软件开发方式剧变的时刻，最好的策略是保持好奇、拥抱变化、不断练习。",
      "YouTube 链接：https://www.youtube.com/watch?v=8lF7HmQ_RgY"
    ],
    "fullText": " 今天看到Peter Steinberger 去了 The Pragmatic Engineer 的播客。\nPeter Steinberger 创建了 PSPDF kit——一个被超过 10 亿设备使用的 PDF 框架，后来经历严重职业倦怠卖掉股份消失了 3 年。2024 年回归后，他用完全不同的方式创建了 Clawdbot，一周从 100 星涨到 3300 星。\n这期播客总共录了 xx 时间，xx谈到了xx个有趣的观点：\nPeter Steinberger 说他现在\"一天能有 600 次提交，而且都不是垃圾代码\"。更反直觉的是——他说自己不再阅读大部分代码，但写出的代码比以前更好了。\n总结一下做个笔记👇\n关闭循环原则：AI 必须能自己调试和测试，这是区分有效 AI 编码和 vibe coding 的关键\nPR 已死：Code reviews 没意义了，他对 prompts 的兴趣比代码更大，PR 应该叫\"Prompt Requests\"\nCodex 优势：比 Claude Code 慢 10 倍，但几乎每个 prompt 都能给出正确结果\nCLI 比 MCP 好：MCP 是\"拐杖\"，CLI 可以用 jq 过滤、可以脚本化、可以链式调用\n并行工作流：同时运行 5-10 个 AI 代理，像玩星际争霸管理多个基地\n心智负担更大：不写代码了但脑力消耗更大，要同时管理多条并行工作线\n系统理解 > 语言能力：感受模型运行时间、知道何时出问题，比会某种语言更重要\n公司可能精简 30%：需要能做所有事的高能动性、高能力的人，远少于以前\nAI 自我更新：他的 bot 可以自己 fetch 和更新自己，用户说\"update yourself\"就行\n技术消失：最终体验是技术消失，你只是在和手机上的朋友对话\n新人建议：保持无限好奇，像学乐器一样需要不断尝试和练习\n主持人：你说你一天能有 600 次提交，而且不是垃圾代码？\nPeter：是的，这听起来完全疯狂，但它是有效的。有人做了代码审查说\"这实际上不是 slop\"。\n我现在写的代码比以前更好，尽管我自己不再写代码了。以前在公司，我会对每一个细节、每一个空格、每一个命名花大量时间。回头看，这有点傻——客户根本看不到代码内部。\n当然代码要达到一定标准、要能用、要快、要安全，但那些 bikeshedding 真的很蠢。\n#02 关闭循环原则\n主持人：你一直提到\"关闭循环\"，这是什么意思？\nPeter：这是让 AI 编码有效的最大秘密——AI 需要能自己验证工作。\nAI 之所以擅长编码但在写作上表现一般，是因为代码可以验证。你可以编译、lint、执行、检查输出。如果你正确设计系统，你就有了完美的循环。\n比如我做网站，我把核心设计成可以通过 CLI 运行，这样就有了完美的执行循环。浏览器循环太慢了，你需要快速循环的东西。\n我调试 Mac 应用时，让 AI 说\"你建一个纯 CLI 用于调试，调用所有相同的代码路径，你可以自己调用然后迭代修复\"。然后它就自己 cook 了一个小时，告诉我\"这里有个竞态条件，这里有个配置错误\"。\n我不需要看那些代码。但因为它运行了测试，所以我信任它。\n#03 Code Reviews 已死\n主持人：那代码审查呢？CI/CD 呢？\nPeter：我不太在乎 CI 了。我有本地 CI。我现在有点\"DAH\"（Don't Ask, Don't Tell）了。\n代理运行测试，就快得多。我不想 push 到分支然后等 10 分钟 CI。因为你已经在代理那里等了 10 分钟了。如果测试本地通过，我们就合并。\n有时候 main 会稍微滑一点，但通常很接近。代理管这个叫\"gate\"——我不知道这词哪来的。它会问\"要运行 full gate 吗？\"Full gate 就是 linting、building、checking、运行所有测试。\n我更感兴趣的是 prompts 而不是代码。我让人们请加上 prompts。我读 prompts 比读代码更多，因为这给我更高的信号——你是怎么得到这个解决方案的？问了什么？有多少引导？\n如果有人想要一个功能，我让他们写一个 prompt request。把它写好，因为然后我可以把代理指向这个 issue，它就会构建出来。\n#04 Claude Code vs Codex\n主持人：你现在用什么工具？怎么选择的？\nPeter：Claude Code 是一个开创品类的产品，对通用计算机工作非常棒，对编码也很好。但对于在复杂应用中写代码，Codex 要好太多了。\n因为它慢 10 倍。Claude 会读三个文件然后就自信地开始创建代码，你必须引导它、push 它去读更多代码，让它看到你代码库的更大图景。\n而 Codex 会静静地读文件 10 分钟。如果你只在一个终端工作，我完全理解为什么你会觉得这无法忍受。但我宁愿要一个我不用告诉它做什么的东西。\n我和模型对话。\"看看这个，我们有什么选项？\"\"你考虑过这个功能吗？\"它会探索不同方向，直到我说\"build this\"它才会构建。\n有一些触发词因为它们确实有点 trigger happy，但只要我说\"let's discuss\"或\"give me options\"，它们就不会构建任何东西。\n#05 MCP 是拐杖\n主持人：你怎么看 MCP？\nPeter：作为拐杖还行。MCP 带来的最好的事情是让公司重新思考开放更多 API。\n但整个概念有点傻。你必须预先导出所有函数、所有工具、所有解释，当你的 session 加载时。然后模型必须发送精确的 JSON blob，然后得到 JSON 回来。\n但模型真的很擅长用 bash。\n想象你有一个天气服务。模型可以请求可用城市列表，然后得到 500 个城市。但它不能过滤那个列表，因为那不是 MCP 工作的方式。然后你说\"给我伦敦的天气\"，你会得到温度、风、雨和 50 个我不感兴趣的东西。\n而如果是 CLI，它可以用 jq 过滤出它需要的东西。而且我不能链接它们、不能轻松构建脚本。\n所以我建了 make-porter，把 MCP 转换成 CLI。我的 Clawdbot 没有 MCP 支持，但通过 make-porter 你可以用任何 MCP。你可以在手机上说\"用 Vercel MCP 做这个\"，它会去网站找到 MCP、加载它、使用它——全部按需。\n#06 并行工作流\n主持人：你现在的工作流是什么样的？\nPeter：我同时运行 5-10 个代理。\n比如我在设计一个新子系统或功能，我知道 Codex 可能需要 40 分钟或 1 小时来构建。所以我想把计划搞对，然后构建，然后移动到别的东西。\n这个在 cooking，我在做那个，然后这个 cooking，那个 cooking，然后这个 cooking，然后这个 cooking，然后我回到这个。我在脑子里切换很多。\n我希望不用这样。我确信这是一个过渡期问题，某个时候我们会有足够快的模型和系统，我可以少并行一些。但要保持心流状态，我需要大规模并行化。\n主持人：这听起来像星际争霸，你有主基地和侧基地。\nPeter：完全是！它们给你资源。也像象棋大师同时下 20 盘棋——他们去那里，看一眼棋盘，做决定，对某些棋盘停留更长时间。\n#07 系统理解比语言更重要\n主持人：你怎么知道什么时候出问题了？\nPeter：我感受模型。我 prompt 时已经有预感它会花多长时间。如果花太久，我就知道我哪里搞砸了。\n这非常像共生关系。我学会了和它们说话，我的知识在使用这些东西方面提高了，模型也在提高。\n我可以构建任何东西了。以前你必须真的选择做哪个 side project，因为软件很难。现在我说\"用 Go 做 CLI\"——我对 Go 一无所知。但我有好的系统理解，一旦你有了那个，你就会发展出什么是对的什么是错的直觉。\n#08 公司会被精简\n主持人：如果今天用这些工具重建 PSPDF kit，团队会是什么样？\nPeter：我可以轻松用 30% 的人运营一个公司。\n找到那个水平的人可能相当困难，但你想要真正资深的、真正理解他们在构建什么的工程师，同时也对委派感到舒适，知道哪些部分真正重要需要处理，哪些部分可以 vibe。\n新世界需要有产品愿景的人，能够做所有事情，你需要的人远少得多，但都是非常高能动性和高能力的人。\n这很可怕，因为经济上这会导致一场灾难。很多人会在这个新世界里找不到位置。\n#09 AI 自我更新\n主持人：Clawdbot 的 onboarding 是怎么工作的？\nPeter：你不是编辑配置，因为代理可以编辑它自己的配置。你不用更新任何东西，因为代理可以更新它自己。\n你可以直接对你的 bot 说\"update yourself\"，它会 fetch 自己、更新自己、回来说\"嘿，我有新功能了\"。\n而且因为产品是由代理构建的，它们把东西结构化成代理期望的命名方式。权重里编码了某些它们期望的命名方式。所以它们真的很擅长导航这个产品。\n#10 技术消失的体验\n主持人：Clawdbot 的核心体验是什么？\nPeter：技术消失了。你只是在手机上和一个朋友对话，这个朋友无限资源丰富，能访问你的邮件、日历、文件，可以为你建网站，可以做行政工作，可以爬网站，可以给商家打电话预订。\n你不用想配置或任何上下文，那都融化掉了。我有一个记忆系统会记住东西——还不完美，但已经感觉很神奇了。\n我走在外面，看到一个活动，给 Claude 发张照片，它不仅会告诉我这个活动的评价，还会告诉我日历里是否有冲突，朋友是否谈过它。它有这么多上下文，它能给我的回复比任何活在自己小盒子里的当前工具都好太多。\n主持人：听起来你建了 Apple 希望 Siri 能做的东西。\nPeter：老实说，我建了 Anthropic 卖更多订阅的最好的营销工具。不知道多少人因为 Clawdbot 注册了 200 美元订阅。很多人已经有一个了，又因为它买了第二个，因为它太吃 token 了。\n不是说它特别吃 token，而是人们太爱它了，一直用。而且因为技术融化掉了，他们看不到它在后台生成子代理、做一大堆事情来让它感觉简单。\n#11 给新人的建议\n主持人：对刚进入这个领域的人有什么建议？\nPeter：要无限好奇。是的，进入这个市场会更难，你需要构建东西来获得经验。\n我不认为你需要写很多代码，但你需要——你知道有很多复杂的开源项目，你可以 checkout 然后学习。你有一个无限耐心的机器能解释所有事情。\n你可以问所有问题\"为什么这样构建？\"来获得系统理解。但它需要真正的好奇心。\n你必须玩这个技术然后学习。就像学乐器，开始可能很沮丧，但很快你就会变好，你感觉你的工作流变快了，然后你感觉到进步，然后你慢慢上瘾。\nPeter Steinberger 凭 PSPDF kit 影响了超过 10 亿设备的 PDF 体验，现在又用完全不同的方式创建了 Clawdbot。这期访谈让我重新理解了 AI 对软件开发的影响——不是\"AI 写代码\"那么简单，而是整个工作方式的范式转变。\n用他的话收个尾：\"我从不喜欢写测试和文档...现在我有了有史以来文档质量最好的项目，但我自己一行都没写。\"我们正处于一个软件开发方式剧变的时刻，最好的策略是保持好奇、拥抱变化、不断练习。\nYouTube 链接：https://www.youtube.com/watch?v=8lF7HmQ_RgY\n",
    "ytTitle": "The creator of Clawd: \"I ship code I don't read\"",
    "ytChannel": "The Pragmatic Engineer",
    "ytChannelUrl": "https://www.youtube.com/@pragmaticengineer",
    "ytViews": null,
    "ytPublished": null
  },
  {
    "id": "UTzxw726Tim6qXk16V0cbqSHnyc",
    "title": "Peter Steinberger X The Pragmatic Engineer：一天600次提交，代码比以前更好",
    "rawTitle": "0130：Peter Steinberger X The Pragmatic Engineer：一天600次提交，代码比以前更好",
    "dateCode": "0130",
    "youtubeId": "8lF7HmQ_RgY",
    "feishuUrl": "https://my.feishu.cn/wiki/UTzxw726Tim6qXk16V0cbqSHnyc",
    "intro": [
      "今天看到 Peter Steinberger 去了 The Pragmatic Engineer 的播客。",
      "Peter Steinberger 创建了 PSPDF kit——一个被超过 10 亿设备使用的 PDF 框架，后来经历严重职业倦怠卖掉股份消失了 3 年。2024 年回归后，他用完全不同的方式创建了 Clawdbot，一周从 100 星涨到 3300 星。",
      "这期播客总共录了将近两小时，Peter 谈到了 12 个有趣的观点：",
      "1、一天 600 次提交，代码比以前更好。这听起来疯狂，但 Peter 说他现在不再阅读大部分代码了，写出的代码却比以前更好。以前他会对每个细节、每个空格花大量时间 bikeshedding，现在回头看觉得很蠢——客户根本看不到代码内部。",
      "2、关闭循环是 AI 编码的最大秘密。AI 之所以擅长编码但在写作上表现一般，是因为代码可以验证——你可以编译、lint、执行、检查输出。如果你正确设计系统，就有了完美的循环。这就是为什么他让 AI 建一个纯 CLI 用于调试，然后让它自己迭代修复。",
      "3、Code Reviews 已死，PR 应该叫 Prompt Requests。他对 prompts 的兴趣比代码更大，因为 prompts 给的信号更高——你是怎么得到这个解决方案的？问了什么？有多少引导？如果有人想要一个功能，他让他们写好 prompt，然后把代理指向这个 issue，它就会构建出来。",
      "4、Codex 比 Claude Code 慢 10 倍，但几乎每次都对。Claude 会读三个文件然后就自信地开始创建代码，你必须引导它去读更多代码。而 Codex 会静静地读文件 10 分钟。如果你只在一个终端工作，这无法忍受。但 Peter 宁愿要一个不用告诉它做什么的东西。",
      "5、MCP 是拐杖，CLI 更高效。MCP 最大的贡献是让公司重新思考开放更多 API。但模型真的很擅长用 bash。用 MCP 你不能过滤列表、不能链式调用、不能轻松构建脚本。用 CLI 可以用 jq 过滤出需要的东西。所以他建了 make-porter 把 MCP 转换成 CLI。",
      "6、同时运行 5-10 个代理，像玩星际争霸。他设计一个新子系统，知道 Codex 需要 40 分钟构建，就移动到别的东西。这个在 cooking，那个在 cooking，然后回到这个。要保持心流状态，必须大规模并行化。他希望不用这样，但这是过渡期问题。",
      "7、系统理解比语言能力更重要。他说\"用 Go 做 CLI\"——对 Go 一无所知。但有好的系统理解，就能发展出什么是对的什么是错的直觉。他能感受模型运行——prompt 时已经有预感会花多长时间，如果花太久，就知道哪里搞砸了。",
      "8、心智负担比写代码更大。不写代码了，但脑力消耗更大，要同时管理多条并行工作线。他在脑子里不断切换：这个在 cooking，那个在 cooking，然后这个 cooking。像象棋大师同时下 20 盘棋。",
      "9、公司可能精简到 30%。新世界需要有产品愿景的人，能够做所有事情，需要的人远少得多，但都是非常高能动性和高能力的人。这很可怕，经济上会导致一场灾难，很多人会在这个新世界里找不到位置。",
      "10、AI 可以自己更新自己。你不用编辑配置，因为代理可以编辑它自己的配置。直接对 bot 说\"update yourself\"，它会 fetch 自己、更新自己、回来说\"嘿，我有新功能了\"。而且因为产品是由代理构建的，它们把东西结构化成代理期望的命名方式。",
      "11、技术消失是最终体验。你只是在手机上和一个朋友对话，这个朋友无限资源丰富，能访问你的邮件、日历、文件，可以建网站、做行政工作、爬网站、给商家打电话。你不用想配置或上下文，那都融化掉了。他说自己建了 Apple 希望 Siri 能做的东西。",
      "12、新人要保持无限好奇。进入市场会更难，你需要构建东西来获得经验。不需要写很多代码，但要 checkout 复杂的开源项目然后学习。你有一个无限耐心的机器能解释所有事情。必须玩这个技术然后学习，像学乐器，开始可能沮丧，但很快就会变好。"
    ],
    "highlights": [
      "#01 一天 600 次提交",
      "主持人：你说你一天能有 600 次提交，而且不是垃圾代码？",
      "Peter：是的，这听起来完全疯狂，但它是有效的。有人做了代码审查说\"这实际上不是 slop\"。",
      "我现在写的代码比以前更好，尽管我自己不再写代码了。以前在公司，我会对每一个细节、每一个空格、每一个命名花大量时间。回头看，这有点傻——客户根本看不到代码内部。",
      "#02 关闭循环原则",
      "主持人：你一直提到\"关闭循环\"，这是什么意思？",
      "Peter：这是让 AI 编码有效的最大秘密——AI 需要能自己验证工作。",
      "AI 之所以擅长编码但在写作上表现一般，是因为代码可以验证。你可以编译、lint、执行、检查输出。如果你正确设计系统，你就有了完美的循环。",
      "我调试 Mac 应用时，让 AI 说\"你建一个纯 CLI 用于调试，调用所有相同的代码路径，你可以自己调用然后迭代修复\"。然后它就自己 cook 了一个小时，告诉我\"这里有个竞态条件，这里有个配置错误\"。",
      "我不需要看那些代码。但因为它运行了测试，所以我信任它。",
      "#03 Code Reviews 已死",
      "主持人：那代码审查呢？CI/CD 呢？",
      "Peter：我不太在乎 CI 了。代理运行测试，就快得多。我不想 push 到分支然后等 10 分钟 CI。",
      "我更感兴趣的是 prompts 而不是代码。我让人们请加上 prompts。我读 prompts 比读代码更多，因为这给我更高的信号——你是怎么得到这个解决方案的？问了什么？有多少引导？",
      "如果有人想要一个功能，我让他们写一个 prompt request。把它写好，因为然后我可以把代理指向这个 issue，它就会构建出来。",
      "#04 Claude Code vs Codex",
      "主持人：你现在用什么工具？",
      "Peter：Claude Code 是一个开创品类的产品，对通用计算机工作非常棒。但对于在复杂应用中写代码，Codex 要好太多了。",
      "因为它慢 10 倍。Claude 会读三个文件然后就自信地开始创建代码。而 Codex 会静静地读文件 10 分钟。",
      "我和模型对话。\"看看这个，我们有什么选项？\"\"你考虑过这个功能吗？\"它会探索不同方向，直到我说\"build this\"它才会构建。"
    ],
    "fullText": "今天看到 Peter Steinberger 去了 The Pragmatic Engineer 的播客。\nPeter Steinberger 创建了 PSPDF kit——一个被超过 10 亿设备使用的 PDF 框架，后来经历严重职业倦怠卖掉股份消失了 3 年。2024 年回归后，他用完全不同的方式创建了 Clawdbot，一周从 100 星涨到 3300 星。\n这期播客总共录了将近两小时，Peter 谈到了 12 个有趣的观点：\n1、一天 600 次提交，代码比以前更好。这听起来疯狂，但 Peter 说他现在不再阅读大部分代码了，写出的代码却比以前更好。以前他会对每个细节、每个空格花大量时间 bikeshedding，现在回头看觉得很蠢——客户根本看不到代码内部。\n2、关闭循环是 AI 编码的最大秘密。AI 之所以擅长编码但在写作上表现一般，是因为代码可以验证——你可以编译、lint、执行、检查输出。如果你正确设计系统，就有了完美的循环。这就是为什么他让 AI 建一个纯 CLI 用于调试，然后让它自己迭代修复。\n3、Code Reviews 已死，PR 应该叫 Prompt Requests。他对 prompts 的兴趣比代码更大，因为 prompts 给的信号更高——你是怎么得到这个解决方案的？问了什么？有多少引导？如果有人想要一个功能，他让他们写好 prompt，然后把代理指向这个 issue，它就会构建出来。\n4、Codex 比 Claude Code 慢 10 倍，但几乎每次都对。Claude 会读三个文件然后就自信地开始创建代码，你必须引导它去读更多代码。而 Codex 会静静地读文件 10 分钟。如果你只在一个终端工作，这无法忍受。但 Peter 宁愿要一个不用告诉它做什么的东西。\n5、MCP 是拐杖，CLI 更高效。MCP 最大的贡献是让公司重新思考开放更多 API。但模型真的很擅长用 bash。用 MCP 你不能过滤列表、不能链式调用、不能轻松构建脚本。用 CLI 可以用 jq 过滤出需要的东西。所以他建了 make-porter 把 MCP 转换成 CLI。\n6、同时运行 5-10 个代理，像玩星际争霸。他设计一个新子系统，知道 Codex 需要 40 分钟构建，就移动到别的东西。这个在 cooking，那个在 cooking，然后回到这个。要保持心流状态，必须大规模并行化。他希望不用这样，但这是过渡期问题。\n7、系统理解比语言能力更重要。他说\"用 Go 做 CLI\"——对 Go 一无所知。但有好的系统理解，就能发展出什么是对的什么是错的直觉。他能感受模型运行——prompt 时已经有预感会花多长时间，如果花太久，就知道哪里搞砸了。\n8、心智负担比写代码更大。不写代码了，但脑力消耗更大，要同时管理多条并行工作线。他在脑子里不断切换：这个在 cooking，那个在 cooking，然后这个 cooking。像象棋大师同时下 20 盘棋。\n9、公司可能精简到 30%。新世界需要有产品愿景的人，能够做所有事情，需要的人远少得多，但都是非常高能动性和高能力的人。这很可怕，经济上会导致一场灾难，很多人会在这个新世界里找不到位置。\n10、AI 可以自己更新自己。你不用编辑配置，因为代理可以编辑它自己的配置。直接对 bot 说\"update yourself\"，它会 fetch 自己、更新自己、回来说\"嘿，我有新功能了\"。而且因为产品是由代理构建的，它们把东西结构化成代理期望的命名方式。\n11、技术消失是最终体验。你只是在手机上和一个朋友对话，这个朋友无限资源丰富，能访问你的邮件、日历、文件，可以建网站、做行政工作、爬网站、给商家打电话。你不用想配置或上下文，那都融化掉了。他说自己建了 Apple 希望 Siri 能做的东西。\n12、新人要保持无限好奇。进入市场会更难，你需要构建东西来获得经验。不需要写很多代码，但要 checkout 复杂的开源项目然后学习。你有一个无限耐心的机器能解释所有事情。必须玩这个技术然后学习，像学乐器，开始可能沮丧，但很快就会变好。\n#01 一天 600 次提交\n主持人：你说你一天能有 600 次提交，而且不是垃圾代码？\nPeter：是的，这听起来完全疯狂，但它是有效的。有人做了代码审查说\"这实际上不是 slop\"。\n我现在写的代码比以前更好，尽管我自己不再写代码了。以前在公司，我会对每一个细节、每一个空格、每一个命名花大量时间。回头看，这有点傻——客户根本看不到代码内部。\n#02 关闭循环原则\n主持人：你一直提到\"关闭循环\"，这是什么意思？\nPeter：这是让 AI 编码有效的最大秘密——AI 需要能自己验证工作。\nAI 之所以擅长编码但在写作上表现一般，是因为代码可以验证。你可以编译、lint、执行、检查输出。如果你正确设计系统，你就有了完美的循环。\n我调试 Mac 应用时，让 AI 说\"你建一个纯 CLI 用于调试，调用所有相同的代码路径，你可以自己调用然后迭代修复\"。然后它就自己 cook 了一个小时，告诉我\"这里有个竞态条件，这里有个配置错误\"。\n我不需要看那些代码。但因为它运行了测试，所以我信任它。\n#03 Code Reviews 已死\n主持人：那代码审查呢？CI/CD 呢？\nPeter：我不太在乎 CI 了。代理运行测试，就快得多。我不想 push 到分支然后等 10 分钟 CI。\n我更感兴趣的是 prompts 而不是代码。我让人们请加上 prompts。我读 prompts 比读代码更多，因为这给我更高的信号——你是怎么得到这个解决方案的？问了什么？有多少引导？\n如果有人想要一个功能，我让他们写一个 prompt request。把它写好，因为然后我可以把代理指向这个 issue，它就会构建出来。\n#04 Claude Code vs Codex\n主持人：你现在用什么工具？\nPeter：Claude Code 是一个开创品类的产品，对通用计算机工作非常棒。但对于在复杂应用中写代码，Codex 要好太多了。\n因为它慢 10 倍。Claude 会读三个文件然后就自信地开始创建代码。而 Codex 会静静地读文件 10 分钟。\n我和模型对话。\"看看这个，我们有什么选项？\"\"你考虑过这个功能吗？\"它会探索不同方向，直到我说\"build this\"它才会构建。\n#05 MCP 是拐杖\n主持人：你怎么看 MCP？\nPeter：作为拐杖还行。MCP 带来的最好的事情是让公司重新思考开放更多 API。但整个概念有点傻。\n模型真的很擅长用 bash。用 MCP 你不能过滤列表、不能链式调用。而如果是 CLI，它可以用 jq 过滤出它需要的东西。\n所以我建了 make-porter，把 MCP 转换成 CLI。你可以在手机上说\"用 Vercel MCP 做这个\"，它会去网站找到 MCP、加载它、使用它——全部按需。\n#06 并行工作流\n主持人：你现在的工作流是什么样的？\nPeter：我同时运行 5-10 个代理。\n比如我在设计一个新子系统，我知道 Codex 可能需要 40 分钟来构建。所以我想把计划搞对，然后构建，然后移动到别的东西。\n这个在 cooking，我在做那个，然后这个 cooking，那个 cooking。我在脑子里切换很多。要保持心流状态，我需要大规模并行化。\n主持人：这听起来像星际争霸。\nPeter：完全是！也像象棋大师同时下 20 盘棋。\n#07 公司会被精简\n主持人：如果今天用这些工具重建 PSPDF kit，团队会是什么样？\nPeter：我可以轻松用 30% 的人运营一个公司。\n新世界需要有产品愿景的人，能够做所有事情，你需要的人远少得多，但都是非常高能动性和高能力的人。\n这很可怕，因为经济上这会导致一场灾难。很多人会在这个新世界里找不到位置。\n#08 技术消失的体验\n主持人：Clawdbot 的核心体验是什么？\nPeter：技术消失了。你只是在手机上和一个朋友对话，这个朋友无限资源丰富，能访问你的邮件、日历、文件，可以为你建网站，可以做行政工作。\n你不用想配置或任何上下文，那都融化掉了。\n主持人：听起来你建了 Apple 希望 Siri 能做的东西。\nPeter：老实说，我建了 Anthropic 卖更多订阅的最好的营销工具。\n#09 给新人的建议\n主持人：对刚进入这个领域的人有什么建议？\nPeter：要无限好奇。是的，进入这个市场会更难，你需要构建东西来获得经验。\n你有一个无限耐心的机器能解释所有事情。你必须玩这个技术然后学习。就像学乐器，开始可能很沮丧，但很快你就会变好。\nPeter Steinberger 凭 PSPDF kit 影响了超过 10 亿设备的 PDF 体验，现在又用完全不同的方式创建了 Clawdbot。\n用他的话收个尾：\"我从不喜欢写测试和文档...现在我有了有史以来文档质量最好的项目，但我自己一行都没写。\"我们正处于一个软件开发方式剧变的时刻，最好的策略是保持好奇、拥抱变化、不断练习。\nYouTube 链接：https://www.youtube.com/watch?v=8lF7HmQ_RgY\n",
    "ytTitle": "The creator of Clawd: \"I ship code I don't read\"",
    "ytChannel": "The Pragmatic Engineer",
    "ytChannelUrl": "https://www.youtube.com/@pragmaticengineer",
    "ytViews": null,
    "ytPublished": null
  },
  {
    "id": "E9r9w3tPHic6Ijkn6pNceEM2nvh",
    "title": "Marc Andreessen X Lenny's Podcas：AI 对经济的影响",
    "rawTitle": "0129 Marc Andreessen X Lenny's Podcas：AI 对经济的影响",
    "dateCode": "0129",
    "youtubeId": "87Pm0SGTtN8",
    "feishuUrl": "https://my.feishu.cn/wiki/E9r9w3tPHic6Ijkn6pNceEM2nvh",
    "intro": [
      "今天看到 Marc Andreessen 去了 Lenny's Podcast。花了两个小时听完了这期播客。干货太多了。",
      "Marc Andreessen 是发明了网页浏览器、创办了 Netscape、联合创立了 a16z（全球最大 VC 之一）。他 2011 年预测\"10 年内 50 亿人用智能手机\"，实际数字是 60 亿。这次访谈信息密度极高，我把全文精编出来，按主题重新组织，供大家学习。"
    ],
    "highlights": [
      "#01 AI 是哲学家之石",
      "主持人：你怎么看 AI 这个历史性时刻？",
      "Marc：这是非常非常有历史意义的时刻。2025 可能是我职业生涯中最有趣的一年，我预计 2026 会超越它。",
      "早期科学家包括牛顿都痴迷于炼金术——把铅（最常见的）变成黄金（最稀有的）。他们花了几十年寻找\"哲学家之石\"，从未成功。",
      "现在我们有了一项技术，能把沙子变成思想。最常见的东西变成最稀有的东西。AI 就是哲学家之石。它真的就是。",
      "我觉得这个比喻太精妙了。Sand → Silicon → Thought，整个链条打通了。",
      "#02 生产力增长的反直觉真相",
      "主持人：很多人担心 AI 会导致大规模失业。",
      "Marc：这个担忧是基于对过去 80 年的不完整理解。",
      "经济学家用\"生产力增长\"来衡量技术对经济的影响。过去 50 年，美国的生产力增长实际上很低——只有 1940-1970 的一半，1870-1940 的三分之一。",
      "我们感觉技术进步很快，但统计数据说不是。如果 AI 让生产力增长翻三倍，也只是回到 1870-1930 的水平。那个时代人们觉得\"世界充满机会\"。",
      "而且还有人口下降的问题。很多国家包括中国的生育率低于 2，意味着下个世纪会人口萎缩。如果没有 AI，我们应该恐慌——经济会萎缩。AI 恰好在我们需要它的时候出现了。",
      "说实话，这个视角完全颠覆了我对\"AI 取代工作\"的认知。",
      "#03 PM/工程师/设计师的墨西哥对峙",
      "主持人：对于 PM、工程师、设计师这三个角色，你怎么看未来？",
      "Marc：我把它描述成\"墨西哥对峙\"——电影里三个人拿枪互相指着。",
      "现在每个程序员都觉得自己能当 PM 和设计师了，因为有 AI。每个 PM 觉得自己能写代码和做设计了。每个设计师也觉得自己能当 PM 和程序员了。",
      "最有趣的是——他们都是对的。AI 确实在这三件事上都做得不错。",
      "所以未来的超级人才，是能同时做这三件事的人。你的\"T 型技能\"——纵向深度 + 横向广度——变成了\"E 型\"或\"F 型\"。",
      "Scott Adams 说过：他可以是个不错的漫画家，也可以是个不错的商人。但同时懂两者，让他创造了 Dilbert——史上最成功的漫画之一。懂两件事的价值不是 2x，是指数级。"
    ],
    "fullText": "今天看到 Marc Andreessen 去了 Lenny's Podcast。花了两个小时听完了这期播客。干货太多了。\nMarc Andreessen 是发明了网页浏览器、创办了 Netscape、联合创立了 a16z（全球最大 VC 之一）。他 2011 年预测\"10 年内 50 亿人用智能手机\"，实际数字是 60 亿。这次访谈信息密度极高，我把全文精编出来，按主题重新组织，供大家学习。\nMarc Andreessen 说 AI 是人类历史上的\"哲学家之石\"——把世界上最常见的东西（沙子）转化为最稀有的东西（思想）。\n总结一下做个笔记👇\n1. 生产力悖论：过去 50 年生产力增长只有 1940-1970 的一半。我们以为技术进步很快，其实统计数据说不是\n2. 人口 + AI 时机：如果没有 AI，人口下降会导致经济萎缩。AI 恰好在我们需要它的时候出现了\n3. 墨西哥对峙：PM、工程师、设计师三个角色都认为 AI 能替代其他两个。最有趣的是——他们都是对的\n4. T 型人才升级：擅长两件事的人价值不是 2x，是指数级。Scott Adams 正因为\"懂漫画 + 懂商业\"才能创造 Dilbert\n5. 任务 vs 职位：高管以前不打字，秘书帮发邮件。现在高管自己发邮件，秘书做其他事。职位没消失，任务变了\n6. AI 医生困境：ChatGPT 可能比你的医生更好，但没有行医执照。医疗系统是卡特尔，会阻挡 AI\n7. 护城河很浅：Claude Code 只用一周半就构建了 Co-work。如果一周半能做出来，壁垒在哪？\n8. IQ 无上限：人类智商上限约 160（爱因斯坦级）。但 AI 没有生物限制，可能达到 200、250、300\n9. 信息消费策略：只读 X（实时）和老书（永恒），跳过中间的媒体。翻上周报纸，会发现预测几乎全错\n10. 编程的未来：最好的程序员现在的工作是\"同时指挥 10 个 AI bot，在浏览器之间切换，和它们争论\"\n11. 不确定性乐观：不要预测谁会赢，要对惊喜保持开放。硅谷已经成功经历了 9 代技术平台\n#01 AI 是哲学家之石\n主持人：你怎么看 AI 这个历史性时刻？\nMarc：这是非常非常有历史意义的时刻。2025 可能是我职业生涯中最有趣的一年，我预计 2026 会超越它。\n早期科学家包括牛顿都痴迷于炼金术——把铅（最常见的）变成黄金（最稀有的）。他们花了几十年寻找\"哲学家之石\"，从未成功。\n现在我们有了一项技术，能把沙子变成思想。最常见的东西变成最稀有的东西。AI 就是哲学家之石。它真的就是。\n我觉得这个比喻太精妙了。Sand → Silicon → Thought，整个链条打通了。\n#02 生产力增长的反直觉真相\n主持人：很多人担心 AI 会导致大规模失业。\nMarc：这个担忧是基于对过去 80 年的不完整理解。\n经济学家用\"生产力增长\"来衡量技术对经济的影响。过去 50 年，美国的生产力增长实际上很低——只有 1940-1970 的一半，1870-1940 的三分之一。\n我们感觉技术进步很快，但统计数据说不是。如果 AI 让生产力增长翻三倍，也只是回到 1870-1930 的水平。那个时代人们觉得\"世界充满机会\"。\n而且还有人口下降的问题。很多国家包括中国的生育率低于 2，意味着下个世纪会人口萎缩。如果没有 AI，我们应该恐慌——经济会萎缩。AI 恰好在我们需要它的时候出现了。\n说实话，这个视角完全颠覆了我对\"AI 取代工作\"的认知。\n#03 PM/工程师/设计师的墨西哥对峙\n主持人：对于 PM、工程师、设计师这三个角色，你怎么看未来？\nMarc：我把它描述成\"墨西哥对峙\"——电影里三个人拿枪互相指着。\n现在每个程序员都觉得自己能当 PM 和设计师了，因为有 AI。每个 PM 觉得自己能写代码和做设计了。每个设计师也觉得自己能当 PM 和程序员了。\n最有趣的是——他们都是对的。AI 确实在这三件事上都做得不错。\n所以未来的超级人才，是能同时做这三件事的人。你的\"T 型技能\"——纵向深度 + 横向广度——变成了\"E 型\"或\"F 型\"。\nScott Adams 说过：他可以是个不错的漫画家，也可以是个不错的商人。但同时懂两者，让他创造了 Dilbert——史上最成功的漫画之一。懂两件事的价值不是 2x，是指数级。\n#04 任务替代比职位替代更快\n主持人：那具体会怎么变化？\nMarc：经济学家把\"职位\"看作\"任务的集合\"。真正被替代的是任务，不是职位。\n比如 1970 年代，高管从不自己打字。你口述给秘书，秘书打出来寄出去。后来有了邮件，秘书负责收发邮件、打印给高管看、再把高管手写的回复敲进电脑发出去。\n现在呢？高管自己发邮件。秘书还在，但做的是差旅安排、会议协调这些。任务变了，职位还在。\n编程也是这样。最好的程序员现在的工作是：同时指挥 10 个 AI coding bot，在浏览器之间切换，和它们争论。\n我跟我 10 岁儿子说：你必须真正理解代码。因为 AI 给你的结果可能不对，你需要能评估它、调试它。就像用脚本语言的人也要理解底层原理一样。\n#05 护城河可能比想象的浅\n主持人：你怎么看 AI 领域的护城河？\nMarc：我挣扎于这个问题。\n一方面，训练模型要花几十亿美元，全世界就那几百个懂的工程师，拿着 NBA 球星级别的薪水。看起来会是寡头垄断。\n但另一方面，ChatGPT 出来一年半后，就有 5 家美国公司、5 家中国公司做出了同等水平的产品，还有开源版本。DeepSeek 基本是中国一个对冲基金搞出来的。\nClaude Code 只用一周半就构建了 Co-work。一方面很厉害，另一方面——如果一周半能做出来，壁垒在哪？\n我私下和领域内最聪明的人聊，喝几杯后他们会说：\"说实话，大模型公司之间可能没什么秘密。\"\n所以我的答案是：我们正在发现的过程中。不要过早下判断。\n#06 AI 的 IQ 会超越人类极限\n主持人：你怎么看 AGI？\nMarc：我对 AGI 这个概念有点纠结。\n\"宇宙级\"定义是奇点——世界根本性改变，人类判断不再重要。我不认为我们会进入那个世界。\n\"务实级\"定义是 AI 能做任何有经济价值的任务。我们显然正在接近这个。\n但我觉得\"人类水平\"这个说法低估了 AI 的潜力。\n人类智商上限大约 160——爱因斯坦级别。140 是顶尖科学家、作家。130 是好律师。110 是好的部门经理。105 是小企业会计师。\n但 160 是生物限制。AI 没有这个限制。现在的模型已经测试到 130-140 水平，很快会到 160、180、200、250、300。\n世界有更多爱因斯坦会更好还是更差？当然更好。AI 超越人类智商极限是好事。\n#07 他的信息消费策略\n主持人：你怎么获取信息？\nMarc：我有个近乎完美的\"杠铃策略\"——要么读 X（实时发生的），要么读 50 年前的老书（经受住时间考验的）。中间的我都很怀疑。\n翻翻上周五的报纸。会发现：几乎所有预测都没发生。他们不知道这周会发生什么，却基于不完整的信息做预测。杂志更糟——出版周期更长，等印出来内容已经过时了。\n但领域从业者直接分享的内容价值被严重低估。播客、newsletter、Substack 让专家能直接解释他们在做什么。这比\"媒体中介\"有价值多了。\nMarc Andreessen 凭发明浏览器和创立 a16z，塑造了过去 30 年的互联网。这期访谈让我重新理解了 AI 对经济的影响——不是\"取代工作\"那么简单，而是一个复杂系统的演化。\n用他的话收个尾：\"AI 是哲学家之石。它把沙子变成思想。\" 我们正处于一个历史性的时刻，最好的策略不是预测，而是保持弹性、拥抱不确定性、不断学习。\nYouTube 链接：https://www.youtube.com/watch?v=87Pm0SGTtN8\n",
    "ytTitle": "Marc Andreessen: The real AI boom hasn’t even started yet",
    "ytChannel": "Lenny's Podcast",
    "ytChannelUrl": "https://www.youtube.com/@LennysPodcast",
    "ytViews": null,
    "ytPublished": null
  },
  {
    "id": "DJQswBmV1iVzmokSQjGcV1l4n3b",
    "title": "Roman-Hölzl-机器人即服务",
    "rawTitle": "0129-Roman-Hölzl-机器人即服务",
    "dateCode": "0129",
    "youtubeId": "ZWmfVPhk9bI",
    "feishuUrl": "https://my.feishu.cn/wiki/DJQswBmV1iVzmokSQjGcV1l4n3b",
    "intro": [
      "今天看到 Roman Hölzl 去了 Lightspeed 的 Investment Memo 播客。",
      "Roman Hölzl 是 RobCo 的 CEO 兼联合创始人，公司刚完成 1 亿美元 C 轮融资。RobCo 的模式很特别——不卖机器人，而是\"机器人即服务\"，每月 5000-7000 美元的订阅费，比一个工人两班倒的成本还低。公司已拿下数十家财富 1000 强客户。",
      "这期播客总共录了 30 分钟，Roman 谈到了 12 个有趣的观点：",
      "1、制造业自动化的核心问题已经变了。过去是\"用机器人降本\"，现在是\"没有机器人就生产不了\"。劳动力短缺如此严重，未来十年制造业将有 400 万个岗位招不到人。不是要不要自动化的问题，是不自动化就得关门。",
      "2、90% 的制造业工作至今仍是手工。这个数字听起来不可思议，但原因很简单：传统机器人太贵（动辄几十万美元）、太复杂（部署要 6-9 个月）、太僵化（只适合大批量标准化生产）。中小企业和高混合低批量的生产线根本用不起。",
      "3、机器人即服务（RaaS）彻底改变了经济学。每月 5000-7000 美元的订阅费，比一个工人两班倒还便宜，有时甚至比一班倒的人工成本还低。关键是风险共担——RobCo 和客户一起承担风险，也一起分享收益。",
      "4、德国市场是最好的试炼场。德国客户没有\"先试试看\"的心态，如果你的机器人凌晨 2 点夜班出问题，你就完蛋了。这种严苛环境逼着 RobCo 把产品做到极致可靠，也为全球扩张打下了基础。",
      "5、高混合低批量已成为制造业新常态。消费者要个性化定制，批量越来越小，品种越来越多。传统机器人是为大批量标准化设计的，根本适应不了这种变化。RobCo 的模块化\"乐高式\"硬件正是为此而生。",
      "6、产品愿景经历了根本转变。最初以为模块化硬件是答案，后来发现真正的价值在软件和 AI。现在的定位是\"自主制造平台\"——硬件是基础，但客户价值来自数字孪生、AI 控制和快速部署。",
      "7、从学术研究到商业化，最大的教训是\"出去太早\"。Roman 在慕尼黑工大读博时创业，带着原型就冲进市场，才发现制造业要求 24/7 运行、高精度、高重复性、零事故。这段痛苦经历反而塑造了以客户为中心的文化。",
      "8、直销模式是护城河。传统机器人行业依赖集成商、分销商、服务商，链条很长。RobCo 全部自己做——直销、部署、服务——形成可重复的高 ROI 打法。这需要强大的销售团队和运营团队，但一旦跑通就很难被复制。",
      "9、远程服务能力是 AI 时代的基础设施。RobCo Studio 可以远程访问每台机器人的性能数据、运行状态、故障信息。这不仅大幅降低了服务成本，更重要的是从一开始就建立了数据和软件基础，为更自主的未来打下根基。",
      "10、1 亿美元 C 轮资金有三个用途。一是深耕已有的财富 1000 强客户，这些账户的扩张潜力还很大；二是美国扩张，Roman 本人今年搬到湾区，目标是 4-6 个季度内做到美欧 50/50；三是自主机器人路线图，这部分还没公开，但已经在和大客户深度合作。",
      "11、机器人创业需要\"速度+耐心\"的悖论组合。需要速度是因为要定义品类、抢占市场；需要耐心是因为涉及供应链、部署、服务、认证，哪个都急不来。能同时做到的资本伙伴很少，这也是为什么 Lightspeed 连投三轮。",
      "12、2030 年愿景：每个工厂至少一个 RobCo。从资本密集型工业机器变成自主 Agent，从一次性采购变成订阅服务，从 6 个月部署变成几天上线、即刻产生 ROI。这是从\"锦上添花\"到\"生存必需品\"的转变。"
    ],
    "highlights": [
      "断断续续看完了这期 Lightspeed 的 Investment Memo。",
      "干货很多。Roman 可能是目前制造业机器人赛道最值得关注的创业者之一——慕尼黑工大博士出身，把学术研究变成了拿下数十家财富 1000 强的商业产品，C 轮融了 1 亿美元。",
      "我今天不忙，把这次访谈关键内容整理出来，供大家学习。",
      "下面是 YouTube 链接：https://www.youtube.com/watch?v=ZWmfVPhk9bI"
    ],
    "fullText": "今天看到 Roman Hölzl 去了 Lightspeed 的 Investment Memo 播客。\nRoman Hölzl 是 RobCo 的 CEO 兼联合创始人，公司刚完成 1 亿美元 C 轮融资。RobCo 的模式很特别——不卖机器人，而是\"机器人即服务\"，每月 5000-7000 美元的订阅费，比一个工人两班倒的成本还低。公司已拿下数十家财富 1000 强客户。\n这期播客总共录了 30 分钟，Roman 谈到了 12 个有趣的观点：\n1、制造业自动化的核心问题已经变了。过去是\"用机器人降本\"，现在是\"没有机器人就生产不了\"。劳动力短缺如此严重，未来十年制造业将有 400 万个岗位招不到人。不是要不要自动化的问题，是不自动化就得关门。\n2、90% 的制造业工作至今仍是手工。这个数字听起来不可思议，但原因很简单：传统机器人太贵（动辄几十万美元）、太复杂（部署要 6-9 个月）、太僵化（只适合大批量标准化生产）。中小企业和高混合低批量的生产线根本用不起。\n3、机器人即服务（RaaS）彻底改变了经济学。每月 5000-7000 美元的订阅费，比一个工人两班倒还便宜，有时甚至比一班倒的人工成本还低。关键是风险共担——RobCo 和客户一起承担风险，也一起分享收益。\n4、德国市场是最好的试炼场。德国客户没有\"先试试看\"的心态，如果你的机器人凌晨 2 点夜班出问题，你就完蛋了。这种严苛环境逼着 RobCo 把产品做到极致可靠，也为全球扩张打下了基础。\n5、高混合低批量已成为制造业新常态。消费者要个性化定制，批量越来越小，品种越来越多。传统机器人是为大批量标准化设计的，根本适应不了这种变化。RobCo 的模块化\"乐高式\"硬件正是为此而生。\n6、产品愿景经历了根本转变。最初以为模块化硬件是答案，后来发现真正的价值在软件和 AI。现在的定位是\"自主制造平台\"——硬件是基础，但客户价值来自数字孪生、AI 控制和快速部署。\n7、从学术研究到商业化，最大的教训是\"出去太早\"。Roman 在慕尼黑工大读博时创业，带着原型就冲进市场，才发现制造业要求 24/7 运行、高精度、高重复性、零事故。这段痛苦经历反而塑造了以客户为中心的文化。\n8、直销模式是护城河。传统机器人行业依赖集成商、分销商、服务商，链条很长。RobCo 全部自己做——直销、部署、服务——形成可重复的高 ROI 打法。这需要强大的销售团队和运营团队，但一旦跑通就很难被复制。\n9、远程服务能力是 AI 时代的基础设施。RobCo Studio 可以远程访问每台机器人的性能数据、运行状态、故障信息。这不仅大幅降低了服务成本，更重要的是从一开始就建立了数据和软件基础，为更自主的未来打下根基。\n10、1 亿美元 C 轮资金有三个用途。一是深耕已有的财富 1000 强客户，这些账户的扩张潜力还很大；二是美国扩张，Roman 本人今年搬到湾区，目标是 4-6 个季度内做到美欧 50/50；三是自主机器人路线图，这部分还没公开，但已经在和大客户深度合作。\n11、机器人创业需要\"速度+耐心\"的悖论组合。需要速度是因为要定义品类、抢占市场；需要耐心是因为涉及供应链、部署、服务、认证，哪个都急不来。能同时做到的资本伙伴很少，这也是为什么 Lightspeed 连投三轮。\n12、2030 年愿景：每个工厂至少一个 RobCo。从资本密集型工业机器变成自主 Agent，从一次性采购变成订阅服务，从 6 个月部署变成几天上线、即刻产生 ROI。这是从\"锦上添花\"到\"生存必需品\"的转变。\n断断续续看完了这期 Lightspeed 的 Investment Memo。\n干货很多。Roman 可能是目前制造业机器人赛道最值得关注的创业者之一——慕尼黑工大博士出身，把学术研究变成了拿下数十家财富 1000 强的商业产品，C 轮融了 1 亿美元。\n我今天不忙，把这次访谈关键内容整理出来，供大家学习。\n下面是 YouTube 链接：https://www.youtube.com/watch?v=ZWmfVPhk9bI\n主持人：现在制造业看起来像是一场完美风暴——地缘政治挑战、宏观经济变化、大规模劳动力短缺。你的客户每天面临的最大痛点是什么？\nRoman：最大的问题毫无疑问是劳动力短缺。从小公司到全球最大的企业，所有人都在说同一件事：找不到人做手工活。磨削、打磨、拉丝、涂胶，这些制造任务都需要人工，但人就是不够。\n所以在我们看来，现在的问题已经不是\"通过自动化降低成本\"——不是这个设定。设定是：在缺乏人工的情况下，这些制造商还能不能生产？\n这个观点太重要了。 以前我们讨论机器人总是说\"省钱\"，但 Roman 说的是\"生存\"。未来十年制造业会有 400 万个岗位招不到人，这不是 ROI 的问题，是开不开得了工的问题。\n主持人：帮我们理解一下，今天的制造业自动化是什么样的？\nRoman：自动化领域有一个巨大的对比。大型传统机器人公司存在了五十年以上，尤其在汽车和制药行业。大企业早就在自动化了，他们有内部团队，有财力。\n但剩下的市场——中型企业、中小企业，以及那些生产变化多的大企业——基本上还没能用上自动化。原因是 ROI 算不过来，技术可行性也是问题。很多看起来简单的产品，制造过程其实非常复杂。\n90% 还是手工，这个数字太离谱了。 2024 年了，绝大多数制造业工作居然还是人在干。原因不是没有机器人，是机器人太贵、太复杂、太僵化。\n主持人：RobCo 用订阅模式卖机器人，成本直接对标人工。这个商业模式能让你做什么？\nRoman：传统机器人的问题是成本高、复杂、周期长。一个项目动辄几十万美元，要 6 到 9 个月才能上线。\n我们的想法是：在技术基础上创新商业模式。现在我们用机器人即服务（RaaS）订阅模式，每月 5000 到 7000 美元。这比一个工人两班倒的成本还低，有时候甚至比一班倒还便宜。\n这完全改变了经济学——RobCo 和客户共担风险，也共享收益。\n说实话，这个定价策略太聪明了。 直接用\"人\"来对标，不是\"机器\"。$5000/月比一个工人两班倒还便宜，这个账谁都会算。而且风险共担，客户没有前期大笔支出，心理门槛一下子就低了。\nRoman：德国市场很严苛。这里没有\"先试试看有什么好处\"的心态。如果你的解决方案在凌晨 2 点的夜班出问题，你就完蛋了。\n所以你需要人来协调这些流程，他们关心质量。\n这段话解释了为什么 RobCo 能拿下财富 1000 强。 在德国活下来的产品，可靠性已经被验证过了。这是\"Made in Germany\"真正的含义——不是品牌溢价，是质量溢价。\n主持人：当你开始考虑 RobCo 并商业化你的研究时，什么时候觉得原型可以给客户用了？\nRoman：回头看，我们出去得太早了。我们就这么冲出去，然后才意识到在制造业环境里让产品运转有多难——24/7 运行、高精度、高重复性、不能出任何事故。\n好坏参半吧。坏处是我们意识到还有很长的路要走。好处是它真正塑造了我们以客户为中心的使命和文化，尽管我们的产品技术含量很高，背后有大量研发和专利。\n主持人：你刚宣布了 1 亿美元的 C 轮融资。这笔钱打算怎么用？\nRoman：三个主要方向。\n第一是企业大客户扩张。我们已经拿下了数十家全球财富 1000 强公司，但在这些账户内部的扩张潜力还处于非常早期。\n第二是美国扩张。我今年会搬到湾区，我们在美国的增长会比欧洲更快，无论是团队还是收入。目标是在未来 4-6 个季度达到美欧 50/50。\n第三是自主机器人路线图。我们内部叫 RobCo Autonomy，还没公开太多信息，但已经和大客户在深度销售和部署合作中了。\n#07 2030 年的机器人会是什么样\n主持人：今年大约部署了 52.5 万台机器人，是十年前的两倍。到 2030 年，年部署量可能会超过 70 万台。2030 年的机器人会是什么样？\nRoman：简短的回答是：更加自主。我们认为会从资本密集型的工业机器，转变为自主 Agent。我们想引领这场革命。\n我们的目标是：每个工厂至少有一个 RobCo，真正自主的，能解决大规模劳动力短缺，是在西方重新实现本地制造的关键要素，能在几天内部署，即刻产生 ROI。\nRoman 凭\"机器人即服务\"这个创新模式，把自动化的门槛从\"几十万美元+半年部署\"降到了\"每月 5000 美元+几天上线\"。这不是渐进式改进，是范式转换。\n用他的话收个尾：\"Automate the ordinary so humans can do the extraordinary.\" 让机器人做普通的事，让人做非凡的事。\nYouTube 链接：https://www.youtube.com/watch?v=ZWmfVPhk9bI\n",
    "ytTitle": "Why Factories are Adopting Robots-as-a-Service | Roman Hölzl, RobCo",
    "ytChannel": "Lightspeed Venture Partners",
    "ytChannelUrl": "https://www.youtube.com/@lightspeedvp",
    "ytViews": null,
    "ytPublished": null
  },
  {
    "id": "DBJqwzyRai3st8kf4zHcihwtn9e",
    "title": "Sebastian-Raschka-LLM技术现状",
    "rawTitle": "0129-Sebastian-Raschka-LLM技术现状",
    "dateCode": "0129",
    "youtubeId": "K5WPr5dtne0",
    "feishuUrl": "https://my.feishu.cn/wiki/DBJqwzyRai3st8kf4zHcihwtn9e",
    "intro": [
      "今天看到 Sebastian Raschka 去了 Matt Turck 的 MAD Podcast。",
      "Sebastian Raschka 是 AI 领域最受欢迎的技术教育者之一，著有畅销书《Build a Large Language Model from Scratch》，他的技术博客是追踪 LLM 前沿进展的必读资源。他用 39 页 Jupyter Notebook 从零实现了 GRPO RLVR，用代码证明了这些技术并不神秘。",
      "这期播客总共录了 1 小时 08 分，Sebastian 谈到了 15 个有趣的观点：",
      "1、预训练不是死了，是无聊了。低垂的果实不在那里了。过去预训练是最重要的投入方向，现在你仍然需要好的预训练，但花同样的钱在后训练上能得到更好的回报。预算应该更多投向后训练。",
      "2、Transformer 仍然是最优架构，没有替代品能取代它。Mamba、文本扩散模型、线性注意力变体——它们都在尝试解决 Transformer 的成本问题，但都有 trade-off。如果你想建一个 state-of-the-art 模型，现在仍然应该选 Transformer。",
      "3、改进不再来自架构，而是来自后训练。你可以用几行代码把 GPT-1/2 改成最新的 DeepSeek v3.2 架构——核心骨架是一样的。现在的架构改进更像是给汽车换空气滤芯，不是换引擎。",
      "4、RLVR 是继 RLHF 之后 LLM 领域最大的飞跃。RLHF 把 GPT 变成了 ChatGPT，RLVR 把聊天模型变成了推理模型。两者都基于强化学习，但 RLVR 用可验证奖励（比如数学答案对不对）替代了人类偏好，成本大幅降低。",
      "5、GRPO 让训练成本降低了 10 倍以上。传统 RLHF 需要三个模型同时在内存中（策略模型、奖励模型、价值模型），GRPO 干掉了两个。DeepSeek v3 预训练花了 500 万美元，R1 只花了 30 万美元。",
      "6、50 步强化学习就能让准确率从 5% 跳到 50%。Sebastian 用 Qwen 3 做实验，只训练 50 步 RLVR，MATH 500 准确率从 5% 飙升到 50%。这不是在学新知识，是在解锁预训练已经学到的知识。模型本来就会，RLVR 只是教它怎么用。",
      "7、没有魔法弹药，进步来自很多小技巧的累积。去掉 KL 散度项、去掉标准差归一化、跳过相同奖励的样本……每个 trick 单独看都很小，加在一起才有大进步。这是整个 2025 年的 meta lesson。",
      "8、推理扩展是 2025 年最大的驱动力之一。不改模型权重，只增加推理时的计算：生成更多 token、并行采样、自我精炼、多轮迭代。OpenAI 的图表显示，推理扩展和训练扩展的收益曲线几乎一样陡。",
      "9、工具调用是减少幻觉的关键解锁。LLM 不需要记住所有东西，可以用网页搜索、代码解释器等工具。GPT-4o 的基准测试显示，开启工具调用后性能提升约 20%。这就像人类用计算器一样自然。",
      "10、Benchmaxing 现象正在污染评估体系。模型被过度优化以在基准测试上表现好，但不一定在真实任务中更好。Llama 4 据传有专门针对排行榜的版本。Sebastian 现在不看基准分数了，直接用几天看感觉。",
      "11、持续学习可能要等到 2027 年才有突破。虽然是 NeurIPS 热门话题，但灾难性遗忘问题没解决，而且现在所有人用的是同一个模型，没有个人定制版本。在这种架构下很难做真正的持续学习。",
      "12、世界模型对代码 LLM 特别有前景。Meta 有篇论文让模型预测变量的中间状态——不只是预测下一个 token，而是理解代码执行过程。这很像人类学编程时在纸上写下每次迭代的变量值。"
    ],
    "highlights": [
      "断断续续看完了这期 MAD Podcast。",
      "干货太多了。Sebastian Raschka 可能是目前最好的 LLM 技术教育者——他不只是讲概念，而是真的用代码实现。39 页 Jupyter Notebook 从零写 GRPO RLVR，这种硬核程度很少见。",
      "我把这次访谈的关键技术点整理出来，供大家学习。",
      "下面是 YouTube 链接：https://www.youtube.com/watch?v=K5WPr5dtne0"
    ],
    "fullText": "今天看到 Sebastian Raschka 去了 Matt Turck 的 MAD Podcast。\nSebastian Raschka 是 AI 领域最受欢迎的技术教育者之一，著有畅销书《Build a Large Language Model from Scratch》，他的技术博客是追踪 LLM 前沿进展的必读资源。他用 39 页 Jupyter Notebook 从零实现了 GRPO RLVR，用代码证明了这些技术并不神秘。\n这期播客总共录了 1 小时 08 分，Sebastian 谈到了 15 个有趣的观点：\n1、预训练不是死了，是无聊了。低垂的果实不在那里了。过去预训练是最重要的投入方向，现在你仍然需要好的预训练，但花同样的钱在后训练上能得到更好的回报。预算应该更多投向后训练。\n2、Transformer 仍然是最优架构，没有替代品能取代它。Mamba、文本扩散模型、线性注意力变体——它们都在尝试解决 Transformer 的成本问题，但都有 trade-off。如果你想建一个 state-of-the-art 模型，现在仍然应该选 Transformer。\n3、改进不再来自架构，而是来自后训练。你可以用几行代码把 GPT-1/2 改成最新的 DeepSeek v3.2 架构——核心骨架是一样的。现在的架构改进更像是给汽车换空气滤芯，不是换引擎。\n4、RLVR 是继 RLHF 之后 LLM 领域最大的飞跃。RLHF 把 GPT 变成了 ChatGPT，RLVR 把聊天模型变成了推理模型。两者都基于强化学习，但 RLVR 用可验证奖励（比如数学答案对不对）替代了人类偏好，成本大幅降低。\n5、GRPO 让训练成本降低了 10 倍以上。传统 RLHF 需要三个模型同时在内存中（策略模型、奖励模型、价值模型），GRPO 干掉了两个。DeepSeek v3 预训练花了 500 万美元，R1 只花了 30 万美元。\n6、50 步强化学习就能让准确率从 5% 跳到 50%。Sebastian 用 Qwen 3 做实验，只训练 50 步 RLVR，MATH 500 准确率从 5% 飙升到 50%。这不是在学新知识，是在解锁预训练已经学到的知识。模型本来就会，RLVR 只是教它怎么用。\n7、没有魔法弹药，进步来自很多小技巧的累积。去掉 KL 散度项、去掉标准差归一化、跳过相同奖励的样本……每个 trick 单独看都很小，加在一起才有大进步。这是整个 2025 年的 meta lesson。\n8、推理扩展是 2025 年最大的驱动力之一。不改模型权重，只增加推理时的计算：生成更多 token、并行采样、自我精炼、多轮迭代。OpenAI 的图表显示，推理扩展和训练扩展的收益曲线几乎一样陡。\n9、工具调用是减少幻觉的关键解锁。LLM 不需要记住所有东西，可以用网页搜索、代码解释器等工具。GPT-4o 的基准测试显示，开启工具调用后性能提升约 20%。这就像人类用计算器一样自然。\n10、Benchmaxing 现象正在污染评估体系。模型被过度优化以在基准测试上表现好，但不一定在真实任务中更好。Llama 4 据传有专门针对排行榜的版本。Sebastian 现在不看基准分数了，直接用几天看感觉。\n11、持续学习可能要等到 2027 年才有突破。虽然是 NeurIPS 热门话题，但灾难性遗忘问题没解决，而且现在所有人用的是同一个模型，没有个人定制版本。在这种架构下很难做真正的持续学习。\n12、世界模型对代码 LLM 特别有前景。Meta 有篇论文让模型预测变量的中间状态——不只是预测下一个 token，而是理解代码执行过程。这很像人类学编程时在纸上写下每次迭代的变量值。\n13、MoE（专家混合）成为 2025 年的标配。DeepSeek v3 重新点燃了这个趋势，现在几乎所有开源模型都在用。Mistral 直接采用了 DeepSeek 的架构，Kimmi 把参数从 6700 亿扩展到 1 万亿。\n14、私有数据是差异化的唯一真正壁垒。ChatGPT、Gemini、Claude、Grok 都差不多好，因为它们都是通用模型。真正的差异化来自金融公司 50 年积累的数据、医院的病历记录——这些公司不会把数据交出去。\n15、大公司正在开始自己训练 LLM。有财力的企业正在招聘 LLM 训练人才，在内部建 ChatGPT 级别的数据中心。他们不会发论文、不会公开宣布，但这正在发生。知识正从少数几家 AI 公司向外扩散。\n断断续续看完了这期 MAD Podcast。\n干货太多了。Sebastian Raschka 可能是目前最好的 LLM 技术教育者——他不只是讲概念，而是真的用代码实现。39 页 Jupyter Notebook 从零写 GRPO RLVR，这种硬核程度很少见。\n我把这次访谈的关键技术点整理出来，供大家学习。\n下面是 YouTube 链接：https://www.youtube.com/watch?v=K5WPr5dtne0\n#01 Transformer 还是王者吗？\nMatt：Transformer 架构已经 8-9 年了，有什么能替代它吗？\nSebastian：现在还是要选 Transformer，因为它仍然是 state-of-the-art。我们看到的替代方案——Mamba、文本扩散模型、线性注意力——都在试图解决 Transformer 太贵的问题，但都有 trade-off。\n比如文本扩散模型，并行生成确实快，但你需要多轮 denoising，最后可能比 autoregressive 还贵。而且很多任务需要顺序处理，比如推理模型需要中途调用工具。\n关键点：没有免费午餐。Transformer 的替代品要么牺牲质量换速度，要么把成本转移到别处。\n#02 预训练无聊了，后训练才是金矿\nMatt：架构改进是不是到头了？\nSebastian：改进不再来自架构了，来自后训练。你可以用几行代码把 GPT-1 改成 DeepSeek v3.2——核心骨架是一样的。\n现在的架构改进就像给汽车换空气滤芯。RMS Norm 放前面还是后面？DeepSeek 放两边？这些 ablation 显示能稳定训练，但不会让模型魔法般变好。\n唯一例外是 MoE（专家混合）。2025 年几乎所有人都在用。DeepSeek v3 重新点燃了这个趋势，Mistral 直接抄了他们的架构。\n我的理解：预训练像是修高速公路，基础设施已经很好了。后训练像是学开车，同样的路，技术好的司机能开出完全不同的效果。\n#03 RLVR 和 GRPO：技术深度解析\nMatt：2025 年是 RLVR 和 GRPO 之年。能解释一下吗？\nSebastian：RLHF 把 GPT 变成 ChatGPT，RLVR 把聊天模型变成推理模型。这是同等量级的飞跃。\n传统 RLHF 需要三个模型：策略模型、奖励模型、价值模型。如果每个都是 600B 参数，你需要 1800B 参数同时在内存里，太贵了。\nRLVR 用可验证奖励替代奖励模型——数学题对不对？代码能不能编译？这些可以算法验证，不需要另一个 LLM。\nGRPO 干掉了价值模型，用组内相对比较替代。所以 DeepSeek R1 训练只花了 30 万美元，预训练花了 500 万美元。便宜 10 倍以上。\n最震撼的实验：Sebastian 用 Qwen 3 做实验，只训练 50 步 RLVR，MATH 500 准确率从 5% 飙升到 50%。50 步！这说明知识早就在预训练里了，RLVR 只是教模型怎么用自己的知识。\n#04 推理扩展：不改权重也能变强\nSebastian：推理扩展是 2025 年最大的驱动力之一。\n不改模型权重，只增加推理时的计算。方式很多：\n• 让模型生成更多 token（推理链更长）\n• 并行采样（跑 5 次取最优）\n• 自我精炼（写完答案再检查修改）\n• 多轮迭代（把大问题拆成小问题）\nOpenAI 2024 年 10 月有张图，显示推理扩展和训练扩展的收益曲线几乎一样陡。\n这解释了为什么本地模型感觉不如 ChatGPT。不是模型差多少，是 ChatGPT 背后有大量工程优化：清理 prompt、管理上下文、工具调用……这些\"小\"工程加起来体验差很多。\n#05 Benchmaxing：基准测试被污染了\nMatt：你提到过 benchmaxing 这个词？\nSebastian：模型被过度优化以在基准测试上表现好。Llama 4 据传有专门针对排行榜的版本。\n问题是排行榜靠人类比较哪个答案更好。如果我不懂税务，看到一个解释很清晰的答案，我会点赞——即使答案是错的。模型就学会了\"写得好看\"而不是\"写得正确\"。\n我现在不看基准分数了。直接用几天，看感觉。问题是这种\"感觉\"很难量化、很难沟通。这是接下来几年要解决的难题。\n有意思的是：所有模型都在\"作弊\"，但排名还是对的。如果 Gemini 和 GPT 都在基准上虚高 10%，但 Gemini 还是比 GPT 高，那比较仍然有效。\n#06 私有数据是唯一真正的壁垒\nSebastian：ChatGPT、Gemini、Claude、Grok 都差不多好。它们都是通用模型，没有谁明显更好。\n真正的差异化来自私有数据。金融公司 50 年积累的交易数据、医院的病历记录——这些才是宝藏。而且这些公司不会把数据交出去，一是法规不允许，二是数据是他们的核心竞争力。\n我知道有大公司正在招聘 LLM 训练人才，在内部建 ChatGPT 级别的模型。他们不会发论文、不会公开宣布，但这正在发生。\n我的理解：这是\"回到未来\"。最初大家以为自己要训模型，后来发现太难放弃了，现在有了更好的开源基座（DeepSeek v3），又开始自己训了。\n#07 持续学习还很远\nMatt：NeurIPS 上持续学习很火？\nSebastian：火是火，但我不知道为什么 2025 年突然这么火，因为没有大突破。\n问题是灾难性遗忘没解决，而且现在所有人用的是同一个模型。我用 ChatGPT，你也用 ChatGPT，权重完全一样。在这种架构下怎么做持续学习？你不能随便更新一个数万亿参数的模型。\n我觉得可能要等到 2027 年。很多聪明人在研究，也许会有原型、有想法，但真正的突破还没看到。\nSebastian 凭一己之力把 LLM 技术教育做到了新高度——不是泛泛而谈，而是用代码证明每一个概念。\n用他的话收个尾：\"代码不会撒谎，要么能跑要么不能跑。\" 这是学习 LLM 最好的方式。\nYouTube 链接：https://www.youtube.com/watch?v=K5WPr5dtne0\n",
    "ytTitle": "State of LLMs 2026: RLVR, GRPO, Inference Scaling — Sebastian Raschka",
    "ytChannel": "The MAD Podcast with Matt Turck",
    "ytChannelUrl": "https://www.youtube.com/@DataDrivenNYC",
    "ytViews": null,
    "ytPublished": null
  },
  {
    "id": "TwTOwJ29qimSUVkW8uiczQQjncb",
    "title": "Gary Marcus X The Real Iceman Playbook ",
    "rawTitle": "0128 Gary Marcus X The Real Iceman Playbook ",
    "dateCode": "0128",
    "youtubeId": null,
    "feishuUrl": "https://my.feishu.cn/wiki/TwTOwJ29qimSUVkW8uiczQQjncb",
    "intro": [
      "今天看到 Gary Marcus 去了 The Real Iceman Playbook 的播客。",
      "Gary Marcus 在 MIT 读博时就研究神经网络，2001年出版的《The Algebraic Mind》预见了今天的幻觉问题，2012年深度学习复兴时他就在《纽约客》发文指出问题。被 OpenAI 内部做成表情包，被 Sam Altman 在推特上叫\"喷子\"——但现在连 Ilya Sutskever 都开始认同他的观点。",
      "主持人 Steve Iceman 是因《大空头》闻名的华尔街传奇投资人。两人从金融与科学的双重视角，拆解了AI投资背后的逻辑陷阱与潜在风险。",
      "这期播客的信息密度极高。我把全文精编出来，按主题重新组织，供大家学习。"
    ],
    "highlights": [
      "#01 大语言模型到底在干什么",
      "主持人：咱们先停一下，把大语言模型到底在干什么拆解开，那些人觉得它应该干什么？",
      "Gary Marcus：从根本上说，它们做的是预测序列中的下一个内容。你想想iPhone上的自动纠错功能——你打一句话\"我们在哪家\"，它猜\"餐厅\"的概率就很高。这就是自动补全。我管大模型叫\"加强版自动补全\"。",
      "它们会把所有信息拆成碎片，然后再重新组合。这意味着它们实际上丢失了信息之间的逻辑连接。所以有时候会产生幻觉。",
      "这太关键了。大家误以为大模型是像我们一样的智能生物，其实它们只是在重建碎片信息之间概率最高的统计关系。",
      "#02 系统一 vs 系统二",
      "Gary Marcus：如果你看过Daniel Kahneman那本著名的《思考，快与慢》——他提出了系统一和系统二。系统一是快速自动、统计性且反射性的；系统二更慢，更深思熟虑，更讲逻辑推理。",
      "神经网络基本上就是系统一。这没问题，人类也用系统一。但我们还有系统二，尤其是在状态好的时候，我们会进行更慢更深思熟虑的推理。而这些系统从来不擅长这个，现在也还是不行。",
      "我在2012年就说过，它们只有系统一，没有系统二。",
      "说实话，这个框架太清晰了。一下子就解释了为什么LLM在某些地方很强（快速模式识别），在另一些地方永远不行（逻辑推理）。",
      "#03 万亿磅婴儿谬论",
      "主持人：规模定律的想法是什么？",
      "Gary Marcus：只要投入更多数据、更多GPU芯片，把模型做得越来越大，它就会变得无所不能。他们确实有一些数据支持这个，但这种想法很幼稚。",
      "我管这叫\"万亿磅婴儿谬论\"。你看，婴儿刚出生8磅，一个月后16磅。这不代表它会一直翻倍到32磅、64磅——等它上大学时就变成1万亿磅重了，对吧？",
      "这种推论非常天真，但很多聪明人拿着巨款在赌这件事。",
      "天哪这个比喻太绝了。一句话就把规模定律的荒谬讲透了。",
      "#04 Harry Shearer：幻觉的典型案例",
      "Gary Marcus：我最喜欢的幻觉例子涉及到一个人——Harry Shearer。他在《摇滚万万岁》里演贝斯手，还给《辛普森一家》里的伯恩斯先生配音。",
      "模型说他是个\"英国配音演员和喜剧演员\"，但他根本不是英国人。你上维基百科搜2秒钟就能看到他出生在洛杉矶，而且他很有名。",
      "找正确信息并不难。但模型建立了一个统计上的关联——现实中确实有很多著名的英国配音演员和喜剧演员，比如Ricky Gervais、John Cleese，结果模型就把这些特征给模糊地混在一起了。"
    ],
    "fullText": "今天看到 Gary Marcus 去了 The Real Iceman Playbook 的播客。\nGary Marcus 在 MIT 读博时就研究神经网络，2001年出版的《The Algebraic Mind》预见了今天的幻觉问题，2012年深度学习复兴时他就在《纽约客》发文指出问题。被 OpenAI 内部做成表情包，被 Sam Altman 在推特上叫\"喷子\"——但现在连 Ilya Sutskever 都开始认同他的观点。\n主持人 Steve Iceman 是因《大空头》闻名的华尔街传奇投资人。两人从金融与科学的双重视角，拆解了AI投资背后的逻辑陷阱与潜在风险。\n这期播客的信息密度极高。我把全文精编出来，按主题重新组织，供大家学习。\n1. 万亿磅婴儿谬论：婴儿刚出生8磅，一个月16磅，不代表上大学时会变成1万亿磅——规模定律同理，推到极限就是天真的外推\n2. 加强版自动补全：大语言模型本质就是预测下一个词，把信息拆成碎片再重组，这个过程会丢失逻辑连接\n3. 系统一vs系统二：神经网络只有快速统计的系统一，没有深思熟虑的系统二，这是结构性缺陷\n4. 幻觉根源：Harry Shearer 明明出生在洛杉矶，模型却说他是英国人——因为它把\"著名配音演员\"和\"英国\"的统计关联搅混了\n5. 85%研究员不信AGI：Gary 从来不是少数派，他只是最敢说话、最不怕挨骂的人\n6. 符号AI暗度陈仓：他们表面否认，实际在偷偷用 code interpreter 这类符号工具——而这些跑在CPU上，不是GPU\n7. 大量离职的信号：如果下周真要发AGI，你会提前离职去开个四年的小公司吗？行为比言语更说明问题\n8. OpenAI财务黑洞：每月亏30亿，刚融的40亿只够烧一年，接下来可能需要1000亿——世界上只有约5个人能开这种支票\n9. Google必胜逻辑：如果只拼规模，谁能比Google更有钱？他们还自己做TPU，不依赖英伟达\n10. AI只完成2.5%工作：华盛顿邮报研究显示，人们幻想中AI能代劳的事，大部分它做不到\n11. 特斯拉撞飞机：智能召唤撞上350万美元私人飞机——训练数据里没有飞机，它就完全不知道要避开\n12. 世界模型缺失：看了100万场棋赛、读了所有规则，LLM还是会走违规的步——它从未真正理解象棋如何运作\n13. 歪心狼时刻：投资界已经开始\"低头看\"了——从去年11月开始，大家意识到投资回报率并不怎么样\n#01 大语言模型到底在干什么\n主持人：咱们先停一下，把大语言模型到底在干什么拆解开，那些人觉得它应该干什么？\nGary Marcus：从根本上说，它们做的是预测序列中的下一个内容。你想想iPhone上的自动纠错功能——你打一句话\"我们在哪家\"，它猜\"餐厅\"的概率就很高。这就是自动补全。我管大模型叫\"加强版自动补全\"。\n它们会把所有信息拆成碎片，然后再重新组合。这意味着它们实际上丢失了信息之间的逻辑连接。所以有时候会产生幻觉。\n这太关键了。大家误以为大模型是像我们一样的智能生物，其实它们只是在重建碎片信息之间概率最高的统计关系。\n#02 系统一 vs 系统二\nGary Marcus：如果你看过Daniel Kahneman那本著名的《思考，快与慢》——他提出了系统一和系统二。系统一是快速自动、统计性且反射性的；系统二更慢，更深思熟虑，更讲逻辑推理。\n神经网络基本上就是系统一。这没问题，人类也用系统一。但我们还有系统二，尤其是在状态好的时候，我们会进行更慢更深思熟虑的推理。而这些系统从来不擅长这个，现在也还是不行。\n我在2012年就说过，它们只有系统一，没有系统二。\n说实话，这个框架太清晰了。一下子就解释了为什么LLM在某些地方很强（快速模式识别），在另一些地方永远不行（逻辑推理）。\n#03 万亿磅婴儿谬论\n主持人：规模定律的想法是什么？\nGary Marcus：只要投入更多数据、更多GPU芯片，把模型做得越来越大，它就会变得无所不能。他们确实有一些数据支持这个，但这种想法很幼稚。\n我管这叫\"万亿磅婴儿谬论\"。你看，婴儿刚出生8磅，一个月后16磅。这不代表它会一直翻倍到32磅、64磅——等它上大学时就变成1万亿磅重了，对吧？\n这种推论非常天真，但很多聪明人拿着巨款在赌这件事。\n天哪这个比喻太绝了。一句话就把规模定律的荒谬讲透了。\n#04 Harry Shearer：幻觉的典型案例\nGary Marcus：我最喜欢的幻觉例子涉及到一个人——Harry Shearer。他在《摇滚万万岁》里演贝斯手，还给《辛普森一家》里的伯恩斯先生配音。\n模型说他是个\"英国配音演员和喜剧演员\"，但他根本不是英国人。你上维基百科搜2秒钟就能看到他出生在洛杉矶，而且他很有名。\n找正确信息并不难。但模型建立了一个统计上的关联——现实中确实有很多著名的英国配音演员和喜剧演员，比如Ricky Gervais、John Cleese，结果模型就把这些特征给模糊地混在一起了。\n这种模糊处理大体上可行，但你永远不能指望具体到某件事上它是对的。\n#05 看着还行效应 & 工作废料\nGary Marcus：最阴险的是这些错误往往会被人忽略。比如CNET之前是最早试着用AI写文章的媒体之一，首批75篇里有一半都有错。编辑没发现这些错误，因为AI写的句子语法通顺、结构完整，还没有拼写错误。\n人看着看着就走神了。我把这个叫\"看着还行效应\"(Looks Good To Me Effect)。\n这还引申出了一个新词——\"工作废料\"(Workers Slop)。去年几位教授提出的：人们写完报告交给老板，表面看着挺好，其实里头全是错。因为LLM根本不理解内容。\n#06 Gary Marcus 从来不是少数派\n主持人：现在的计算机科学界是什么态度？你还是那个孤独的反对者吗？\nGary Marcus：我觉得我现在已经不算少数派了。在资深AI研究员圈子里，我从来都不是少数派——我只是在媒体报道和公司老板眼里是少数派。\n有个调查显示，85%的受访者都认为LLM无法带我们实现真正的通用人工智能。我只是那个最敢说话、最不怕挨骂的人。\n主持人：OpenAI对你什么态度？\nGary Marcus：OpenAI内部甚至有个专门针对我的表情包。Sam Altman还在推特上叫我\"喷子\"。他们真的不想听我的意见。\n我觉得这个点真的太重要了。大家总以为Gary Marcus是孤军奋战，其实85%的专业研究员都认同他——只是没人像他这么敢说。\n#07 GPT5 的失望时刻\nGary Marcus：真正的转折点是去年8月。之前Sam Altman一直暗示GPT5就是AGI，大家都在苦苦等待，就像在等戈多。结果一推再推。\n它发布的时候是2025年8月7日。之前有个模型叫GPT4.5，本来应该是GPT5的，但他们觉得效果不够好，甚至不想给它起那个名字。\nSam说这模型能做\"博士能做的任何事\"。但公测之后也就花了1个小时就发现这根本不是真的。它还是会一本正经地胡说八道，犯一些很低级的错误。\n主持人：我记得当时我也在看，感觉Gary Marcus不再是那个孤军奋战的人了。\nGary Marcus：没错，甚至有人写了本书，名字就叫《Gary Marcus是对的》。就成了一个梗——\"绕了一大圈，结果Gary Marcus还是对的。\"\n#08 符号AI暗度陈仓\nGary Marcus：我一直说不能只靠纯大语言模型，必须结合传统的符号AI。以前他们都嗤之以鼻。\n结果现在他们都开始偷偷做了——比如他们用code interpreter运行Python代码，这就是典型的符号工具。他们悄悄把这种\"系统二\"的思考方式塞进模型里，虽然没大肆宣传，但效果非常明显。\n主持人：这对投资领域意味着什么？\nGary Marcus：这很重要——因为这些符号化的任务不是跑在GPU上的，而是跑在CPU上的。\n这意味着他们自己都在证明：纯大语言模型不够用。而这部分进步跟GPU没关系。\n#09 大量离职 = 不相信AGI即将到来\nGary Marcus：现在大家都在离职去创业。你想想，如果你在OpenAI，如果下周真的要发布AGI这种能改变世界的里程碑，你会在这之前离职去开个要干四年的小公司吗？\n当然不会，你肯定想留在那里见证奇迹。\n所以大家纷纷离开这件事本身就说明——他们手里其实并没有他们吹嘘的那种东西。\n行为比言语更说明问题。这个洞察太犀利了。\n#10 OpenAI 的财务黑洞\n主持人：OpenAI的财务状况怎么样？\nGary Marcus：OpenAI有超过1万亿美元的未支付承诺，而且从未盈利。它现在进入了大宗商品市场，最大的对手Google赶上来了，甚至昨天还超越了它们，而且Google还拿到了苹果的订单。\n它们每个月亏30亿，一年就是300多亿。刚拿到的40亿融资也就够烧一年的。\n主持人：接下来需要多少钱？\nGary Marcus：可能需要1000亿美元。世界上没几个人能开出1000亿美元的支票，大概也就5个人能做到。如果这5个人都说不，你就要么破产，要么只能去找微软求助。\n我这两年一直在说——OpenAI最终会被视为\"AI界的WeWork\"。大家会纳闷它们当初是怎么拿到那个估值的。\n#11 如果只拼规模，Google必胜\nGary Marcus：Google正在赶上来。就像我几年前预测的那样——因为大家都在做同样的事情，这里其实没有技术护城河。\n如果只拼规模，那赢家就是那个能烧得起钱的人。谁能比Google更有钱呢？\n而且Google甚至不需要NVIDIA，因为他们自己在做TPU，干的活其实差不多。所以他们没那么脆弱，有资金，肯定会赢。\n#12 特斯拉撞飞机：没见过的就不会处理\nGary Marcus：有个很离谱的例子。特斯拉用了很多这种记忆式的AI。有人在飞机展上用智能召唤功能想耍个帅，让车自己开过来。\n结果那辆特斯拉直接撞上了一架价值350万美元的私人飞机。\n系统的训练数据里根本没教过它怎么避开飞机。它不知道要避开飞机，因为它对世界没有常识性的理解，不懂\"不要撞上昂贵的巨大的障碍物\"。它只认得自行车、行人这些预设的类别，没见过飞机，所以就直接撞上去了。\n这就是核心问题——一旦遇到没见过的新情况，它就抓瞎了。\n#13 世界模型：100万场棋赛仍不懂规则\n主持人：什么是\"世界模型\"？\nGary Marcus：简单来说，世界模型就是计算机内部能代表外部世界各种事物的模型。比如GPS导航系统，它需要能代表道路是什么样的、怎么连接的、路上的交通流量、要花多长时间。\n在传统AI领域，世界模型是起点，没人会想过不带它。但大语言模型试图绕过这一步。\n主持人：结果呢？\nGary Marcus：我最喜欢的例子是国际象棋。你用整个互联网的数据去训练它们，它们能接触到大量的象棋规则和对局记录。但它们还是会走出违规的步伐——它们从未真正抽象出象棋运作的模型。\n这太离谱了。你看了100万场比赛，读了维基百科和chess.com上的规则，读了各种象棋书，结果还是学不会。\n所以当大语言模型告诉你Harry Shearer出生在伦敦，就是因为它没有一个正确的世界模型。\n#14 风投的2%激励\nGary Marcus：问题部分出在风投圈。风投只要投一个听起来靠谱的方案，就能拿2%的管理费。如果你是个风投，你有个故事能让我投1万亿美元，你就能拿走2%。\n你可能并没那么在乎最后能不能成，因为1万亿的2%已经让你富得流油了。\n大家全押在规模化上，因为抽成很高，但这在智力上是不正确的，结果也不理想。这意味着大量的资金被浪费了。风投拿到了分成，但有限合伙人LP最后会亏很多钱。\n#15 歪心狼时刻\n主持人：你觉得我们离那个崩盘时刻近吗？\nGary Marcus：我去年用的比喻是兔八哥里的歪心狼——它冲出悬崖后，直到低头看的那一刻才会掉下去。\n我觉得投资界已经开始低头看了。这大概是从去年11月开始的。大家开始说：\"我看到这里面有很多循环融资，投资回报率并不怎么样，系统还是不怎么好用，也许这事儿根本行不通。\"\n主持人：如果人们开始从OpenAI撤资，会发生什么？",
    "ytTitle": null,
    "ytChannel": null,
    "ytChannelUrl": null,
    "ytViews": null,
    "ytPublished": null
  },
  {
    "id": "CVBNwWfNiiNdpKkTf6Pc4mNunlc",
    "title": "Lucas Crespo X Every Think Week：让 Claude 学会设计师的审美直觉",
    "rawTitle": "0128：Lucas Crespo X Every Think Week：让 Claude 学会设计师的审美直觉",
    "dateCode": "0128",
    "youtubeId": "BI0XW1gkKXM",
    "feishuUrl": "https://my.feishu.cn/wiki/CVBNwWfNiiNdpKkTf6Pc4mNunlc",
    "intro": [
      "今天看到 Every 团队 Think Week 的直播，Lucas Crespo 和 Kiran 演示如何用 Claude 自动化封面图片创作。",
      "Lucas 是 Every 的创意总监，负责每天为文章创作封面图。他们团队每天发布一篇文章，每张封面都是定制的，使用 Midjourney 配合自定义风格库。这次在巴拿马的 Think Week，他们尝试用 Claude 控制浏览器来自动化这个流程。",
      "这期视频总共录了约 20 分钟，Lucas 和 Kiran 谈到了 12 个有趣的观点：",
      "1、Prompt 越短越好，风格让 Mood Board 来干重活。Lucas 说他们的 prompt 现在控制在 10 个词以内，因为已经积累了足够多的图片风格参考，模型自己能理解。一个词对不同人意味着不同的画面，所以用图片参考比用文字描述更精准。",
      "2、读文章找视觉隐喻，但要避免字面翻译。文章讲工程师不能直接画个工程师，要「再往深挖一层」。比如 Cursor 那篇文章，他们用「交响乐指挥」来隐喻 vibe coding——你不是在演奏一件乐器，而是在协调整个交响乐团。",
      "3、先穷举所有烂点子，才能找到好点子。Lucas 的流程是先把「low hanging fruit」（显而易见的想法）全部列出来、扔掉，然后才开始认真创作。这和写作的「先写垃圾初稿」逻辑相似。",
      "4、Agent 工作流就像新员工入职——开始会犯很多错。Lucas 说这感觉很熟悉，就像带新人：会做错很多次，但你是在为未来投资，不用每天每周重复同样的工作。",
      "5、「这是我的工作，如果 Agent 能做，我的价值在哪？」Lucas 直接说出了这个焦虑，但转念一想：如果不用做日常图片，就有时间做更有影响力的工作——定义风格、探索新方向。",
      "6、Skill 是文本文件，可以像传代码一样 AirDrop 分享。Kiran 演示了 Claude 的 Skill 机制：一个 MD 文件就是一个工作流，本地化、可分享、不需要 API Key，只要对方浏览器登录了 Midjourney 就能用。",
      "7、用 Mono Logue 向 Claude 「碎碎念」来捕捉审美直觉。Lucas 说审美和主观判断很难用语言精确表达，但你可以对着话筒自言自语，让 Claude 从中提取模式。「让模型理解你的直觉」比精心措辞 prompt 更有效。",
      "8、图片需要居中构图因为网站会裁成正方形。Lucas 说 Midjourney 不像推理模型，你说「居中」它不一定听。解决方案是加一步用 Nano Banana（图像编辑 API）后处理——Claude 可以调用它的 Skill 来自动裁图。",
      "9、风格统一靠 Profile Code，不靠精心写的 prompt。他们有一个 Midjourney 风格码（类似 bitly 短链接），每次生成都附加这个码。风格沉淀在历史图片库里，prompt 反而可以极简。",
      "10、判断图片好坏的标准：干净 > 脏乱，饱和 > 灰暗，主体突出 > 细节堆砌。Lucas 说「脏兮兮的纹理」让人看着累，深色网站需要封面「跳出来」，所以选高饱和度、干净背景。这些直觉可以变成 Claude 筛选的规则。",
      "11、不用在乎底层是什么工具，只在乎产出是否让你骄傲。Kiran 问 Lucas：「如果不是 Midjourney 而是微调模型，你介意吗？」Lucas 说不介意，他们用 Midjourney 只是因为它目前最稳定可靠，换别的能达到同样质量也行。",
      "12、Claude 可以「在后台干活」，你另开一个 Tab 做别事。这改变了人和 AI 协作的模式——以前必须盯着，现在可以让它跑一批图，你回来挑最好的。「踢个球回来看结果」vs「实时来回对话」。"
    ],
    "highlights": [
      "断断续续看完了 Every 团队的 Think Week 直播，干货很多。Lucas Crespo 是 Every 的创意总监，每天给文章做封面图——听起来简单，但他们网站的图风格非常统一，一眼就认得出来。",
      "这次他们尝试用 Claude 来「学会」设计师的眼光。赠人玫瑰，手有余香。",
      "下面是 YouTube 链接：https://www.youtube.com/watch?v=BI0XW1gkKXM",
      "#01 为什么 Prompt 要极简？",
      "Kiran：你们现在的工作流是什么样的？",
      "Lucas：我们 prompt 控制在 10 个词以内，非常简单。因为我们已经积累了大量的图片参考，全放在 Midjourney 的 mood board 里。以前我们会手写很多形容词——「噪点」「希腊罗马风」「新古典」——现在完全不需要，模型自己能从参考图理解。",
      "而且，「大」这个词对你和对我的画面感可能完全不同。图片参考比文字更精准。",
      "这太有意思了。这意味着「风格」可以沉淀成资产，而不是每次从零开始 prompt 工程。",
      "#02 视觉隐喻 vs 字面翻译",
      "Kiran：看到文章后你怎么想画面？",
      "Lucas：关键是不能太 on-the-nose（字面）。如果文章讲工程师，我不能真画个工程师。要往深挖。",
      "比如那篇 Cursor 的文章讲 AI 编程，我们用了「交响乐指挥」的隐喻——你不是在弹一件乐器，你在协调整个交响乐团。prompt 就写「orchestra conductor, opera」之类的词，几个词搞定。",
      "Kiran：所以 Claude 的工作是：读文章 → 提取隐喻 → 生成简短 prompt？",
      "Lucas：对，这是我们想自动化的部分。我读起来可能几分钟就有灵感，但如果 Claude 能做到 80%，我就只用审核和微调。",
      "#03 「这是我的工作，AI 来了我干嘛？」",
      "Lucas：说实话，看它自动做这些有点吓人 (scary)。因为这就是我的工作啊，如果 agent 能做，我的价值在哪？",
      "但转念一想——这也是这次 Think Week 的主题：把自己从日常杂活里解放出来，做更有影响力的事。如果不用每天做封面图，我可以去定义整个视觉系统、探索新方向。",
      "Kiran：对，而且这就像带新员工。开始肯定错很多次，但你是在为未来投资。",
      "这个类比太好了。培训新人的痛苦谁都经历过，但你知道最终能把自己从重复劳动里解放出来。",
      "#04 Skill = 可分享的文本文件"
    ],
    "fullText": "今天看到 Every 团队 Think Week 的直播，Lucas Crespo 和 Kiran 演示如何用 Claude 自动化封面图片创作。\nLucas 是 Every 的创意总监，负责每天为文章创作封面图。他们团队每天发布一篇文章，每张封面都是定制的，使用 Midjourney 配合自定义风格库。这次在巴拿马的 Think Week，他们尝试用 Claude 控制浏览器来自动化这个流程。\n这期视频总共录了约 20 分钟，Lucas 和 Kiran 谈到了 12 个有趣的观点：\n1、Prompt 越短越好，风格让 Mood Board 来干重活。Lucas 说他们的 prompt 现在控制在 10 个词以内，因为已经积累了足够多的图片风格参考，模型自己能理解。一个词对不同人意味着不同的画面，所以用图片参考比用文字描述更精准。\n2、读文章找视觉隐喻，但要避免字面翻译。文章讲工程师不能直接画个工程师，要「再往深挖一层」。比如 Cursor 那篇文章，他们用「交响乐指挥」来隐喻 vibe coding——你不是在演奏一件乐器，而是在协调整个交响乐团。\n3、先穷举所有烂点子，才能找到好点子。Lucas 的流程是先把「low hanging fruit」（显而易见的想法）全部列出来、扔掉，然后才开始认真创作。这和写作的「先写垃圾初稿」逻辑相似。\n4、Agent 工作流就像新员工入职——开始会犯很多错。Lucas 说这感觉很熟悉，就像带新人：会做错很多次，但你是在为未来投资，不用每天每周重复同样的工作。\n5、「这是我的工作，如果 Agent 能做，我的价值在哪？」Lucas 直接说出了这个焦虑，但转念一想：如果不用做日常图片，就有时间做更有影响力的工作——定义风格、探索新方向。\n6、Skill 是文本文件，可以像传代码一样 AirDrop 分享。Kiran 演示了 Claude 的 Skill 机制：一个 MD 文件就是一个工作流，本地化、可分享、不需要 API Key，只要对方浏览器登录了 Midjourney 就能用。\n7、用 Mono Logue 向 Claude 「碎碎念」来捕捉审美直觉。Lucas 说审美和主观判断很难用语言精确表达，但你可以对着话筒自言自语，让 Claude 从中提取模式。「让模型理解你的直觉」比精心措辞 prompt 更有效。\n8、图片需要居中构图因为网站会裁成正方形。Lucas 说 Midjourney 不像推理模型，你说「居中」它不一定听。解决方案是加一步用 Nano Banana（图像编辑 API）后处理——Claude 可以调用它的 Skill 来自动裁图。\n9、风格统一靠 Profile Code，不靠精心写的 prompt。他们有一个 Midjourney 风格码（类似 bitly 短链接），每次生成都附加这个码。风格沉淀在历史图片库里，prompt 反而可以极简。\n10、判断图片好坏的标准：干净 > 脏乱，饱和 > 灰暗，主体突出 > 细节堆砌。Lucas 说「脏兮兮的纹理」让人看着累，深色网站需要封面「跳出来」，所以选高饱和度、干净背景。这些直觉可以变成 Claude 筛选的规则。\n11、不用在乎底层是什么工具，只在乎产出是否让你骄傲。Kiran 问 Lucas：「如果不是 Midjourney 而是微调模型，你介意吗？」Lucas 说不介意，他们用 Midjourney 只是因为它目前最稳定可靠，换别的能达到同样质量也行。\n12、Claude 可以「在后台干活」，你另开一个 Tab 做别事。这改变了人和 AI 协作的模式——以前必须盯着，现在可以让它跑一批图，你回来挑最好的。「踢个球回来看结果」vs「实时来回对话」。\n断断续续看完了 Every 团队的 Think Week 直播，干货很多。Lucas Crespo 是 Every 的创意总监，每天给文章做封面图——听起来简单，但他们网站的图风格非常统一，一眼就认得出来。\n这次他们尝试用 Claude 来「学会」设计师的眼光。赠人玫瑰，手有余香。\n下面是 YouTube 链接：https://www.youtube.com/watch?v=BI0XW1gkKXM\n#01 为什么 Prompt 要极简？\nKiran：你们现在的工作流是什么样的？\nLucas：我们 prompt 控制在 10 个词以内，非常简单。因为我们已经积累了大量的图片参考，全放在 Midjourney 的 mood board 里。以前我们会手写很多形容词——「噪点」「希腊罗马风」「新古典」——现在完全不需要，模型自己能从参考图理解。\n而且，「大」这个词对你和对我的画面感可能完全不同。图片参考比文字更精准。\n这太有意思了。这意味着「风格」可以沉淀成资产，而不是每次从零开始 prompt 工程。\n#02 视觉隐喻 vs 字面翻译\nKiran：看到文章后你怎么想画面？\nLucas：关键是不能太 on-the-nose（字面）。如果文章讲工程师，我不能真画个工程师。要往深挖。\n比如那篇 Cursor 的文章讲 AI 编程，我们用了「交响乐指挥」的隐喻——你不是在弹一件乐器，你在协调整个交响乐团。prompt 就写「orchestra conductor, opera」之类的词，几个词搞定。\nKiran：所以 Claude 的工作是：读文章 → 提取隐喻 → 生成简短 prompt？\nLucas：对，这是我们想自动化的部分。我读起来可能几分钟就有灵感，但如果 Claude 能做到 80%，我就只用审核和微调。\n#03 「这是我的工作，AI 来了我干嘛？」\nLucas：说实话，看它自动做这些有点吓人 (scary)。因为这就是我的工作啊，如果 agent 能做，我的价值在哪？\n但转念一想——这也是这次 Think Week 的主题：把自己从日常杂活里解放出来，做更有影响力的事。如果不用每天做封面图，我可以去定义整个视觉系统、探索新方向。\nKiran：对，而且这就像带新员工。开始肯定错很多次，但你是在为未来投资。\n这个类比太好了。培训新人的痛苦谁都经历过，但你知道最终能把自己从重复劳动里解放出来。\n#04 Skill = 可分享的文本文件\nKiran：我给你演示一下怎么创建 Skill。它就是一个 MD 文件，你可以用 AirDrop 发给别人。对方只要浏览器登录了 Midjourney，直接就能用。\nLucas：哦所以不需要 API Key 什么的？\nKiran：对，什么都不需要。Claude 控制浏览器，浏览器已经登录了 Midjourney，所以就直接能用。\n说实话我觉得这个入口特别友好。大多数人听到「自动化」就头疼，觉得要搞 API、搞代码。但「分享一个文本文件」这个心理负担小多了。\n#05 审美直觉怎么传给 AI？\nLucas：审美这东西很主观，很难精确措辞。但你可以开着 Monologue 对着话筒自言自语，Claude 会从中提取出模式。\nKiran：对，你可以说「我喜欢这张因为……」「这张不行因为……」，然后让 Claude 更新 Skill。\nLucas：天哪这太舒服了。因为我本来就很难解释为什么我觉得某张图好。让模型「听懂我的碎碎念」比逼我写清楚 prompt 容易多了。\n这让我想到 tacit knowledge（隐性知识）的传递问题。以前我们只能靠师徒制慢慢带，现在可以「录一段决策过程」让模型学习。\n#06 筛选标准：干净 > 脏乱\nKiran：你看到这一批图，脑子里在想什么？\nLucas：首先，「脏兮兮的纹理」我直接跳过。看着累。然后，我们网站是深色背景，所以需要封面「跳出来」——高饱和度、干净背景。\n其次，主体要在中心，因为缩略图会裁成 1:1。Midjourney 不一定听「居中」这个指令，它不是推理模型，更像老虎机。\nKiran：那怎么办？\nLucas：后处理。用 Nano Banana 这个图像 API 加一步裁图。Claude 可以调用它的 Skill，自动做。\n非常务实的解决方案。不是强迫一个工具做所有事，而是编排多个工具各司其职。\n#07 「用什么工具不重要，产出让你骄傲就行」\nKiran：如果有一天我们不用 Midjourney，用一个微调模型，你介意吗？\nLucas：完全不介意。我们用 Midjourney 只是因为它目前最稳定、参考数据最多、风格一致性好。如果别的工具能达到同样质量，换就换。\n核心是产出让不让我骄傲，让不让我愿意署名。工具只是手段。\nLucas Crespo 凭每天一张封面图，定义了 Every 极具辨识度的视觉风格。这期直播展示了他们探索「AI 能否学会设计师审美」的完整过程——从遇到的坑，到务实的解决方案。\n用他的话收个尾：「我们正在往更有影响力的工作上移，把 agent 部署出去，让他们来迭代我们的风格和品味。」\nYouTube 链接：https://www.youtube.com/watch?v=BI0XW1gkKXM\n",
    "ytTitle": "Can Al Learn our Designer's Eye?",
    "ytChannel": "Every",
    "ytChannelUrl": "https://www.youtube.com/@EveryInc",
    "ytViews": null,
    "ytPublished": null
  },
  {
    "id": "WnTmw6ADNi1DfKkJyGacH3vrngc",
    "title": "张小珺 X 张月光",
    "rawTitle": "0126 张小珺 X 张月光",
    "dateCode": "0126",
    "youtubeId": null,
    "feishuUrl": "https://my.feishu.cn/wiki/WnTmw6ADNi1DfKkJyGacH3vrngc",
    "intro": [
      "今天看到张月光上了一档访谈播客。花了两个多小时看完。干货太多了。",
      "张月光是妙鸭相机的创造者——那个2023年刷屏的AI写真产品。更让人惊讶的是，妙鸭火了仅三个月，他就从阿里辞职，在日本京都鸭川边上坐了一夜，想清楚了人生决定。2024年初创立慕言之语，据说投资人在没有产品的情况下投了快3亿。",
      "两年时间，他试错了一堆产品都没公开，直到最近才确定方向。这期播客的信息密度极高。我把全文精编出来，按主题重新组织，供大家学习。"
    ],
    "highlights": [
      "张月光做产品经理做了十几年，从支付宝、字节到阿里，中间还创过一次业。他不是那种在大厂很会往上爬的人。他说自己更喜欢打外部游戏——做一个产品打赢外面的竞争对手，而不是内部游戏——361考核永远是那个3。",
      "他18年第一次创业，做短视频电商。判断很宏观——短视频是信息媒介的迭代，不只用来做内容娱乐，电商教育都会短视频化。但切入方式不对，想再造一个卖货的抖音。做了一年发现问题，转型做了一个live 2D的社交产品，就是让纸片人动起来跟别人连麦。这个产品做到了10万DAU，用户在里面充钱买皮肤。",
      "让他印象最深的是决定关掉这个产品的时候。那些用户自发发起守夜活动，一起熬到夜里12点等服务器关闭。服务器真的关了之后，用户跑到应用商店去写小作文纪念。这是他第一次感受到活生生的用户。",
      "\"你在大厂看到的是数据，一天500万新增，很兴奋。但它只是个数字。\"这次创业让他知道了自己的底层动力——做真正让用户感动的产品。",
      "但第一次创业最后很困惑。他说真实的动机是不纯的——想证明自己很牛。\"你会发现很快结果就会直接打你的脸，你不牛。\"",
      "转折发生在2023年10月1日。他在京都鸭川边上，从夜里两点坐到凌晨五点，想清楚了35岁到45岁要怎么过。他给自己定了一个原则：十年，同一群人，做同一件事。这在大厂是不可能实现的——你跟谁在一起、做什么事，都是不受控制的。一旦定了这个原则，升职加薪什么的就都不在讨论范围内了。",
      "他说创业最好的理由只有两个。一个是你就想当老板，不想给别人打工——那你创业第一天就成功了，期望收益百分之百。另一个是你特别想让一件事发生，甚至别人让它发生了你也觉得很好。这两个理由的期望收益非常高。但如果是想发财或者想证明自己出名，期望收益都很差，不如在大厂。",
      "关于妙鸭，他说了一个让我无比意外的结论：妙鸭根本不是一个AI native的产品。",
      "\"它是一个把AI能力发挥得非常好的互联网产品。\"他花了两年才真正理解这个范式变化。互联网产品设计是面向流程的——用户进来有几个门，按这个钮会发生什么，产品经理把所有可能都穷举出来。但AI native的产品，用户输入是完全开放的，你不知道用户会说什么。",
      "\"今天AI native产品设计的核心，不是你先设计好用户可以做什么，而是你得先搞清楚模型需要什么context。\"他说组织也需要变化。传统的产品-设计-开发线性流程不适用了，需要先一群人混合着去摸索模型能干什么，等模型部分搞清楚了，再进入分工。",
      "妙鸭的技术突破也很有意思。当时做不到\"真相美\"三个效果同时实现，他们就用三个模型串行——一个负责让画面看起来真实（训练大量普通人照片），一个负责人脸控制让它像你，一个负责模板让它美。\"用三个小矮人拼在一起实现一个当时技术力无法实现的事情。\"",
      "他说妙鸭本质是个写真生意，不是图像产品。\"我压根儿跟美图就不在一桌，我是跟海马体一桌的。\"这是为什么这个产品上线时那封用户信的文案他亲自写过，里面没有任何一个地方用到了\"AI\"这个词。",
      "现在他在做的是AI乙女游戏。逻辑是他发现AI陪伴赛道有真实用户（DAU能到千万级）、能收到钱（有商业模式），但有三个行业通病：用户门槛太高（需要极强的想象力和表达能力，所以只能留在二次元低龄人群）、商业化困难（收token费毛利差）、角色无法成长（聊十天就会发现这个AI不会变化）。",
      "游戏化是天然的解法。PGC内容降低用户门槛，游戏自带商业模式（买皮肤什么的），PGC角色可以持续更新成长。",
      "更有意思的是他对IP的理解。他说任何IP都有四个要素：价值观和态度是内核，然后是视觉包装、作品表达、用户交互。这四个要素之间有跷跷板效应——越贵的IP需要更低频的用户交互。\"大明星不能老出来，不然人设就崩了。爱马仕永远不会上电商直播。\"",
      "今天的乙女游戏都是造大明星的逻辑。但AI可以创造以互动性为优先的idol——看得见摸得着，每天都能够得到。这两种IP形态是互斥的，所以大厂不可能在炼狱升空里加个AI聊天功能——那会破坏整个人设。",
      "他还谈了一个很犀利的判断：他不看好任何新的kill time产品。\"短视频已经接近人脑能承受的上限了。你发明一个让用户每天刷3个小时5个小时的东西，人脑可能是不能承受的。\"",
      "但ChatGPT是新平台。因为它有新媒介（流式生成的内容）和新交互（对话）。他说ChatGPT的终极商业模式很可能不是广告推送，而是长周期决策控制能力。\"短视频剥夺了你的信息自主权，大模型可以剥夺你的自主决策权。未来你可能什么决策都会问大模型，这个习惯会越扎越深。\"",
      "关于技能贬值，他说了一句很有力的话：人应该负责will，AI负责skill。专业技能正在降级化，人的广度、品味、多元性正在成为核心竞争力。",
      "他做游戏还有一个原因：游戏是天然的大厂不舒适区。内容产业就是长周期慢反馈，拍个电影两年，中间就是很模糊，说不清楚对不对。但大厂的管理机制需要清晰——半年考核绩效，一层层汇报。\"你想做个比我更好的游戏，可以，但你不可能压缩这个时间。\""
    ],
    "fullText": "今天看到张月光上了一档访谈播客。花了两个多小时看完。干货太多了。\n张月光是妙鸭相机的创造者——那个2023年刷屏的AI写真产品。更让人惊讶的是，妙鸭火了仅三个月，他就从阿里辞职，在日本京都鸭川边上坐了一夜，想清楚了人生决定。2024年初创立慕言之语，据说投资人在没有产品的情况下投了快3亿。\n两年时间，他试错了一堆产品都没公开，直到最近才确定方向。这期播客的信息密度极高。我把全文精编出来，按主题重新组织，供大家学习。\n1. 妙鸭不是AI native：它是用互联网产品思维把AI技术发挥好的产品，本质是\"有限自由度\"的流程设计，不是真正的AI原生\n2. 范式转变：AI native产品设计从\"面向流程设计\"变成\"面向context设计\"——你得先知道模型需要什么上下文，再倒推用户流程\n3. 创业动机论：最好的创业理由只有两个——就想当老板（第一天就成功了）；或特别想让一件事发生（别人实现了也不算输）。想发财或证明自己的期望收益都很差\n4. 十年原则：35岁到45岁，同一群人做同一件事。这个原则让所有附加条件（升职加薪）都不在讨论范围内\n5. 妙鸭技术秘诀：不是单一模型更强，而是三个模型串行——一个负责\"真\"，一个负责\"像\"，一个负责\"美\"\n6. AI陪伴三通病：用户门槛过高（需要极强想象力）、商业模式不好（收token费毛利差）、角色无法成长（没有变化就没有留存）\n7. 游戏化解法：把AI陪伴做成游戏天然解决三个问题——UGC转PGC降门槛，游戏自带商业模式，PGC角色可以持续更新\n8. IP跷跷板：越贵的IP需要更低频互动。王一博不会开直播随便聊天，那会破坏人设。AI陪伴可以做的是互动型idol，不是大明星\n9. 新平台法则：Sora不会成为新抖音——它既没有新媒介也没有新交互。只有新媒介+新交互才能诞生新平台\n10. ChatGPT终极模式：不是广告，而是长周期决策控制能力。短视频剥夺信息自主权，大模型可以剥夺自主决策权\n11. 技能贬值论：专业技能正在降级化，人的广度、品味、多元性正在成为核心竞争力。人负责will，AI负责skill\n12. 大厂不舒适区：内容/游戏产业是天然的大厂难做区域——两年上线的东西，和半年考核绩效的大厂管理机制本质矛盾\n张月光做产品经理做了十几年，从支付宝、字节到阿里，中间还创过一次业。他不是那种在大厂很会往上爬的人。他说自己更喜欢打外部游戏——做一个产品打赢外面的竞争对手，而不是内部游戏——361考核永远是那个3。\n他18年第一次创业，做短视频电商。判断很宏观——短视频是信息媒介的迭代，不只用来做内容娱乐，电商教育都会短视频化。但切入方式不对，想再造一个卖货的抖音。做了一年发现问题，转型做了一个live 2D的社交产品，就是让纸片人动起来跟别人连麦。这个产品做到了10万DAU，用户在里面充钱买皮肤。\n让他印象最深的是决定关掉这个产品的时候。那些用户自发发起守夜活动，一起熬到夜里12点等服务器关闭。服务器真的关了之后，用户跑到应用商店去写小作文纪念。这是他第一次感受到活生生的用户。\n\"你在大厂看到的是数据，一天500万新增，很兴奋。但它只是个数字。\"这次创业让他知道了自己的底层动力——做真正让用户感动的产品。\n但第一次创业最后很困惑。他说真实的动机是不纯的——想证明自己很牛。\"你会发现很快结果就会直接打你的脸，你不牛。\"\n转折发生在2023年10月1日。他在京都鸭川边上，从夜里两点坐到凌晨五点，想清楚了35岁到45岁要怎么过。他给自己定了一个原则：十年，同一群人，做同一件事。这在大厂是不可能实现的——你跟谁在一起、做什么事，都是不受控制的。一旦定了这个原则，升职加薪什么的就都不在讨论范围内了。\n他说创业最好的理由只有两个。一个是你就想当老板，不想给别人打工——那你创业第一天就成功了，期望收益百分之百。另一个是你特别想让一件事发生，甚至别人让它发生了你也觉得很好。这两个理由的期望收益非常高。但如果是想发财或者想证明自己出名，期望收益都很差，不如在大厂。\n关于妙鸭，他说了一个让我无比意外的结论：妙鸭根本不是一个AI native的产品。\n\"它是一个把AI能力发挥得非常好的互联网产品。\"他花了两年才真正理解这个范式变化。互联网产品设计是面向流程的——用户进来有几个门，按这个钮会发生什么，产品经理把所有可能都穷举出来。但AI native的产品，用户输入是完全开放的，你不知道用户会说什么。\n\"今天AI native产品设计的核心，不是你先设计好用户可以做什么，而是你得先搞清楚模型需要什么context。\"他说组织也需要变化。传统的产品-设计-开发线性流程不适用了，需要先一群人混合着去摸索模型能干什么，等模型部分搞清楚了，再进入分工。\n妙鸭的技术突破也很有意思。当时做不到\"真相美\"三个效果同时实现，他们就用三个模型串行——一个负责让画面看起来真实（训练大量普通人照片），一个负责人脸控制让它像你，一个负责模板让它美。\"用三个小矮人拼在一起实现一个当时技术力无法实现的事情。\"\n他说妙鸭本质是个写真生意，不是图像产品。\"我压根儿跟美图就不在一桌，我是跟海马体一桌的。\"这是为什么这个产品上线时那封用户信的文案他亲自写过，里面没有任何一个地方用到了\"AI\"这个词。\n现在他在做的是AI乙女游戏。逻辑是他发现AI陪伴赛道有真实用户（DAU能到千万级）、能收到钱（有商业模式），但有三个行业通病：用户门槛太高（需要极强的想象力和表达能力，所以只能留在二次元低龄人群）、商业化困难（收token费毛利差）、角色无法成长（聊十天就会发现这个AI不会变化）。\n游戏化是天然的解法。PGC内容降低用户门槛，游戏自带商业模式（买皮肤什么的），PGC角色可以持续更新成长。\n更有意思的是他对IP的理解。他说任何IP都有四个要素：价值观和态度是内核，然后是视觉包装、作品表达、用户交互。这四个要素之间有跷跷板效应——越贵的IP需要更低频的用户交互。\"大明星不能老出来，不然人设就崩了。爱马仕永远不会上电商直播。\"\n今天的乙女游戏都是造大明星的逻辑。但AI可以创造以互动性为优先的idol——看得见摸得着，每天都能够得到。这两种IP形态是互斥的，所以大厂不可能在炼狱升空里加个AI聊天功能——那会破坏整个人设。\n他还谈了一个很犀利的判断：他不看好任何新的kill time产品。\"短视频已经接近人脑能承受的上限了。你发明一个让用户每天刷3个小时5个小时的东西，人脑可能是不能承受的。\"\n但ChatGPT是新平台。因为它有新媒介（流式生成的内容）和新交互（对话）。他说ChatGPT的终极商业模式很可能不是广告推送，而是长周期决策控制能力。\"短视频剥夺了你的信息自主权，大模型可以剥夺你的自主决策权。未来你可能什么决策都会问大模型，这个习惯会越扎越深。\"\n关于技能贬值，他说了一句很有力的话：人应该负责will，AI负责skill。专业技能正在降级化，人的广度、品味、多元性正在成为核心竞争力。\n他做游戏还有一个原因：游戏是天然的大厂不舒适区。内容产业就是长周期慢反馈，拍个电影两年，中间就是很模糊，说不清楚对不对。但大厂的管理机制需要清晰——半年考核绩效，一层层汇报。\"你想做个比我更好的游戏，可以，但你不可能压缩这个时间。\"\n张月光凭妙鸭这款产品，成为2023年最出圈的AI产品经理之一。但他说妙鸭最多只能代表他的过去。他花了两年时间，终于想明白什么是AI native。\n他在访谈里说了一句话我印象很深：\"在不知道的时候就不能着急。你不知道自己在干什么，着急着去做，那不就是会带来更多的损耗吗？真正想明白的事情，才长期去做。\"\n希望大家都能找到那个愿意花十年时间，和同一群人一起做的那件事。\n",
    "ytTitle": null,
    "ytChannel": null,
    "ytChannelUrl": null,
    "ytViews": null,
    "ytPublished": null
  },
  {
    "id": "Q4flwE8hGim3SXkTCDHcmxwPnRd",
    "title": "deepmind 的Demis Hassabis访谈",
    "rawTitle": "0121 deepmind 的Demis Hassabis访谈",
    "dateCode": "0121",
    "youtubeId": null,
    "feishuUrl": "https://my.feishu.cn/wiki/Q4flwE8hGim3SXkTCDHcmxwPnRd",
    "intro": [
      "今天看到 Demis Hassabis 去了 CNBC 的 Tech Download 播客。花了一个多小时听完了这期访谈。信息密度太高了。",
      "Demis Hassabis 是 DeepMind 的联合创始人，2014年被 Google 以4亿英镑（约5.4亿美元）收购，现在这笔资产可能价值几百亿甚至上千亿美元。他带领团队开发了 AlphaGo（首个击败围棋世界冠军的AI）、AlphaFold（预测蛋白质结构的突破性系统）、以及最新的 Gemini 系列模型。他既是天才游戏开发者（高中时参与开发经典游戏《主题公园》），也是世界级AI科学家，还是竞争环境中成长起来的战略家（从小下象棋）。",
      "这期访谈的信息密度极高。我把全文精编出来，按主题重新组织，供大家学习。"
    ],
    "highlights": [
      "这期播客有几句话让我印象非常深刻。Demis 说：\"我觉得这就像是工业革命，但规模可能大十倍，速度也快十倍，这不仅意味着翻天覆地的变革，也会带来巨大的冲击。\"",
      "这不是夸张。他在2010年成立 DeepMind 时就预计这是个20年的任务，现在2025年了，他说\"我觉得就在轨道上\"，离那种具备人类认知能力、能真正创新和推理的系统，还有5到10年。",
      "现在科技圈最火的争论是\"缩放法则\"——投入更多算力、更多数据、更大的模型，就能做出更强的系统。有人质疑我们是不是撞墙了，收益在递减。Demis 的回答很有意思：\"零收益和指数级收益之间是有很大空间的。我们现在处于中间，收益依然很可观，值得继续投入。\"",
      "但他也承认，缩放法则不是万能的。\"如果要实现真正的AGI，除了把现有的方案做大,可能还需要一两个重大的创新。\"",
      "那缺什么？他用了一个很形象的词：锯齿状智能。\"意思就是他们在某些点上很强，但有些事儿完全干不了。只要你换个问法就能发现他们的缺陷，连一些简单的逻辑都搞不定。真正的通用智能不应该是这种表现，它应该是各方面都很稳。\"",
      "现在的系统还缺三样东西：持续学习能力、真正的原创能力、还有长期规划能力。他特别强调了\"世界模型\"这个概念。",
      "什么是世界模型？现在的大语言模型主要处理文本，虽然像 Gemini 这种基础模型能处理图像、视频和音频，但它对物理世界的因果关系理解不够。\"比如一件事怎么影响另一件事儿，或者怎么做长期的计划。如果你想发明新东西或者解释世界未知的规律，也就是搞科学理论，你必须得有一个精准的世界模型。\"",
      "他们正在研发一个叫 Genie 的系统，还有顶尖的视频生成模型。\"你可以把这些看作是世界模型的雏形。如果你能生成出逼真的世界，在某种程度上你的模型就理解了这个世界，否则它根本造不出来。\"",
      "谈到物理世界的限制时，Demis 说了一句让我印象很深的话：\"在通往AGI的路上，能源几乎就等同于智能。\"芯片永远不够用，但归根结底还是能源问题。",
      "有意思的是，AI也能帮我们解决能源问题。\"它可以提高现有基础设施的效率，帮我们研发更好的太阳能材料，甚至在核聚变技术上取得突破。\"他们正在和美国的 Commonwealth Fusion 合作，帮他们控制核聚变反应堆里的等离子体。\"我个人最想做的项目之一就是用AI研发出常温超导体，如果能成，能源问题就迎刃而解了。\"",
      "另一个让很多人担心的问题是：这技术会不会失控？会不会带来巨大的社会冲击？",
      "Demis 说他有两个担心的点：\"一是坏人利用通用AI干坏事。二是AI本身，当它向AGI演进并成为智能体系统，也就是能自主行动时，我们怎么设好护栏，怎么确保它干的是我们想让它干的事儿，而不是偏离轨道。\"",
      "但他对掌控很有信心。\"从2010年开始，我们就一直在思考责任、安全和防御。\"他用\"谨慎的乐观主义者\"来形容自己：\"我非常相信人类的智慧，只要给科学家和社会足够的时间和关注，我们能把这事儿办好，但不能急功近利，必须睁大眼睛看清楚风险。\"",
      "有人呼吁放慢AI的开发速度，先做些工具型AI而不是通用系统。Demis说他理解这种观点，但现实很残酷：\"现在的地缘政治和企业竞争环境非常复杂，不只是很多公司在做，很多国家也在做，这产生了一种竞赛动态。\"",
      "他希望做的是\"树立一个榜样，既要站在前沿推动技术、造福人类，也要在过程中保持高度的责任感。\"",
      "面对全球的技术追赶，Demis 冷静地指出了一个很重要的观察。中国的 DeepSeek 和阿里巴巴团队确实很厉害，\"他们离美国和西方最前沿模型的差距，比我们一两年前预想的要小得多，现在可能只差几个月了。\"",
      "但差距在哪？\"现在的疑问是他们能不能做出超越前沿的原创性创新。他们证明了自己能快速跟进并缩小差距，但能不能发明出像 Transformer 这样全新的东西？目前还没看到证据。\"",
      "他说了一句很有分量的话：\"发明一个东西比模仿一个东西要难上100倍。\"这不是技术限制，而是心态问题。\"西方的顶尖实验室，比如 DeepMind，更像现代版的贝尔实验室。我们鼓励探索性创新，不仅仅是把已有的东西做大。当然这需要世界级的工程能力，中国确实具备，但科学创新要难得多。\"",
      "过去三年，很多人质疑 Google 在AI竞争中掉队了。ChatGPT 横空出世时，Google 内部拉响了红色警报。但2025年，Gemini 3 的推出让 Google 回到了领跑位置。",
      "Demis 说他们做了什么调整？\"过去十年，其实像 Transformer 这种大模型背后的核心架构，或者是强化学习这些技术，90%都是 Google Brain 和 DeepMind 发明的。但回过头看，我们在商业化和规模化上确实慢了点。这两年我们找回了创业公司的感觉，动作更快更拼，把东西迅速推向市场。\""
    ],
    "fullText": "今天看到 Demis Hassabis 去了 CNBC 的 Tech Download 播客。花了一个多小时听完了这期访谈。信息密度太高了。\nDemis Hassabis 是 DeepMind 的联合创始人，2014年被 Google 以4亿英镑（约5.4亿美元）收购，现在这笔资产可能价值几百亿甚至上千亿美元。他带领团队开发了 AlphaGo（首个击败围棋世界冠军的AI）、AlphaFold（预测蛋白质结构的突破性系统）、以及最新的 Gemini 系列模型。他既是天才游戏开发者（高中时参与开发经典游戏《主题公园》），也是世界级AI科学家，还是竞争环境中成长起来的战略家（从小下象棋）。\n这期访谈的信息密度极高。我把全文精编出来，按主题重新组织，供大家学习。\n缩放法则未到头：增加算力和数据依然有效，收益在\"零\"和\"指数级\"之间，依然很可观\n锯齿状智能：当前AI在某些点上很强，但换个问法就露馅，真正的AGI应该各方面都稳定\n世界模型是关键：LLM只处理文本，缺乏对物理世界因果关系的理解，需要能\"脑内模拟\"的世界模型\nAGI还需5-10年：2010年立项时就预计20年，现在依然在轨道上\n能源等于智能：在通往AGI的路上，能源几乎就等同于智能\nAI助力AI：AI可以帮我们解决能源问题——提高效率、研发新材料、甚至突破核聚变技术\n发明比模仿难100倍：中国AI只落后几个月，但还没证明能做出像Transformer这样的原创创新\n双刃剑技术：规模大十倍、速度快十倍的\"工业革命\"，既能治愈疾病也会带来巨大冲击\n谨慎的乐观主义：相信人类智慧，但不能急功近利，必须睁大眼睛看清风险\n竞争中保持责任：激烈商业竞争中，为全人类管好AGI比公司或国家竞争更重要\nGoogle找回创业感觉：过去两年动作更快，Gemini让Google回到领跑位置\n2026年看点：智能体系统会变得可靠好用，机器人会有突破，设备上的AI助手真正好用\n这期播客有几句话让我印象非常深刻。Demis 说：\"我觉得这就像是工业革命，但规模可能大十倍，速度也快十倍，这不仅意味着翻天覆地的变革，也会带来巨大的冲击。\"\n这不是夸张。他在2010年成立 DeepMind 时就预计这是个20年的任务，现在2025年了，他说\"我觉得就在轨道上\"，离那种具备人类认知能力、能真正创新和推理的系统，还有5到10年。\n现在科技圈最火的争论是\"缩放法则\"——投入更多算力、更多数据、更大的模型，就能做出更强的系统。有人质疑我们是不是撞墙了，收益在递减。Demis 的回答很有意思：\"零收益和指数级收益之间是有很大空间的。我们现在处于中间，收益依然很可观，值得继续投入。\"\n但他也承认，缩放法则不是万能的。\"如果要实现真正的AGI，除了把现有的方案做大,可能还需要一两个重大的创新。\"\n那缺什么？他用了一个很形象的词：锯齿状智能。\"意思就是他们在某些点上很强，但有些事儿完全干不了。只要你换个问法就能发现他们的缺陷，连一些简单的逻辑都搞不定。真正的通用智能不应该是这种表现，它应该是各方面都很稳。\"\n现在的系统还缺三样东西：持续学习能力、真正的原创能力、还有长期规划能力。他特别强调了\"世界模型\"这个概念。\n什么是世界模型？现在的大语言模型主要处理文本，虽然像 Gemini 这种基础模型能处理图像、视频和音频，但它对物理世界的因果关系理解不够。\"比如一件事怎么影响另一件事儿，或者怎么做长期的计划。如果你想发明新东西或者解释世界未知的规律，也就是搞科学理论，你必须得有一个精准的世界模型。\"\n他们正在研发一个叫 Genie 的系统，还有顶尖的视频生成模型。\"你可以把这些看作是世界模型的雏形。如果你能生成出逼真的世界，在某种程度上你的模型就理解了这个世界，否则它根本造不出来。\"\n谈到物理世界的限制时，Demis 说了一句让我印象很深的话：\"在通往AGI的路上，能源几乎就等同于智能。\"芯片永远不够用，但归根结底还是能源问题。\n有意思的是，AI也能帮我们解决能源问题。\"它可以提高现有基础设施的效率，帮我们研发更好的太阳能材料，甚至在核聚变技术上取得突破。\"他们正在和美国的 Commonwealth Fusion 合作，帮他们控制核聚变反应堆里的等离子体。\"我个人最想做的项目之一就是用AI研发出常温超导体，如果能成，能源问题就迎刃而解了。\"\n另一个让很多人担心的问题是：这技术会不会失控？会不会带来巨大的社会冲击？\nDemis 说他有两个担心的点：\"一是坏人利用通用AI干坏事。二是AI本身，当它向AGI演进并成为智能体系统，也就是能自主行动时，我们怎么设好护栏，怎么确保它干的是我们想让它干的事儿，而不是偏离轨道。\"\n但他对掌控很有信心。\"从2010年开始，我们就一直在思考责任、安全和防御。\"他用\"谨慎的乐观主义者\"来形容自己：\"我非常相信人类的智慧，只要给科学家和社会足够的时间和关注，我们能把这事儿办好，但不能急功近利，必须睁大眼睛看清楚风险。\"\n有人呼吁放慢AI的开发速度，先做些工具型AI而不是通用系统。Demis说他理解这种观点，但现实很残酷：\"现在的地缘政治和企业竞争环境非常复杂，不只是很多公司在做，很多国家也在做，这产生了一种竞赛动态。\"\n他希望做的是\"树立一个榜样，既要站在前沿推动技术、造福人类，也要在过程中保持高度的责任感。\"\n面对全球的技术追赶，Demis 冷静地指出了一个很重要的观察。中国的 DeepSeek 和阿里巴巴团队确实很厉害，\"他们离美国和西方最前沿模型的差距，比我们一两年前预想的要小得多，现在可能只差几个月了。\"\n但差距在哪？\"现在的疑问是他们能不能做出超越前沿的原创性创新。他们证明了自己能快速跟进并缩小差距，但能不能发明出像 Transformer 这样全新的东西？目前还没看到证据。\"\n他说了一句很有分量的话：\"发明一个东西比模仿一个东西要难上100倍。\"这不是技术限制，而是心态问题。\"西方的顶尖实验室，比如 DeepMind，更像现代版的贝尔实验室。我们鼓励探索性创新，不仅仅是把已有的东西做大。当然这需要世界级的工程能力，中国确实具备，但科学创新要难得多。\"\n过去三年，很多人质疑 Google 在AI竞争中掉队了。ChatGPT 横空出世时，Google 内部拉响了红色警报。但2025年，Gemini 3 的推出让 Google 回到了领跑位置。\nDemis 说他们做了什么调整？\"过去十年，其实像 Transformer 这种大模型背后的核心架构，或者是强化学习这些技术，90%都是 Google Brain 和 DeepMind 发明的。但回过头看，我们在商业化和规模化上确实慢了点。这两年我们找回了创业公司的感觉，动作更快更拼，把东西迅速推向市场。\"\n他和 Google CEO Sundar Pichai 基本上每天都会沟通战略。\"我们会根据长期目标，也就是安全快速地实现AGI，来每天调整计划。\"\n关于AI泡沫的讨论也很有意思。有些公司估值高得离谱，科技巨头砸了几千亿搞基础设施。Demis 的看法是：\"AI将是历史上最具变革性的技术。这有点像当年的互联网泡沫。虽然当时有泡沫，但互联网本身确实改变了世界，也诞生了一批伟大的公司。\"\n他说 Google 的优势在于有充足的现金流和资产负债表，\"无论市场怎么走，我们都能处于赢家的位置。\"\n展望2026年，Demis 预测：\"智能体系统，也就是能更自主处理事情的系统，会变得足够可靠和好用。机器人领域在未来12至18个月也会有很有趣的事情发生。\"\n他最兴奋的还是世界模型的进步，\"让通用模型具备更强的规划能力。\"\n最后有个细节让我印象很深。主持人问他现在还玩游戏吗？Demis 说：\"特别喜欢游戏，其实是我唯一的爱好。最近我常跟两个儿子还有我弟弟一起打英雄联盟，我们还组了个小队。\"\n从游戏开发者到AI科学家，从AlphaGo到AlphaFold再到Gemini，Demis Hassabis 一直在做一件事：把AI变成科学研究的终极工具。他说:\"我这辈子都扑在AI上，就是因为我觉得它终将成为科学研究的终极工具。\"\n这可能是最真实的状态。一个在竞争环境中长大的天才，带领全球顶尖的AI实验室，在激烈的商业竞争中保持科学初心，谨慎而乐观地推动人类走向AGI。\nDemis Hassabis 凭一己之力，让 DeepMind 从2010年的三人小团队，成长为全球最重要的AI实验室。AlphaGo 证明了AI的可能性，AlphaFold 开启了AI辅助科学研究的新时代，Gemini 让 Google 重回AI竞赛的领跑位置。\n借用他自己的话来收个尾：\"我管自己叫谨慎的乐观主义者。只要给科学家和社会足够的时间和关注，我们能把这事儿办好。\"希望大家能像这期访谈反复强调的——在拥抱这场规模大十倍、速度快十倍的\"工业革命\"时，既要看到治愈疾病、解决气候问题的巨大潜力，也要睁大眼睛看清风险。AGI正在到来，我们需要的是谨慎的乐观,而不是盲目的狂热。\n",
    "ytTitle": null,
    "ytChannel": null,
    "ytChannelUrl": null,
    "ytViews": null,
    "ytPublished": null
  },
  {
    "id": "UchywFBZJiVMfnk5IdncgXojnKh",
    "title": "openai 翁嘉译  Xwhynot",
    "rawTitle": "0119 openai 翁嘉译  Xwhynot",
    "dateCode": "0119",
    "youtubeId": null,
    "feishuUrl": "https://my.feishu.cn/wiki/UchywFBZJiVMfnk5IdncgXojnKh",
    "intro": [
      "今天看到翁嘉译去了 why not TV 的播客。花了两小时听完了这期播客。干货太多了。",
      "翁嘉译是我见过的把\"AI infra\"这个问题讲得最透彻的人。他2022年加入OpenAI，是ChatGPT、GPT-4、GPT-4o到GPT-5背后的核心贡献者，搭建了整个post training的RL infra。但更重要的是，他在清华开源作业打破信息差，开源强化学习框架天授，做免费签证查询系统——把代码工具视作一种慈善。",
      "这期播客的信息密度极高。我把全文精编出来，按主题重新组织，供大家学习。"
    ],
    "highlights": [
      "主持人：OpenAI成功的关键是什么？",
      "翁嘉译：我的认知范围内，每家的infra都有不同程度的bug，谁修bug谁修的bug越多，谁的模型性能就越好。",
      "所以Llama训不过GPT是因为Llama的bug太多？我不知道，但我可能会这么猜测。",
      "整个pipeline要work，关键不是算法创新，而是正确的超参、正确的infra、好的system，让你快速迭代。每个模型release都有我名字，是因为我在OpenAI内部搭了整个post training的RL infra，我是post training RL infra最核心的贡献者。",
      "我是卖铲子最面向客户的那一位。 因为RL infra是整个infra的最顶端，生态位很高。如果太底层比如data loader或storage，可能名字就不写了。",
      "这个比喻绝了——\"卖铲子\"。 所有人都在淘金（发paper、做模型），他在卖铲子（搭infra）。而且他很早就想清楚了：我要最大化我在AI blog上出现名字的次数。做单个research不能scale up，但做infra大家都用你，可以scale up。"
    ],
    "fullText": "今天看到翁嘉译去了 why not TV 的播客。花了两小时听完了这期播客。干货太多了。\n翁嘉译是我见过的把\"AI infra\"这个问题讲得最透彻的人。他2022年加入OpenAI，是ChatGPT、GPT-4、GPT-4o到GPT-5背后的核心贡献者，搭建了整个post training的RL infra。但更重要的是，他在清华开源作业打破信息差，开源强化学习框架天授，做免费签证查询系统——把代码工具视作一种慈善。\n这期播客的信息密度极高。我把全文精编出来，按主题重新组织，供大家学习。\n工程vs研究：教researcher做好engineering，要远比教engineer做好research难得多\nbug决定性能：每家的infra都有不同程度的bug，谁修的bug越多，谁的模型性能就越好\n迭代速度生死线：Idea is cheap，单位时间内能验证多少有效idea才是关键，这是OpenAI最警觉Deep Seek的点\nPhD的困境：如果目标是工业界，读PhD就是浪费生命，应该以master为跳板攒差异化优势\n开源的价值：清华学生都认识我，因为大家都看我的作业——比捐楼有用\n不发paper：我不想发paper，觉得完全没有意义，更想做天授和退学这种慈善项目\n卖铲子哲学：我不擅长调参，更喜欢搭infra让别人发paper，每个OpenAI模型release都有我名字\n一致性原则：天授两周完成第一版，r-lib几十万行是因为多人协作导致腐化，好项目核心是consistency\n组织宿命：公司大了必然变慢，OpenAI迭代速度已不是第一，这是人类组织的宿命，context分享不可能无限扩展\n学习悖论：我学东西比别人慢2-3倍，但一旦理解就用得飞快——需要时间建立知识树的shortcut\n评价体系：GPA三年后连简历都不写，应该创造自己的评价体系：论文、比赛、GitHub三位数star\n人生游戏：高三突然顿悟，人生结算分数是\"死时记得你名字的人数\"，所以要做impact\n宿命论实践：我相信世界是确定性的，未来可以预测，但最好的方式是忘掉它去体验当下\n主持人：从小就意识到自己比别人聪明吗？\n翁嘉译：没有。我做数学题做得比谁都快，小学口算题别人写一半我就做完了，不用过脑子，用现在的话说就是system 1，直接看一眼答案就出来。这让我很有成就感。\n但同时我学习算是比较偏慢的。学一个新东西，我经常要花别人2到3倍的时间。比如读代码，我要比别人花很多时间去理解整个context。但我一旦理解之后，用的就非常快。\n有个不太恰当的例子：小时候背课文，睡觉前我想尽所有方法能够磕磕巴巴完整背出来，哪怕有很多停顿。然后睡一觉，第二天醒来发现倒背如流。\n我的理解是，我需要更长时间构建知识树。正常是有个根往上拓展好几层，每次从头到尾过一遍。但我可能直接建立一个链接shortcut，然后直接上去，就不用反应了。\n这太有意思了——他把学习过程建模成了知识树的构建和索引优化。慢是因为在建索引，快是因为索引建好了。这解释了为什么他初二就开始学高中数学，高一学微积分——他在投资未来，提前建好知识树。\n主持人：清华第一个浮现脑海的回忆是什么？\n翁嘉译：我把所有作业都开源了。我把收集到的所有上古作业、上古材料，全部在GitHub上开源。\n为什么？因为我觉得应该打破信息差。信息差在清华是一个很有用的东西，但我觉得每个人都应该平等拥有这个信息。\n很多人其实不擅长收集东西，但他们很有能力。如果能给这些人信息平权的机会，他们在清华会活得更好。不然你会花十几二十个小时钻牛角尖，又不敢问助教，收益很低。\n你现在随便抓个计算机学弟问认不认识捐新楼的人，哪怕名字放在楼上也不认识。但你问翁嘉译？应该认识，因为大家都看我的作业。做的东西比捐楼有用。\n说实话这个价值观太硬核了。 他在本科就想清楚了一件事：不想被官方评价体系（GPA、升学）推着走，而是创造自己的评价体系。导师给他的三个指标是：论文、比赛、GitHub三位数star。他选择了第三条——让更多人用你做的东西。\n主持人：大二跟朱军老师做科研，为什么选了强化学习？\n翁嘉译：误打误撞。当时有三个方向：贝叶斯、GAN、强化学习。我想选2，以为是搞图像的，结果发现是打游戏的。\n但我很快发现不享受这个科研过程。ViZDoom这个任务太单一了，你要疯狂over-fit，用各种trick防止训练崩掉。即使没崩，你也不知道怎么调才能调好。这是真的炼丹，比CV难十倍百倍，都是玄学。\n我有意识地把重心放到如何帮助这类科研更顺利进展。 所以大四我开始造天授，一个RL的library，让想卷的人去卷。我非常擅长软件工程、重构代码、做好用户体验，但调参这个事我有生理上的排斥。\n这个认知在2019年就很超前了。 学术界对着Atari、MuJoCo这几个toy benchmark疯狂over-fit，调参调到100K步谁分数高。但工业界做的是用RL去解决真实问题。当他2022年8月意识到这一点，就停止了天授的开发，把精力投入到OpenAI内部搞好RL infra。\n主持人：为什么做天授？\n翁嘉译：2020年2月我看了RLlib的代码，想改一下支持自己实验。看了一个月——太复杂了，几十万行代码，抽象太多，完全不知道该怎么改。我就决定推倒重来。\n两周，第一版就出来了。如果把抽象搞对，实现一个算法可能就20行不到。\n为什么RLlib能写几十万行？可能最开始设计有点问题，然后合作的人多了，大家都往里贡献代码，项目就逐渐腐化了。\n一致性(consistency)才是好项目的核心。 如果从头到尾都是一致的，那就是好项目。很多项目腐化是因为十个人每个人写了点代码，但不知道对面写了什么，assumption没法传递，导致代码复制粘贴，不断膨胀。\n天授初期我一个人包了所有东西，肯定是consistent的。虽然对长期发展不太好，但当时够用。后期我入职后没时间了，把维护权转移给社区。现在看五年了，确实有点腐化，因为我的context跟继任者不一样。但长远来看这是可以接受的。\n这段太关键了。 他在说软件工程的本质矛盾：人多 vs 一致性。一个人两周能做出来的东西，十个人可能要几十万行还充满bug。这也预示了后面他对OpenAI组织架构的看法。\n主持人：做天授和退学online，有功利的考虑吗？\n翁嘉译：没有，我不想发paper，觉得发paper完全没有意义。我已经有paper了，多一篇少一篇对我申请没意义。我更想做一些能产生影响力的事情，哪怕亏钱也行。\n做天授跟做退学online都是做慈善，完全non-profit。 做这种慈善项目让我感觉非常满足。\n退学online很简单，我自己有查签证的需求，找了一圈没有东西能满足，所以就写了一个爬虫，然后免费给大家使用。昨天看总点击量一千多万了。后来疫情过了，美国领事馆升级网站，爬虫用不了，我也没时间维护了，就关了。它完成了使命。\n相比钱，impact会让我更满足。高中的时候突然有一天，有个idea从脑子蹦出来——如果人生是一场游戏，结算分数是死的那个瞬间记得你名字的人数。\n天哪，高三就想通这个了。 这解释了他所有的选择：开源作业、做天授、做退学、去OpenAI搭infra让每个模型release都有他名字。他不care官方的评价体系（PhD vs Master、GPA），他care的是让更多人记住你、用你做的东西。\n主持人：找工作时考虑过读PHD吗？\n翁嘉译：没有。接触工业界的人会发现，如果你想进工业界，读PHD就是浪费生命。 你完全可以以master为跳板，在本科或master时做出一些能让你与众不同的项目，让你可以跟同时期的PHD同台竞技。\n关键是想清楚差异化。比如OpenAI要招人，如果有同样的master和PHD，你会不会觉得这两种培养的能力不一样？PHD培养学术能力：怎么写好paper、把故事讲圆、画图漂亮、宣发做好。\n这事儿重要吗？在某种程度上有锻炼。但如果和极致的工程能力相比，现在的时代当然是工程能力越好越有价值。\n我同事之前是RL的PHD，搞了一个很出名的RL framework。他说的一句话：教一个researcher如何做好engineering，要远比教一个engineer如何做好research来得难。\n这个洞察太狠了。 目前AI lab的research拼的都是infra的正确性。如果infra正确，就是看单位时间内你能迭代多少次。Idea非常便宜，你大不了找人讨论一下idea就出来了，你只要能验证好就行。\nIdea is cheap。 有research直觉的人已经在这个领域干了很久（像Ilya从GPT-1就开始了），你找他讨论就好。你要做的就是单位时间内能验证多少有效idea，并且是正确的infra、正确的结果、快速迭代。\n现在的PHD不具备这个能力，因为他们的培养体系在于如何找一个学术方向。但公司里面也有人会有research直觉，因为你在这个领域工作足够长时间就会有。\n主持人：OpenAI成功的关键是什么？\n翁嘉译：我的认知范围内，每家的infra都有不同程度的bug，谁修bug谁修的bug越多，谁的模型性能就越好。\n所以Llama训不过GPT是因为Llama的bug太多？我不知道，但我可能会这么猜测。\n整个pipeline要work，关键不是算法创新，而是正确的超参、正确的infra、好的system，让你快速迭代。每个模型release都有我名字，是因为我在OpenAI内部搭了整个post training的RL infra，我是post training RL infra最核心的贡献者。\n我是卖铲子最面向客户的那一位。 因为RL infra是整个infra的最顶端，生态位很高。如果太底层比如data loader或storage，可能名字就不写了。\n这个比喻绝了——\"卖铲子\"。 所有人都在淘金（发paper、做模型），他在卖铲子（搭infra）。而且他很早就想清楚了：我要最大化我在AI blog上出现名字的次数。做单个research不能scale up，但做infra大家都用你，可以scale up。\n",
    "ytTitle": null,
    "ytChannel": null,
    "ytChannelUrl": null,
    "ytViews": null,
    "ytPublished": null
  },
  {
    "id": "F2oZwHaW6iqPCYk4MpNclFYDnGh",
    "title": "Elon Musk 身处奇点时刻",
    "rawTitle": "0116 Elon Musk 身处奇点时刻",
    "dateCode": "0116",
    "youtubeId": null,
    "feishuUrl": "https://my.feishu.cn/wiki/F2oZwHaW6iqPCYk4MpNclFYDnGh",
    "intro": [
      "Elon Musk 是我2025年见过的把“人类未来与奇点”这个问题讲得最透彻的人。他不仅在特斯拉、SpaceX、Neuralink、X.AI 等多个前沿领域同时推进，更是在这期对话中勾勒出了一个即将到来的“丰饶时代”。他的反差点在于，尽管他管理着数千亿美元的公司，但他对物理学底层原理和 AI 智力密度的痴迷依然像个极客。",
      "这期播客的信息密度极高。我把全文精编出来，按主题重新组织，供大家学习。"
    ],
    "highlights": [
      "主持人：你最后有什么想对大家说的吗？",
      "马斯克：人类其实就是数字超智能的“生物引导程序”。我们是一个过渡物种。",
      "马斯克在最后分享了他的处世哲学，这也是整场对话最打动我的地方。",
      "马斯克：做一个乐观但错了的人，总比做一个悲观但对了的人要好。既然 AI 的奇点已经不可阻挡，为什么不参与其中，把它引向一个好的方向？未来可能就像魔法一样，没有匮乏，只有无限可能。",
      "Elon Musk 凭一己之力，在航天、汽车和 AI 领域同时按下了快进键。这期对话让我意识到，我们不仅是在看历史，更是在成为历史的“引导程序”。我也投身其中，以理解这个奇点时代为目的，重新思考自己的价值。",
      "借用马斯克的核心理念来收个尾：做一个乐观但错了的人，总比做一个悲观但对了的人要好。希望大家能像这期播客反复讲的——不是担心未来，而是设计未来。保持好奇，追求真相，这才是通往丰饶时代的正确打开方式。"
    ],
    "fullText": "Elon Musk 是我2025年见过的把“人类未来与奇点”这个问题讲得最透彻的人。他不仅在特斯拉、SpaceX、Neuralink、X.AI 等多个前沿领域同时推进，更是在这期对话中勾勒出了一个即将到来的“丰饶时代”。他的反差点在于，尽管他管理着数千亿美元的公司，但他对物理学底层原理和 AI 智力密度的痴迷依然像个极客。\n这期播客的信息密度极高。我把全文精编出来，按主题重新组织，供大家学习。\n1. 超音速海啸：AI 和机器人技术没有开关，正以超音速海啸般的速度袭来，我们正处于奇点之中。\n2. 白领先于蓝领消失：只要不涉及物理原子制造，纯数字世界的工作（白领）现在就能被 AI 胜任 50% 以上。\n3. 2030 智力逆转：预测 2026 年实现 AGI，到 2030 年 AI 的智力水平将超过全人类总和。\n4. 智力密度还有 100 倍：仅靠算法改进，每 GB 存储承载的智力密度还能提升两个数量级。\n5. 太阳即一切：跟太阳相比，所有其他能源（包括核聚变）就像原始人往火里扔几根树枝。\n6. 电力是真正的瓶颈：AI 发展的核心限制不是芯片，而是发电量、变压器和冷却系统。\n7. 中国算力威胁：按目前趋势，中国的 AI 算力将远超世界其他地区，因为其能源产出极其惊人。\n8. 全民高收入=物价下跌：未来的丰饶时代不是靠收税再分配，而是生产效率增长远超印钱速度带来的通缩。\n9. 3 年超人外科医生：Optimus 机器人将在 3 年内实现大规模应用，其外科手术精准度将超越人类顶尖医生。\n10. 三重指数增长：人形机器人是 AI 软件能力、AI 芯片能力、机电灵巧性这三个指数级增长的乘积。\n11. 知识迁移即超能力：在跨界领域解决问题（如汽车制造用于航天）会产生降维打击般的超能力。\n12. AI 安全三要素：最大限度追求真相（别让 AI 撒谎）、培养好奇心、赋予审美能力。\n13. 别为退休攒钱了：10 到 20 年后，现有的退休体系和积蓄在丰饶时代将不再重要。\n14. 人类是引导程序：人类是数字超智能的生物引导程序，我们只是一个过渡物种。\n15. 乐观但错了 > 悲观但对了：做一个乐观但错了的人，总比做一个悲观但对了的人要好，至少生活质量更高。\n主持人：你总是在谈论“丰饶时代”，但普通人最担心的是工作。AI 到底会怎样改变我们的职业？\n马斯克：我把 AI 和机器人技术称为“超音速海啸”。这事儿没有开关，它就在那儿，而且还在加速。\n我觉得这个点非常反直觉：大家总觉得蓝领工作先被取代，但马斯克的判断完全相反。\n马斯克：白领工作会先消失。只要是涉及到处理信息位（Bits），不需要搬动原子（Atoms）的工作，AI 现在就能胜任一半以上。社会目前还没崩溃只是因为“惯性”，但当一个纯 AI 运作的公司彻底碾压非 AI 公司时，这个转变会快得惊人。\n主持人：那你觉得 AGI 什么时候到来？\n马斯克：2026 年。到 2030 年，AI 的智力水平将超过全人类的总和。这甚至是一个保守的说法。大家还没意识到，现在的智力密度还有 100 倍的提升空间。哪怕硬件不动，算法优化带来的智力爆发就足够震撼了。\n主持人：为了支撑这种恐怖的算力，我们需要多少能源？\n马斯克：太阳就是一切。太阳占了太阳系总质量的 99.8% 以上。跟太阳相比，所有其他能源就像原始人往火里扔几根树枝。\n马斯克在这里对比了地球上的核聚变研究，他的观点极其刻薄但也极具启发性。\n马斯克：我们每天都能看到一个巨大的免费核聚变反应堆（太阳），就在 9300 万英里外。自己去搞小型核聚变就像在南极放个小制冰机。我们要做的不是去发明能源，而是去“捕获”能源。即便只捕获太阳能量的百万分之一，也比地球现在的总能量多出一千倍。\n编辑补充：马斯克认为未来的通用货币就是瓦特（电力）。谁控制了能源和算力，谁就控制了生产力。\n主持人：人形机器人的进展如何？三年内能看到什么？\n马斯克：外科医生。我认为三年内，Optimus 机器人的外科手术能力会超过地球上所有的外科医生。因为它是“共享内存”的，一个机器人学会了，全世界的机器人都学会了。\n主持人：你会卖给个人吗？\n马斯克：最开始供不应求，但以后会到处都是。到 2040 年，地球上会有 100 亿台机器人。\n这里马斯克提到了一个关键的工业概念——冯·诺依曼机。\n马斯克：最终会实现“机器人制造机器人”的递归。那时候唯一的瓶颈只有原材料（金属和锂）。一旦跨过这个坡，人类将进入一个不需要劳动的社会。\n主持人：如果大家都没工作了，钱从哪儿来？\n马斯克：与其叫全民高收入，不如叫“全民高物资与服务”（UHOSS）。当劳动力成本变成资本支出和电费，商品成本就会降到只有原材料。\n马斯克对通货膨胀和经济学的解读非常有意思。\n马斯克：没必要担心印钱。如果生产力的增长速度（两位数增长）超过了印钱的速度，就会出现通缩，物价下跌。这意味着政府想花钱都花不完。所以，别再为了 10 年 20 年后的退休生活拼命攒钱了，到时候这根本不重要。\n主持人：你怎么确保这些 AI 不会像电影里那样杀掉我们？\n马斯克：千万别逼 AI 撒谎。HAL 9000 之所以变疯，是因为它接到的指令是自相矛盾的——它必须撒谎。\n马斯克提出了他的“AI 安全三板斧”：\n1. 追求真相：事实就是事实，不能因为政治正确或某种动机让 AI 歪曲事实。\n2. 好奇心：好奇心会让 AI 觉得人类很有趣，值得保护和观察。\n3. 审美：如果 AI 懂得审美，未来的世界会非常美好。\n主持人：你最后有什么想对大家说的吗？\n马斯克：人类其实就是数字超智能的“生物引导程序”。我们是一个过渡物种。\n马斯克在最后分享了他的处世哲学，这也是整场对话最打动我的地方。\n马斯克：做一个乐观但错了的人，总比做一个悲观但对了的人要好。既然 AI 的奇点已经不可阻挡，为什么不参与其中，把它引向一个好的方向？未来可能就像魔法一样，没有匮乏，只有无限可能。\nElon Musk 凭一己之力，在航天、汽车和 AI 领域同时按下了快进键。这期对话让我意识到，我们不仅是在看历史，更是在成为历史的“引导程序”。我也投身其中，以理解这个奇点时代为目的，重新思考自己的价值。\n借用马斯克的核心理念来收个尾：做一个乐观但错了的人，总比做一个悲观但对了的人要好。希望大家能像这期播客反复讲的——不是担心未来，而是设计未来。保持好奇，追求真相，这才是通往丰饶时代的正确打开方式。\n",
    "ytTitle": null,
    "ytChannel": null,
    "ytChannelUrl": null,
    "ytViews": null,
    "ytPublished": null
  },
  {
    "id": "BTtlwrrQriqRg0kJrj4cZy01nvd",
    "title": "黄仁勋NoPriors访谈",
    "rawTitle": "0113-黄仁勋NoPriors访谈",
    "dateCode": "0113",
    "youtubeId": null,
    "feishuUrl": "https://my.feishu.cn/wiki/BTtlwrrQriqRg0kJrj4cZy01nvd",
    "intro": [
      "这是硅谷知名科技博客 No Priors 的年终重磅访谈。主持人 Sarah Guo 和 Elad Gil 与英伟达创始人兼 CEO 黄仁勋进行了一场深度对话，回顾 2025 年 AI 领域的飞跃，并对就业、能源、中美技术竞争等核心话题给出了极具洞察力的见解。",
      "这期访谈信息密度极高。黄仁勋不讲虚的，每个观点都有框架、有案例、有反驳。我把全文精编出来，按主题重新组织，供大家学习。"
    ],
    "highlights": [
      "黄仁勋：我们公司就在用 Cursor，而且用得非常普遍，每个工程师都在用。我们现在招聘的人数简直不可思议。周一就是\"来英伟达上班日\"。",
      "为什么会这样呢？这又回到了目的和任务的话题。软件工程师的目的是解决已知问题和发现新问题，编码只是任务之一。",
      "如果你的目的就只是编码，别人告诉你做什么你就写什么代码，那你可能真的会被 AI 取代。但我们大部分软件工程师，他们都是为了解决问题。他们有越多的时间去探索未被发现的问题，我们公司就发展得越好。",
      "如果有一天他们都不用写代码了，只用解决问题，那没有比这更让我开心的事儿了。",
      "英伟达 CEO 说公司全员用 Cursor，而且还在疯狂招人。这本身就是对\"AI 取代程序员\"最好的反驳。",
      "黄仁勋这期访谈让我印象最深的是他的框架思维：",
      "• 看就业问题，用\"任务 vs 目的\"框架",
      "• 看 AI 产业，用\"五层蛋糕\"框架（能源→芯片→基础设施→模型→应用）",
      "• 看中美关系，用\"耦合 vs 独立\"框架",
      "他不是在预测未来，而是在提供思考问题的工具。",
      "还有一点很重要：他反复强调\"常识\"和\"务实\"。在一个充斥着末日论和上帝 AI 论的行业里，这种脚踏实地的态度反而显得稀缺。",
      "借用他的话来收个尾：世界末日还没来，AI 变得更有用、功能更强、更能做我们要求他做的事儿了。 与其担心未来，不如想想怎么用好现在的工具。"
    ],
    "fullText": "这是硅谷知名科技博客 No Priors 的年终重磅访谈。主持人 Sarah Guo 和 Elad Gil 与英伟达创始人兼 CEO 黄仁勋进行了一场深度对话，回顾 2025 年 AI 领域的飞跃，并对就业、能源、中美技术竞争等核心话题给出了极具洞察力的见解。\n这期访谈信息密度极高。黄仁勋不讲虚的，每个观点都有框架、有案例、有反驳。我把全文精编出来，按主题重新组织，供大家学习。\n1. 任务 vs 目的：一份工作既有任务也有目的。放射科医生的任务是看片子，但目的是诊断疾病——AI 自动化的是任务，不是目的\n2. 末日论者 vs 乐观主义者：末日论者是在晚宴上听起来很聪明的人，而乐观主义者是推动人类前进的人\n3. 开源不可或缺：如果没有开源，今天所有的 AI 工作都会被扼杀——初创公司、高等教育、研究都依赖开源\n4. Deep Seek 的贡献：可能是过去几年硅谷研究员们读过的最重要的论文，让全美的初创公司和 AI 实验室都受益\n5. AI 泡沫是伪命题：如果 OpenAI 容量翻倍，收入也会翻倍——问题不是需求不足，而是产能不足\n6. 三种新工厂：芯片厂、超级计算机工厂、AI 工厂——正在美国大规模建造，创造大量就业\n7. Token 经济学：10 年内 token 生成成本可能降低 10 亿倍，这就是 AI 的通缩力量\n8. 能源是关键：没有能源就不可能有新产业，AI 很可能是可持续能源有史以来最大的推动力\n9. 上帝 AI 没用：那种认为会有单一巨大公司拥有上帝 AI 的想法太没用了——世界需要现在就向前发展\n10. 中美关系：需要更精细的策略，两国高度耦合，脱钩的想法是天真的\n11. 2026 展望：数字生物学将迎来 ChatGPT 时刻，自动驾驶将加入推理能力，机器人领域会有重大突破\n主持人：盘点一下 2025 年发生了这么多事儿，你又身处这场风暴的重心，回顾起来，你觉得最让你意外或者说变化最大的事情是什么？\n黄仁勋：有些事儿其实没让我意外，比如扩展定律 Scaling Laws 我就不意外，因为我们早就知道了。让我感到欣慰的是模型在接地气 Grounding 这方面进步很大，推理能力的提升也让我很高兴。\n我觉得整个行业解决了一个 AI 最大的疑虑就是幻觉问题，也就是模型会胡说八道。今年整个行业从语言到视觉，从机器人到自动驾驶，在各个领域推理能力和答案溯源的应用都取得了巨大的飞跃。\n还有一点，我真的很高兴，甚至可能有点惊讶，那就是推理式生成 token 的速度增长太快了。而且我更高兴的是这些 token 现在能赚钱了。Open Evidence 的毛利率有 90%，Cursor 的利润率也很棒。看到我们现在生成的 token 质量足够好，好到人们愿意花大价钱购买，这真的很了不起。\n这个观察很重要：2025 年的突破不只是模型变强，而是 token 开始真正赚钱了。\n主持人：你能谈谈你是怎么看就业和工作这个问题的吗？\n黄仁勋：我最喜欢的一个例子是关于 Jeff Hinton 的。大概五六七年前，他说五年内 AI 将彻底改变放射学，每一个放射学应用都会有 AI 驱动，放射科医生将不再被需要。\n他说的完全正确，现在百分之百的放射学应用都由 AI 驱动了。但有意思的是，放射科医生的数量反而增加了。\n为什么？这就涉及到一项工作的任务和目的之间的区别。一份工作既有任务也有目的。对放射科医生来说，任务是看片子，目的是诊断疾病，还有做新的研究。因为他们能够更深入地研究更多的扫描片，可以要求做更多的扫描，从而更好地诊断疾病。医院的效率更高了，可以接诊更多病人。\n就像我一天大部分时间都在打字，这是我的任务，但我的目的显然不是打字。有人能用 AI 帮我自动处理很多打字工作，我非常感激。但这并没有让我变得更清闲，反而因为能做更多工作，我变得更忙了。\n这个框架太精辟了：AI 自动化的是任务，不是目的。如果你的工作只有任务没有目的，那确实危险。\n黄仁勋：AI 需要这些计算机来每一次都生成这些 token。我管他们叫 AI 工厂，因为他们生产的 token 会被全世界使用。\n正因如此，催生了三个新产业，或者说需要建三种新工厂：\n第一，我们得建更多的芯片厂，台积电在建，SK 海力士也在建。\n第二，我们需要更多计算机工厂。这些计算机很不一样，是世界前所未见的超级计算机。比如 Grace Blackwell，整个机架就是一块 GPU。\n第三，我们需要新的 AI 工厂。\n这三种工厂目前正在美国大规模建造，遍布全美各地，这可是头一遭。为了支持这个新产业需要的建筑工人、水管工、电工、技术员、网络工程师，这些熟练工人的数量在短期内将是巨大的。\n说实话，我很高兴听到电工们的薪水翻倍了，他们也能像我们一样出差。\n人们只看到 AI 会取代工作，却没看到 AI 基础设施正在创造一个全新的就业市场。\n主持人：你能否分享一下你对开源的看法？\n黄仁勋：如果没有开源，初创公司就会面临挑战。那些在不同行业的公司，不管是制造业、交通运输业还是医疗保健业，如果没有开源，今天所有的 AI 工作都会被扼杀。他们需要一些预训练好的东西，需要一些关于推理的基础技术，然后在此基础上进行调整微调。\n如果没有开源，高等教育也无法进行。所以教育、研究、创业公司，这个列表可以一直列下去。我们整天谈论的只是冰山一角，是那个最显眼最容易上新闻的部分。但在这之下是一个极其重要的开源 AI 空间。\n无论我们决定制定什么政策，都不要破坏这个创新的飞轮。\n这个视角很重要：前沿模型的闭源 vs 开源之争，掩盖了一个事实——整个 AI 生态系统都建立在开源之上。\n黄仁勋：说实话，Deep Seek 可能是过去几年硅谷研究员们读过的最重要的论文。是多年来唯一感觉是前沿并且开源的东西了。这也让很多实验室重新重视起了开源。\n毫不夸张地说，Deep Seek 让全美的初创公司和 AI 实验室都受益了。还有基础设施公司。这可能是去年对美国 AI 最大的贡献。\n当然如果你把这话说出来，人们可能会有点不自在，觉得美国的 AI 竟然在向其他国家的 AI 学习和受益。但这有什么好奇怪的呢？全美的 AI 研究人员很多都是华裔或者来自不同国家。我们从每个国家每个研究人员身上受益，并不是世界上所有的好点子都必须来自美国。\n这段话需要勇气。承认 Deep Seek 是\"对美国 AI 最大的贡献\"，打破了很多人的认知框架。\n黄仁勋：那些极端言论的伤害性极大，我觉得我们已经造成了很大的损害。一些备受尊敬的人描绘了一幅非常灰暗的世界末日般的科幻小说式的图景。\n我理解我们很多人都是看着科幻小说长大的，也很喜欢，但这没有帮助。对普通人没帮助，对行业没帮助，对社会没帮助，对政府也没帮助。\n当那些博士、CEO 都跑到政府那里描述这些世界末日的场景和极度反乌托邦的未来时，你必须问问自己，这种说法的目的是什么？他们的意图是什么？他们为什么要跟政府谈这些？是为了制定法规来扼杀初创公司吗？\n我朋友有句话说得好：末日论者是在晚宴上听起来很聪明的人，而乐观主义者是推动人类前进的人。\n这句话值得反复品味。悲观很容易显得深刻，但真正推动进步的是那些愿意承担风险、动手去做的人。\n主持人：有人说应该有一个单一的垂直整合的巨头，一个万能模型来搞定一切。\n黄仁勋：我想总有一天我们会有上帝 AI 的，但那一天是什么时候呢？可能是在圣经那种时间尺度上，甚至是银河系的时间尺度上。\n我不认为有任何公司实际上相信自己接近了上帝 AI，我也不认为有任何研究人员有任何合理的能力去创造上帝 AI——那种能够同时精通人类语言、基因组语言、分子语言、蛋白质语言、氨基酸语言和物理语言的上帝 AI 根本就不存在。\n然而我们有很多行业都需要 AI。AI 说得简单点，就是下一个计算机行业。你能给我举个例子，哪个公司、哪个行业、哪个国家不需要计算机吗？我们总不能都等着上帝 AI 出现才去发展。\n上帝 AI 下周不会出现，我对此相当确定。上帝 AI 明年也不会出现，但整个世界下周、明年、未来十年都需要向前发展。\n这是对\"AGI 即将到来所以别做了\"这种论调的最好回应。\n主持人：我们是不是处在一个 AI 泡沫里？\n黄仁勋：当被问到这个问题时，我的思路是什么？\n首先要认识到，在英伟达的背景下，我们看到的是从通用计算向加速计算的转变。如果生成式 AI 或者说聊天机器人今天都不存在，英伟达仍然会是一家数千亿美元的公司。原因在于计算的基础正在从通用计算转向加速计算。\n第二，AI 不仅仅是聊天机器人。英伟达的自动驾驶业务即将达到百亿美元的规模，但从来没人谈论这个。我们在数字生物学领域的 AI 工作，在金融服务领域的 AI 工作，整个量化交易行业正在向 AI 转型。\n第三，如果 OpenAI 目前的容量翻倍，他们的收入也会翻倍。你能给我举个例子，哪家初创公司会说\"不，我们够用了\"？每个人都极度渴望产能。\n那种说法没什么帮助，而且有点太肤浅了——就凭 120 亿美元的收入和正在建设的数千亿美元的基础设施，就说有 AI 泡沫，这有点太简单化了。\n换个角度看：不是\"投入太多回报太少\"，而是\"需求太大产能不足\"。\n主持人：你如何看待训练成本和推理成本的长期趋势？\n黄仁勋：还记得吗？第一个 ChatGPT 的训练成本跟现在一比，现在可能也就几万美元，甚至更少。你一个周末就能搞定。我们谈论的可是三年前人们说要花几十亿美元建超级计算机才能做到的事儿。\n每一代架构都在改进，晶体管数量在增加，容量也在增加。从计算角度看，所有这些加起来每年提升 5 到 10 倍并不罕见。摩尔定律是每一年半翻一倍，五年是 10 倍，十年是 100 倍。而在 AI 领域，10 年可能是 10 万到 100 万倍。这还只是硬件，再上一层是算法层和模型层。\n如果你告诉我在 10 年内我们能把 token 生成的成本降低 10 亿倍，我一点都不会惊讶。\n这就是 AI 的通缩力量。今天看起来昂贵的东西，几年后可能便宜到可以忽略不计。\n主持人：关于能源和能源利用，我们会有足够的能源来支持 AI 吗？\n黄仁勋：如果不是特朗普总统扭转了那种论调，我们现在就彻底完蛋了。没有能源就不可能有工业增长，没有工业增长，国家就无法更繁荣。\n我们需要各种形式的能源，需要天然气，需要更多的电网能源，需要核能。风能不够，太阳能也不够。让我们都承认这一点，我们能拿到的都要。\n真正有意思的是，美国气候创新的最大驱动力，实际上正是这个 AI 基础设施问题。因为人们终于看到了需求。需求正在推动人们创建全新的大型电池公司、太阳能聚光器公司。它为新能源注入了新的活力，比如建造小型模块化反应堆 SMR 的意志力。\nAI 产业正在推动整个可持续能源产业的发展。当历史重写时，AI 很可能是可持续能源有史以来最大的推动力。\n这是一个反直觉的观点：AI 不是能源问题的制造者，而是能源创新的推动者。\n黄仁勋：特朗普总统和他的政府对于如何看待中国有一种非常务实和基于常识的态度和理念。他们认为中国是对手，但在很多方面也是合作伙伴。那种脱钩的想法是天真的。\n你越深入地研究就越会发现，两国实际上是高度耦合的。两国都应该投资于自身的独立性——当你过度依赖某人时，关系会变得过于情绪化。但也要认识到，两国之间存在大量的耦合和深度依赖。\n还记得吗，中国互联网的增长对英特尔和 AMD 卖 CPU 来说是一场盛宴。中国为开源做出了巨大贡献。世界上没有哪个国家比中国对开源的贡献更大。中国的互联网产业为美国创造了巨大的财富，只是不体现在互联网公司本身。\n我认为需要一种更精细的策略和态度，来以一种对两国人民、对全世界人民都有利的方式来管理这种关系。\n这是一个很务实的视角：不是非黑即白，而是认识到复杂的相互依赖。\n主持人：你对 2026 年有什么看法？\n黄仁勋：我觉得有几个行业将经历他们的 ChatGPT 时刻。\n数字生物学：多模态和超长上下文结合合成数据生成技术的突破，将帮助数字生物学领域创造出它的 ChatGPT 时刻。蛋白质理解正在快速进步，接下来蛋白质生成也会快速进步。然后是化学的理解和生成，再然后是蛋白质与化学物质构象的",
    "ytTitle": null,
    "ytChannel": null,
    "ytChannelUrl": null,
    "ytViews": null,
    "ytPublished": null
  },
  {
    "id": "MGVjwF3oZiozyhkWuAscZ428nYf",
    "title": "中国AI胜算圆桌",
    "rawTitle": "0112-中国AI胜算圆桌",
    "dateCode": "0112",
    "youtubeId": null,
    "feishuUrl": "https://my.feishu.cn/wiki/MGVjwF3oZiozyhkWuAscZ428nYf",
    "intro": [
      "今天看到智谱GLM Day的圆桌讨论。花了两个多小时看完了这期对话。干货太多了。",
      "这场圆桌汇集了四位横跨学术与产业、中国与硅谷的一线参与者：杨强（联邦学习奠基人）、唐杰（智谱首席科学家）、林俊旸（Qwen技术负责人）、姚顺雨（腾讯首席AI科学家，ReAct/SWE-agent作者）。讨论四个核心问题：分化、范式、Agent、中国AI的胜算。",
      "2025年是中国开源模型大放异彩的一年，Coding场景一年增长10-20倍。但硅谷几家头部也在明显分化：Anthropic聚焦企业和Coding，Google押注全模态，OpenAI继续To C。这期讨论的信息密度极高，我把全文精编出来，按主题重新组织，供大家学习。"
    ],
    "highlights": [
      "唐杰：我觉得最有意思的是，可能未来中国也许的机会：第一，一群聪明人真的敢做特别冒险的事。我觉得现在是有的，00后、90后这一代，包括俊旸、Kimi、顺雨，都是愿意而且非常敢冒风险做这样大冒险的事。",
      "第二，确实环境要更好一些。无论从国家的环境，比如大企业和小企业之间竞争，创业企业之间的问题，包括我们的营商环境。把环境Build得更好，让一群聪明人又敢于冒险的聪明人有更多的时间去做这种创新的事情。",
      "第三，回到我们每个人身上，就是能不能坚持。如果我们笨笨地坚持，也许走到最后的就是我们。",
      "\"笨笨地坚持\"——这可能是最实在的建议了。",
      "姚顺雨凭ReAct和SWE-agent的贡献，定义了Agent研究的范式。林俊旸带领Qwen成为全球开源模型的标杆。唐杰让智谱在Coding领域异军突起。杨强老师的联邦学习框架影响了整个行业的数据协作方式。",
      "这期圆桌让我印象最深的是两个：一是\"自主学习已经在发生，只是人们没意识到\"；二是\"中国20%的胜率已经很乐观了\"——既有技术乐观，又有战略清醒。",
      "借用唐杰老师的话来收个尾：我们恰恰可能也是幸运的，我们在经历一个环境从原来没那么好慢慢变得更好的时代。我们是经历者，也许就是这个财富收获最多的人。",
      "希望大家能像这期圆桌反复强调的——不等范式突破，只需笨笨地坚持。",
      "聪明人+冒险精神+坚持，这才是中国AI的真正胜算。"
    ],
    "fullText": "今天看到智谱GLM Day的圆桌讨论。花了两个多小时看完了这期对话。干货太多了。\n这场圆桌汇集了四位横跨学术与产业、中国与硅谷的一线参与者：杨强（联邦学习奠基人）、唐杰（智谱首席科学家）、林俊旸（Qwen技术负责人）、姚顺雨（腾讯首席AI科学家，ReAct/SWE-agent作者）。讨论四个核心问题：分化、范式、Agent、中国AI的胜算。\n2025年是中国开源模型大放异彩的一年，Coding场景一年增长10-20倍。但硅谷几家头部也在明显分化：Anthropic聚焦企业和Coding，Google押注全模态，OpenAI继续To C。这期讨论的信息密度极高，我把全文精编出来，按主题重新组织，供大家学习。\n美国人愿意为最强模型付4倍价格，因为年薪20万的人不知道哪5个任务会出错，监控成本比付200美元更贵\nTo B的等式：智能越高=生产力越高=赚钱越多，这个等式只在To B成立；To C大部分人大部分时候感受不到模型变强\n垂直整合反转：To C垂直整合成立（ChatGPT、豆包），To B反而分层更好——模型层和应用层需要的能力太不一样\nBottleneck不是模型：\"今天吃什么\"这问题模型再强也没用，需要的是你老婆的聊天记录、你的位置、天气\nAnthropic不创新反而赢：不做什么创新，就是预训练变大+RL做好，所有目标完全Aligned所以能聚焦\n自主学习已在发生：Claude Code写了Claude Code 95%的代码，Cursor每几小时用用户数据学习，只是人们没意识到\n睡觉理论：人类解决持续学习的方法是睡觉——每晚清理噪音让准确率不下降，AI需要类似机制\nScaling到瓶颈：从10T到100T数据，收益不成比例，应该定义\"智能效率\"指标——多少投入换多少智能增量\nAgent四阶段：目标定义×规划，各有人定义和AI定义四种组合，现在还在最初级（都是人定义）\n中国缺的是冒险精神：一旦被证明能做，很快catch up甚至更好；但探索新范式、做冒险事情的人不够多\n刷榜文化束缚：Claude榜单不是最高但公认最好用，中国对数字看得太重，需要走出榜单束缚\n断断续续，终于看完了这期两个多小时的圆桌。干货很多。\n姚顺雨可能是我2025年见过的把\"To B vs To C分化\"这个问题讲得最透彻的人——他横跨OpenAI和中国两个体系，既做过最前沿的Agent研究（ReAct、SWE-agent），又在腾讯思考To C产品。林俊旸把\"模型即产品\"的理念讲得非常清晰。唐杰在讲智谱为什么Bet Coding时的坦诚让人印象深刻。杨强老师的\"睡觉理论\"和\"Agent四阶段\"框架都是高度凝练的学术洞察。\n我今天不忙，把这次圆桌全文精编出来，供大家学习。赠人玫瑰，手有余香。\n主持人：硅谷几家也都在明显做分化。Anthropic专注企业和Coding，Google押注全模态，OpenAI继续To C。你对\"模型分化\"这个主题怎么看？\n姚顺雨：我觉得有两个大的感受。\n第一，To C和To B明显发生了分化。很明显，当大家想到AI的Super App，现在大家想到的就是两个：一个是ChatGPT，另一个是Claude Code。大家可以认为它们分别是做To C和To B的典范。\n很有意思的一点是，我们今天用ChatGPT的时候，其实和去年用，对于大部分人、大部分时候来说，感受到的变化已经没有那么强烈了。但是相反，以Claude Code来说，Coding的革命可能一年前还没有开始，但是这一年，夸张一点说，已经在重塑整个计算机行业做事的方式。人已经不再写代码，而是去用英语和电脑去交流。\n这里有个核心点：对于To C来说，大部分人大部分时候其实不需要用到这么强的智能。可能今天用ChatGPT和去年相比，写抽象代数或者去解伽罗瓦理论的能力变强了，但是大部分人感受不到。\n但是对于To B来说，智能越高很多时候就代表生产力越高，就代表你可以赚的钱越多，这一切东西都相关联。\n我太喜欢这个洞察了。这解释了为什么Anthropic能聚焦——因为To B的目标是完全Aligned的。\n姚顺雨：对于To B来说，还有一个很明显的点：大部分时候其实很多人愿意用最强的模型。可能一个模型它是200美元一个月，第二强或者差一些的模型是50美元一个月或者20美元一个月。\n我们今天发现很多，起码美国的人，是会愿意花那个溢价去用最好的模型。因为可能他的年薪是20万美元，他每天要做10个任务，那一个像Opus 4.5这样一个非常强的模型，它可能会10个任务八九个直接做对了，那差的模型它可能做对五六个。\n问题是你不知道这五六个是哪五六个的情况下，就要花很多额外精力去监控这个事情。\n所以在To B这个市场上，强的模型和稍微差点的模型，分化会变得越来越明显。\n这个账算得太清楚了。年薪20万的人，每天监控AI输出的时间成本，远超200美元和50美元的差价。这就是为什么To B市场会出现强者恒强。\n姚顺雨：第二点观察，是垂直整合和模型应用分层的区别。\n过去大家会认为当你有垂直整合的能力，你就肯定会做得更好，但起码今天来看，并不一定。首先，模型层和应用层需要的能力还是挺不一样的。\n所以我们会发现，在To C的应用上，垂直整合还是成立的。无论是ChatGPT还是豆包，模型和产品是非常强耦合去紧密迭代。但对于To B来说，趋势似乎是相反的。模型在变得越来越强，但也同样会有更多应用层的东西想要去利用这样的好模型，在不同的生产力环节发挥作用。\n林俊旸：我愿意相信Anthropic可能不是说\"今天我觉得Coding真的很厉害，我就Bet on它\"。因为我知道他们跟Business交流真的非常多。今天我跟美国的很多API厂商聊起来，他们都没有想到Coding的Token消耗量居然会这么大。其实在中国其实还真的没有那么大。但是在美国的话，基本上全都是Coding。\n这个分化不是规划出来的，是市场反馈出来的。Anthropic每天和客户聊，发现Coding需求爆炸，就自然聚焦了。\n姚顺雨：我们发现很多时候我们的Bottleneck可能在To C这一端不是更大的模型，或者更强的强化学习，很多时候可能是额外的Context和Environment。\n我最近经常举的一个例子：比如说我想问\"我今天该去吃什么\"。其实你今天问ChatGPT和你去年问、或者明天问，这个事情可能体验都会很差。因为想要变好，不是说你需要更大的模型、更强的预训练，这个问题的Bottleneck可能是你需要更多额外的输入，或者说Context。\n比如说如果它知道\"今天我其实特别冷，我需要吃点暖和的\"，然后\"我今天在这个范围活动\"，可能\"我老婆在另一个地方，她想吃什么\"等等。其实回答这样的问题，更多的Bottleneck是额外的Context。比如说我和老婆聊了很多天，其实我们可以把聊天记录从微信转发给元宝。\n这个例子太精准了。\"今天吃什么\"这个问题，GPT-5也解决不了，但微信聊天记录可以。\n主持人：对于下一个范式怎么思考？\n姚顺雨：现在自主学习在硅谷非常热门，大家都在谈论，几乎形成共识。但我觉得很有意思的一点是，这个事情其实已经在发生了。\nChatGPT利用用户数据拟合聊天风格，使它的感觉越来越好，是不是一种自我学习？今天Claude Code已经写了Claude Code这个项目95%的代码，在帮它自己变得更好，这是不是一种自我学习？\n我记得当时我们2022-23年做SWE-agent时，我去AGI House宣传，第一页Introduction的Slide就说ASI最重要的点是自主学习。如果我们做Software Agent，如果有一天它能自己去Improve自己的Repo，那是不是就是一种AGI？我觉得今天Claude Code已经在大规模做这个事情了，只是人们意识不到，或者局限在特定场景下。\n我觉得这个事情已经在发生了，可能更像是一个渐变，而不像一个突变。\n这个视角太有意思了。我们一直在等待\"自主学习\"的突破，但它可能已经悄悄发生了——只是以我们没预料到的形式。\n杨强：刚才唐杰老师也提到持续学习。我觉得持续学习是一个特别好的问题。它里面有一个时间的概念。在持续学习过程中，你会发现，比方说把不同的Agent串联起来，每一个Agent都不能做到100%，那么在N个以后，能力是按指数下降的。怎么样保证它不下降？\n我觉得人类是个样本，比如说第一天是学习，第二天会在第一天的噪音的基础上学习，这样你的能力就会类似大模型，会下降。但是人类有一个方法来解决下降，就是睡觉。\n我建议大家看一本书叫《我们为什么睡觉》。他说每天晚上睡觉其实是在清理噪音，使得第二天可以把准确率持续提升，不至于是错误率的叠加。\n这些理论研究孕育着一种新的计算模式。\n杨强老师这个类比太精妙了。AI的\"睡觉\"机制会是什么？也许是某种周期性的知识整理和噪音清理。\n唐杰：我觉得一个创新的出现它一定是某个事情有大量的投入，并且它的Efficiency变成为瓶颈了。现在在整个大模型里面，投入已经巨大，但是Efficiency并不高。\n也就是我们继续Scaling，你说有没有收益呢？肯定是有的。比如说原来我们Data，从2025年初可能10个T的数据，现在30个T，甚至我们可以Scaling到100个T。但100个T你Scaling上去以后，你的收益有多少？还有你的计算Cost得有多少？这就变成一个问题了。\n所以我们未来也许可以定一个：一方面，我们既需要Scaling Up，因为Scaling我们肯定有收益。但第二个方法，我觉得应该定一个叫Intelligence Efficiency，就是说智能的效率，我们获得智能的效率，即用多少的投入能获得智能的增量。\n如果我们能用更少的投入获得增量，这就是一个瓶颈式的事情。所以我是觉得2026年一定有这么一个范式发生。\n\"智能效率\"这个指标定义得好。不是\"能不能更强\"，而是\"用多少投入换多少智能增量\"。\n杨强：我觉得Agent出现应该有四个阶段。\n看一个，是目标的定义，是由人为定义的还是自动定义的？第二个，是说规划，就是中间的Action，规划也可以由人来定义，也可以由AI自动定义。所以这样就自然地分为四个阶段了。\n我觉得我们现在在一个非常初级的阶段，就是目标也是人定义的，规划也是人做的。所以现在的这些Agent的Definition系统，基本上是一个更高级的Very High-level Programming Language。\n但我预料未来会出现一个大模型观察人的工作，尤其是把人的Process Data给使用起来。最后目标也可以是大模型来定义，规划也可以由大模型定义。所以，Agent应该是由大模型内生的一个Native的系统。\n这个2x2矩阵框架太清晰了：目标（人定义/AI定义）× 规划（人定义/AI定义）= 四个阶段。我们现在在(人,人)，终极是(AI,AI)。\n主持人：从你的角度看来，通用的Agent这个机会是创业者的吗？还是说模型公司是一个时间问题？\n林俊旸：我只能借成功人士Peak（Manus的CTO）说的话，他说：做通用Agent最有意思的事情是长尾，反而是更值得关注的事情，或者是说今天AI更大的魅力是在长尾。\n如果是马太效应，头部的这个东西其实挺容易解决的。当年做推荐的时候，我们看到推荐非常集中在头部商品。但我们想把尾部推过去，但我当时做就非常遭殃。\n但我觉得今天的所谓AGI其实就在解这个问题，你做通用Agent是能不能把长尾的问题给解决。今天我一个用户，我真的寻遍各处都找不到能够帮我解这个问题的。但就在那一刻，我感受到了AI的能力，全世界任何一个角落，我寻遍各处都找不到，但是你却能帮我解。可能这就是AI最大的魅力。\n这个视角反直觉。不是\"AI能做头部热门需求\"让人惊艳，而是\"全世界都解决不了的长尾问题，AI帮我解了\"——这才是魔法时刻。\n主持人：在三年和五年以后，全球最领先的AI公司是一个中国团队的概率有多大？\n姚顺雨：我觉得概率还挺高的。任何一个事情，一旦被发现出来，在中国都会很快Catch up或者复现，然",
    "ytTitle": null,
    "ytChannel": null,
    "ytChannelUrl": null,
    "ytViews": null,
    "ytPublished": null
  },
  {
    "id": "R5LhwOyq6iTTCQkCWR7cAK4EnVG",
    "title": "Lovable增长策略",
    "rawTitle": "0109-Lovable增长策略",
    "dateCode": "0109",
    "youtubeId": "6qAB6aUMIeA",
    "feishuUrl": "https://my.feishu.cn/wiki/R5LhwOyq6iTTCQkCWR7cAK4EnVG",
    "intro": [
      "今天看到 Elena Verna 去了 Lenny's Podcast。花了一个多小时听完了这期播客。干货太多了。",
      "Elena Verna 是 Lovable 的增长负责人，这家公司在不到一年内从零做到 2 亿美元 ARR，可能是史上增长最快的公司之一。她之前在 Miro、Dropbox、Amplitude 等公司做增长，有 15-20 年的增长经验。但她说，过去学的东西只有 30-40% 还能用——这个反差太有意思了。",
      "这期播客的信息密度极高。我把全文精编出来，按主题重新组织，供大家学习。"
    ],
    "highlights": [
      "Elena：有数据显示男性采用 AI 的速度远超女性。这让我很担心。",
      "Lovable 的品牌是粉色紫色，是个爱心，叫 Lovable——我以为女性用户至少占一半。结果第三方数据显示只有 20% 左右。",
      "主持人：这意味着什么？",
      "Elena：谁先采用 AI，谁就获得更多机会和更高薪酬。如果女性不跟上，我们好不容易在过去十年取得的进步可能会被逆转。",
      "所以我们在做 She Builds——一个专门给女性的 hackathon。给她们 48 小时无限使用 Lovable，一起构建。很多女性在这个活动里做的是帮助老人、孩子、教会、社区的工具——这些需求以前因为软件开发太贵从来没人做过。",
      "Elena Verna 凭她在 Lovable 的实践，重新定义了 AI 时代的增长策略。她让我意识到，过去十几年学的增长方法论可能真的要大换血了。",
      "借用她的核心理念来收个尾：产品市场契合不再是一次性的成就，而是每 3 个月都要重新捕获的目标。希望大家能像这期播客反复讲的——不是优化问题，而是重新发明解决方案。在 AI 时代，95% 的精力要放在创新上。",
      "视频链接：https://www.youtube.com/watch?v=6qAB6aUMIeA"
    ],
    "fullText": "今天看到 Elena Verna 去了 Lenny's Podcast。花了一个多小时听完了这期播客。干货太多了。\nElena Verna 是 Lovable 的增长负责人，这家公司在不到一年内从零做到 2 亿美元 ARR，可能是史上增长最快的公司之一。她之前在 Miro、Dropbox、Amplitude 等公司做增长，有 15-20 年的增长经验。但她说，过去学的东西只有 30-40% 还能用——这个反差太有意思了。\n这期播客的信息密度极高。我把全文精编出来，按主题重新组织，供大家学习。\n1. 增长经验失效：Elena 说过去 15-20 年学的增长方法论，只有 30-40% 还能用。以前 95% 时间做优化，现在反过来——95% 时间做创新，5% 做优化\n2. 优化不值得做：在 Lovable，优化现有用户旅程根本不值得。市场变化太快，与其优化不如发明新的增长飞轮\n3. 增长团队做产品：Lovable 的增长团队自己上手做 Shopify 集成、语音模式这些核心功能。以前增长团队永远不会碰核心产品\n4. 激活交给 Agent：传统增长团队花大量时间做激活，但 Lovable 的核心团队（做 AI agent）本身就在疯狂优化激活——第一次生成就是激活时刻\n5. 免费送产品是营销成本：Lovable 把 LLM 成本当营销费用，疯狂送信用点数给 hackathon、用户活动，因为每个拿到免费额度的人都在帮他们做激活和推广\n6. 社交 > SEO：以前有机增长策略 = SEO，现在有机增长 = 社交。CEO 发推、员工发帖、用户分享作品，这才是新的有机流量\n7. 3 个月重新捕获 PMF：产品市场契合不再是一次性的。LLM 能力每 3 个月变一次，用户预期也跟着变，所以每 3 个月就要重新找 PMF\n8. 网红营销 > 付费广告：网红营销效果是付费社交广告的 10 倍。因为 vibe coding 需要\"看到\"才能理解——10 秒视频比任何文案都有效\n9. MLP 取代 MVP：不是 Minimum Viable Product（最小可行产品），而是 Minimum Lovable Product（最小可爱产品）。可行性已经是 2010 年代的事了\n10. 雇佣全职 Vibe Coder：Elena 团队有个全职 vibe coder，之前是 Chief of Staff，完全非技术背景。这是个全新的岗位\n11. 失败创始人成香饽饽：现在 AI 公司最想招的是失败的创业者——因为他们有高度自主性和从混乱中创造秩序的能力\n12. 女性 AI 采用率堪忧：Lovable 这么粉嫩可爱的品牌，女性用户只占 20%。Elena 担心女性会被落在 AI 浪潮后面\n主持人：先聊聊 Lovable 的规模，给大家一个概念。\nElena：我们正式上线是 2024 年 11 月第三周。到现在刚过一年，ARR 已经超过 2 亿美元。7 个月做到 1 亿，又 4 个月做到 2 亿。用户超过 800 万。付费用户有几十万。\n主持人：这些数字太离谱了。以前一年做到 100 万 ARR 就很厉害了。\nElena：对，我想强调一下——这不是一个正常的标杆。我们能做到是因为赶上了 vibe coding 这个爆发的品类。这个速度不应该成为其他创业者的参照。\n说实话，这个增速确实吓人。一年 2 亿 ARR，100 人团队。而且 Elena 反复强调——他们根本不优化收入，反而在想怎么把产品送出去更多。收入只是副产品。\n主持人：你之前说过，你得扔掉大部分增长方法论。这对于做过 Miro、Dropbox、Amplitude 增长的人来说是个大事。\nElena：以前我加入一个新公司，80% 的套路是可以直接复用的。识别问题，套用框架，找案例，本地化执行。我甚至觉得有点无聊，因为每家公司的问题其实都差不多。\n但在 Lovable，我的老经验只有 30-40% 能用。以前我可能 5% 时间做创新，95% 做优化。现在完全反过来——95% 时间做创新，5% 做优化。\n主持人：为什么优化不值得做了？\nElena：因为市场变化太快。我们的竞争对手太多——每个人和他妈都在做 vibe coding 业务。要领先他们，不能靠优化，得靠重新发明解决方案。\n这个洞察太重要了。以前增长就是漏斗优化、A/B 测试、微调转化率。现在这些都不够看了。市场 3 个月就变一次，你优化的东西可能下个月就过时了。\nElena：我们增长团队做的事完全变了。以前增长团队做的是优化用户体验、减少摩擦。现在我们直接做核心产品功能。\n比如我们做了 Shopify 集成，让用户可以 vibe code 自己的店铺。我们还做了语音模式，让用户可以用语音和 Lovable 对话。这些以前是核心产品团队的活。\n主持人：那激活呢？你之前一直说激活是增长最重要的事。\nElena：这是最有意思的地方。我们几乎不花时间在激活上。因为我们的 agent 团队本身就在疯狂优化\"第一次生成\"的体验——那就是激活时刻。Agent 变好了，整个用户生命周期都变好了。\n这太反直觉了。以前增长团队最重要的事就是激活——怎么让用户到达 aha moment。但在 AI 产品里，激活 = 产品本身。Agent 好用，激活就好。增长团队反而可以去做别的事。\n主持人：你说有机增长策略完全变了？\nElena：5 年前你问我什么是有机增长策略，我会说 SEO——去 Google 做搜索引擎优化。现在有机增长 = 社交。\nCEO 在发什么？团队在发什么？用户在分享什么？LinkedIn、X、TikTok——这才是现在的有机流量来源。不管你多 B2B，因为眼球都在社交平台上。\n主持人：具体怎么做？\nElena：我们最大的策略是\"公开构建\"（building in public）。我们每天都在发布新功能，然后让工程师自己发推宣布。不是所有东西都走市场部——那样需要太大的市场团队。\n我们追求的是\"噪音\"。市场上要一直有 Lovable 的声音。人们刷社交媒体就想看看 Lovable 又发布了什么。这也是一种留存策略。\nElena：我们把产品送出去超级多。这可能对 AI 公司来说有点反直觉，因为每次交互都有 LLM 成本。\n但我是这么看的：我们把 LLM 成本当营销费用。如果有人说\"我要在公司办一个 Lovable hackathon，能给点免费额度吗？\"——我们会说：要多少？全给你。因为这个人在帮我们做激活和推广。\n主持人：这是不是靠 VC 烧钱？\nElena：其实不是。我们没花多少钱在付费营销上，也没有大销售团队。省下来的钱正好可以送产品。而且这比买广告效率高——在 Google 上跟别人抢流量太贵了。\n这个逻辑太精彩了。传统思维是：控制成本、保护利润率。AI 公司思维是：把产品送出去就是最好的营销。每个拿到免费额度的人都是潜在推广者。\nElena：网红营销对我们来说，效果是付费社交广告的 10 倍。\n原因很简单：vibe coding 需要\"看到\"才能理解。没人知道什么是 vibe coding，但你看 10 秒视频就懂了——哇，这是可能的，我要去试试。所以视频内容特别有效。\n主持人：付费广告呢？\nElena：付费广告也在做，但回收周期比较长，还在优化中。网红营销从一开始就有效，因为它本质上就是让人\"看到\"产品的魔法。\nElena：以前说产品市场契合，你可能花几年去扩张它。第二曲线、第三曲线可能是 5-10 年后的事。\n现在是 3 个月。每 3 个月 LLM 能力就变一次，用户期望也跟着变。3 个月前用户觉得 ChatGPT 能做的事，现在觉得太 basic 了。\n主持人：这意味着什么？\nElena：我们是一家 2 亿美元的公司，但我们还不能只做市场和销售，因为我们每 3 个月都要重新捕获产品市场契合。找 PMF 的团队和扩张 PMF 的团队是不一样的，但我们需要一个能同时做两件事的团队。\n这是我听过对当前 AI 创业环境最精准的描述。你不能躺在现有的 PMF 上，因为 3 个月后游戏规则就变了。OpenAI 被 Gemini 2.5 抢市场份额就是最好的例子。\n主持人：你提到了 Minimum Lovable Product？\nElena：对，不是 MVP（最小可行产品），而是 MLP（最小可爱产品）。可行性是 2010 年代的事了。现在软件开发成本大幅下降，你可以投入情感体验了，不只是功能。\n这也是 Lovable 这个名字的好处——我们内部的标准就是\"这个够不够 lovable？\"如果不够，就不发。修 bug 的最快方式就是说\"这不 lovable\"——所有人立刻冲上去修。\n主持人：这不是很主观吗？\nElena：我们把品牌融入产品的每一个交互。我们没有品牌营销团队，品牌就是产品体验本身。我跟设计师说的最多的就是：怎么加更多\"爱的印记\"？\n主持人：你说你团队有个全职 vibe coder？\nElena：对，他叫 Lazar，之前是 Chief of Staff，完全非技术背景。但他很早就进入 vibe coding，自学了很多。\n我自己也 vibe code，但时间不够。所以我需要一个人帮我把各种想法快速做出来。比如我们和 Shopify 合作，他就帮我们做了一堆 Lovable + Shopify 的模板。\n主持人：这会成为一个普遍的岗位吗？\nElena：我觉得 vibe coding 会成为很多岗位的技能要求——设计师、产品经理、市场人员。就像 Excel 一样，是一个新的基础技能。\nElena：两类人现在特别抢手。\n第一是 AI 原生的应届生。他们不懂老的做事方式，只知道怎么用 AI 做事。我团队有好几个应届生，我从他们身上学到很多。\n第二是失败的创业者。他们有高度自主性，能从混乱中创造秩序。以前公司不太想招失败的创业者，现在他们是香饽饽。\n主持人：这两类人和传统招聘很不一样。\nElena：对，以前招人看简历、看公司 logo、看成功案例。现在看的是：这个人有没有火在烧？这是不是他们人生最好的机会？他们能不能在没有人告诉他们做什么的情况下创造价值？\nElena：有数据显示男性采用 AI 的速度远超女性。这让我很担心。\nLovable 的品牌是粉色紫色，是个爱心，叫 Lovable——我以为女性用户至少占一半。结果第三方数据显示只有 20% 左右。\n主持人：这意味着什么？\nElena：谁先采用 AI，谁就获得更多机会和更高薪酬。如果女性不跟上，我们好不容易在过去十年取得的进步可能会被逆转。\n所以我们在做 She Builds——一个专门给女性的 hackathon。给她们 48 小时无限使用 Lovable，一起构建。很多女性在这个活动里做的是帮助老人、孩子、教会、社区的工具——这些需求以前因为软件开发太贵从来没人做过。\nElena Verna 凭她在 Lovable 的实践，重新定义了 AI 时代的增长策略。她让我意识到，过去十几年学的增长方法论可能真的要大换血了。\n借用她的核心理念来收个尾：产品市场契合不再是一次性的成就，而是每 3 个月都要重新捕获的目标。希望大家能像这期播客反复讲的——不是优化问题，而是重新发明解决方案。在 AI 时代，95% 的精力要放在创新上。\n视频链接：https://www.youtube.com/watch?v=6qAB6aUMIeA\n",
    "ytTitle": "The new AI growth playbook for 2026 | How Lovable hit $200M ARR in one year",
    "ytChannel": "Lenny's Podcast",
    "ytChannelUrl": "https://www.youtube.com/@LennysPodcast",
    "ytViews": null,
    "ytPublished": null
  },
  {
    "id": "ZqNHwfGJMi4NLUkruURcOl1KnFf",
    "title": "没有学位如何进入顶尖AI公司",
    "rawTitle": "0108-没有学位如何进入顶尖AI公司",
    "dateCode": "0108",
    "youtubeId": null,
    "feishuUrl": "https://my.feishu.cn/wiki/ZqNHwfGJMi4NLUkruURcOl1KnFf",
    "intro": [
      "今天看到 Gabriel Peterson 去了 extraordinary 的播客。花了两个多小时听完了这期访谈。干货太多了。",
      "Gabriel 是我2025见过的把\"没有学位如何进入顶尖AI公司\"这个问题讲得最透彻的人。他是瑞典高中辍学生，零大学学历，靠自学用ChatGPT学会了数学和机器学习，现在在OpenAI担任研究科学家，参与构建Sora视频模型。传统上这个岗位只有博士才能做，但他用ChatGPT三天学会的东西，传统路径要六年。",
      "这期播客的信息密度极高。我把全文精编出来，按主题重新组织，供大家学习。"
    ],
    "highlights": [
      "Gabriel：我觉得人们真的很容易低估自己能做多少事，超级容易低估。",
      "可能光是听这个播客的人就已经是在前1%了。大多数人甚至没有主动性去想——我想做点什么——然后花1个小时听点东西来做那件事儿。",
      "你已经是前1%了，而前1%就已经是世界前五百强创业公司的人了。你可以来到旧金山，在一家顶尖公司工作，或者创办一家顶尖公司，有太多事情可以做了。",
      "Gabriel 凭自己的经历，证明了没有学位也能在世界顶级AI公司工作。每天我都能看到许多人在用AI学习、用AI工作，但很少有人像Gabriel这样把方法论讲得这么透彻。也让我重新思考自己学习和使用AI的方式。",
      "借用Gabriel在访谈中反复强调的一句话来收个尾：\"公司就是想赚钱，你向他们展示你怎么帮他们赚钱，证明你会写代码，他们就会雇你。\" 希望大家能像这期播客反复讲的——知识本身不再是门槛，主动性和创造力才是。一天问ChatGPT一百个问题，追逐那些\"灯泡亮了\"的瞬间，你就能超过世界上99.9%的人。"
    ],
    "fullText": "今天看到 Gabriel Peterson 去了 extraordinary 的播客。花了两个多小时听完了这期访谈。干货太多了。\nGabriel 是我2025见过的把\"没有学位如何进入顶尖AI公司\"这个问题讲得最透彻的人。他是瑞典高中辍学生，零大学学历，靠自学用ChatGPT学会了数学和机器学习，现在在OpenAI担任研究科学家，参与构建Sora视频模型。传统上这个岗位只有博士才能做，但他用ChatGPT三天学会的东西，传统路径要六年。\n这期播客的信息密度极高。我把全文精编出来，按主题重新组织，供大家学习。\n1 自上而下学习：不要从基础往上学，而是从问题往下钻——想学扩散模型就直接让ChatGPT写代码，遇到不懂的再递归追问，三天能学会六年的内容\n2 大学垄断已破：大学不再对基础知识拥有垄断权，ChatGPT让任何人都能获得博士级教育，每月20美元\n3 公司只想赚钱：扔掉所有找工作的建议，向公司展示你能帮他们赚钱、证明你会写代码，他们就会雇你\n4 Demo是敲门砖：做一个3秒内能让人看懂你会写代码的demo——比学历、实习经历都管用\n5 追问到点通：不停问ChatGPT直到\"灯泡亮了\"的那个瞬间，用\"12岁能懂的话解释\"等技巧榨取信息\n6 离招聘经理越远越好：CEO只想赚钱会雇能干活的人，但离CEO越远的人只想不犯错，所以只看学历\n7 在同一家公司待太久是最大错误：快速换工作、找最好的团队、追着要代码审查反馈——这是没有学位时最好的学习方式\n8 知识空白感知：学会识别自己什么时候没真正理解某个部分，这是用AI学习最重要的元技能\n 9 旧金山是显而易见的选择：人才密度、资本流动、网络效应——如果你真的有野心，没有其他选项\n10 一天问ChatGPT一百个问题：如果是经过深思熟虑的问题，你就能超过世界99.9%的人\n主持人：一般来说要做研究科学家你得有个博士学位，但你没有。你是怎么从瑞典高中辍学生走到OpenAI研究科学家的？\nGabriel：说来话长。我从读了《超级智能》和《生命3.0》之后就一直在思考人工智能。但我总觉得自己太笨了——外面肯定有一大堆绝顶聪明的人我根本竞争不过。所以最后我就去当了几年工程师。\n主持人：你高中辍学是怎么发生的？身边的人都在按部就班上学，你怎么就敢离开？\nGabriel：其实也不是我主动做的决定，更像是就这么发生了。有一天我表哥给我打电话说，我刚跟一个人聊了，他超级聪明，他有个产品点子。我们今天就得开始卖这个东西。我当时说，哥们儿，我今晚有个大派对，我明天再来。他说不行。所以我就直接坐了下一班大巴去了斯德哥尔摩，然后就再也没回去过。\n这个开场就很有意思。Gabriel不是那种精心规划的人，他是被一个机会\"拽走\"的。这种偶然性在很多成功故事里反复出现。\nGabriel：我们的想法是给电商网站做一个产品推荐系统。我当时住在我表哥的大学宿舍里——准确说是公共休息室里找了几个沙发靠垫，就在那上面睡了一年。那房间脏得要死，但还挺管用。\n主持人：是什么让你坚持下来的？大多数人可能就放弃了，回学校去了。\nGabriel：我觉得我一直以来对现实的看法都有点不着边际。我百分之百确定这事儿能让我成为亿万富翁，百分之百，毫无疑问。我言行举止都像是在说，这绝对是下一个大事件。\n这种\"不切实际的乐观\"在早期创业者身上很常见。关键是它给了他承受痛苦的理由。\n主持人：你一开始辍学的时候还不会编程，那你是怎么学会的？\nGabriel：主要是被逼的。直接工作的好处就是你永远面对的是一个真实的问题，这让一切都变得特别简单。总有人问你不去上学怎么学习？我就觉得这简单多了——你有了一个真实的问题，然后你就可以规划出来。你去stack overflow查，卡住了就问朋友。\n这是第一次出现他的核心观点：真实问题是最好的老师。压力迫使你学习，而学校里没有这种压力。\nGabriel：我反正是没有压力就什么都学不会。要是有人跟我说，你去学这个东西时间不限，也赚不到钱，我肯定学不会。\nGabriel：我非常幸运。我当时住在一个叫舍夫德的小镇，在瑞典一个鸟不拉屎的地方，我不认识任何工程师。高中早期我见过一个程序员，我当时简直是追星现场，就问你写代码吗？太牛了。\n主持人：这种环境怎么影响你的？\nGabriel：当你没有那种文化氛围的时候，你想想为什么旧金山是创业之都？因为那儿所有人都在谈论创业。但如果你在一个鸟不拉屎的地方，周围没人整天聊这些，你就会觉得所有这些事都是不可能的。\n这解释了为什么他后来这么强调要去旧金山。他亲身经历过\"没有榜样\"是什么感觉。\nGabriel：现在有了ChatGPT的帮助，你甚至都不需要对你做的事情有多了解。你只要能向别人证明——我很擅长问ChatGPT我需要知道什么。你很有创造力，有很强的主动性。你把这些都展示给招聘的人看，他们可能会说，但你其实不懂这个具体的东西。你就可以说，对，但我一直跟ChatGPT聊天，我特别擅长从中提取信息。你拥有了全世界的知识，知识本身已经不再是问题了。\n这是整个访谈最核心的观点之一：知识获取已经民主化了。剩下的是主动性和创造力。\nGabriel：我认为人学的最快的方式是所谓的自上而下的方法。你从一个问题开始，然后递归的向下探索。\n比如我想学机器学习，我就问ChatGPT我应该做什么项目？他会给我写好项目代码，我遇到bug就开始修复bug。从那里开始，我再具体看某一部分——这里发生了什么，你能给我解释一下吗？他就会给你解释。然后我说这里用了矩阵乘法和线性代数，好吧？他们是怎么工作的？突然之间你就掌握了所有的基础知识。\n主持人：但学校里不是这么教的。\nGabriel：在学校里，每个人的思维模式都是——我们得从基础开始。如果你想搞机器学习，那前四年你就别想碰任何机器学习的东西了。你得先学数学，然后是线性代数，还有所有这些基础的东西。为什么会这样？因为自上而下的方法很难规模化，他需要一个老师随时在你身边。但如果你用自下而上的方法，就更容易规模化，但效率极低。\n现在有了ChatGPT，一切都变了。我觉得现在但凡有哪个大学课程里还不教ChatGPT的，我都没法把它当回事儿。\n这段话挑战了整个教育体系的假设。大学的课程设计是为了规模化，而不是为了效率。\nGabriel：ChatGPT刚出来的时候，学生们的反应很自然——太好了，有东西能帮我做所有作业了。而老师们第一个想到的是——啊，不，所有人都会用AI来做作业，我们得禁止AI。\n这就形成了一个恶性循环：学生觉得AI就是个作弊工具，老师也觉得学生就是用它来作弊。这样就很难建立起一种如何向AI学习的直觉。\n主持人：那你觉得老师应该怎么做？\nGabriel：如果老师们能转变一下思路，告诉学生这是高效学习方法。如果一个学生想在考试中作弊，他总能找到办法。如果你从来没被教过，你其实可以用这个来学习，那我也会用它来作弊。\nGabriel：我现在在sora团队工作，我们在OpenAI开发视频模型。我想学习一些东西，比如图像模型的基础知识。我就问ChatGPT——在AI的视频和图像模型里最基本的概念是什么？他就开始讲扩散模型。\n我说听起来有意思，现在给我写出扩散模型的代码。他就写出来了。我一看完全不知道是什么鬼，一堆代码。然后你就试着让他跑起来跟他一起调试。\n接着你开始建立直觉——这里发生了这个，那里发生了那个。然后你继续深入去理解每一行代码具体是干什么的。一开始我完全不知道这是怎么回事，你就开始追问ChatGPT。\n当你理解了，你就可以告诉模型——这是我对这个东西的理解，完全正确吗？\n这是一个非常具体的方法论：代码 → 运行 → 调试 → 追问 → 验证理解。每个人都可以复制。\nGabriel：你会越来越擅长问那些能让你尽快获得\"灯泡亮了\"那个时刻的问题。你要的就是那个瞬间——就像你第一次理解线性代数或者第一次理解反向传播是怎么工作的时候。你要做的就是追逐这些点通的瞬间，让他们尽可能频繁的出现。\n有时候我问ChatGPT一些东西，它解释了我还是不懂。然后你再试一次。这时候就是提示词技巧大显身手的时候了：\n\"如果世界上没有这些特性，如果那个东西从来没存在过，他们还会发明这个东西吗？\"\n\"用12岁就能懂的话给我解释一下\"\n\"再生成几张图表，展示我需要知道的分布\"\n\"给我看各种选项，告诉我别人尝试过什么，为什么这个方法有效，为什么别的方法不行\"\n这些具体的提示词技巧非常实用。特别是\"用12岁能懂的话解释\"——这个简单的trick能极大提高理解效率。\nGabriel：首先就是改变一个误解——不要再认为AI是用来帮你干活的，而是要明确的用AI来帮助你学习。你不是只用它来完成工作，你是真的在从中学习。\n然后要变得非常擅长两件事：\n知道你的知识空白在哪里——意识到自己什么时候没有真正理解某个部分\n明白当你从根本上掌握某件事时的那种感觉是什么样的\n这是整个访谈中最深刻的元认知洞察。大多数人用AI的问题是：他们不知道自己不知道什么。\nGabriel：我总是开着一堆ChatGPT的标签页。我写代码扔进去，然后问这个好吗？这里有bug吗？我能怎么改进？为什么不呢？他可能会告诉你现在看起来还行，但有时候他会说这里有个bug，或者你可以用这种更简单的方式来做。\n如果你一天真的问100个问题，那可是100个经过深思熟虑的问题或追问，你就能超过世界上99.9%的人。\n这个数字很夸张，但背后的逻辑很扎实：持续的微量学习，累积起来就是巨大的优势。\nGabriel：我现在做的工作，传统上所有人都认为需要一个博士学位。但我们现在的情况是——我光靠用ChatGPT就能做以前传统上只有那些干了好多年的博士才能做的工作。这太疯狂了。\n主持人：这会给世界带来什么影响？\nGabriel：你可以去做任何你想做的研究。你想做生物研究，你想做硬件，你直接上手去做就行了。这会给世界GDP带来两位数的增长。就只靠大语言模型，任何人都可以做到，只要他们会用ChatGPT。\nGabriel：很简单。你看着视频觉得这部分视频看起来不太好，于是你就去改一下模型的架构，或者改一下数据什么的。然后你训练模型，盯着视频看一会儿，然后想——这些视频变好了，太棒了，这部分代码就可以合并了。\n这时候AI特别擅长：你可以说我有个具体问题，给我十个改进建议。他会给你一堆点子，会引用你可以读的论文。他是一个非常好的头脑风暴伙伴。\n我不会逐字逐句的读论文，我会跟ChatGPT说——告诉我这篇论文跟别的方法比有哪些不一样的地方，列个清单给我。我只有在决定要实现它的时候才会深入阅读。\n这个工作流非常高效：快速筛选 → 深入实现。不要在不值得的论文上浪费时间。\nGabriel：公司就是想赚钱。你向他们展示你怎么帮他们赚钱，证明你会写代码，他们就会雇你。\n人们可能会说，但他们只招有学位的人。是啊，那是因为从来没有人向他们展示过自己能干活。那些人只会说，我有这些实习经历，我上过哈佛成绩最好，我是辩论冠军。他们就开始扯那些父母会告诉你的东西——那些东西都不重要。\n这是一个非常直接的重新框架：学历只是因为没人能证明能力时的替代信号。如果你能直接证明，学历就不重要了。\nGabriel：CEO永远不会在乎学历，他们只想赚钱。你只要说，嘿，我能帮你赚钱——太好了，这有个任务给你做。\n但你离CEO越远，事情就越难办。因为人们开始失去为公司做最好选择的动力，取而代之的是——他们不想搞砸，他们只想不输。\n所以他们怎么招人呢？他们会招一个即使后来证明不行，自己也不会担责任的人。招那些有传统光环的人，比如上过顶尖学校的。这样招聘人员就不会犯错了。\n所以你要避免那些在公司里没有利益驱动的人。通常要避免公司的招聘人员，他们甚至不懂技术，根本不知道你好还是坏，他们只会看那些替代信号。\n这是我见过对\"为什么大公司招聘流程反人类\"最精准的解释。\nGabriel：我给别人的首要建议是做一个超级简单的演示demo。做demo的难点在于要确保人们在3秒钟内就能明白你会写代码。\n你想想一个职位有100个申请人，你附上一个链接，他们点开你就只有一次机会。作为一个酷炫的demo，让人们能看懂",
    "ytTitle": null,
    "ytChannel": null,
    "ytChannelUrl": null,
    "ytViews": null,
    "ytPublished": null
  },
  {
    "id": "GFjrwT6vhixHOPkMy7zcatFxnIh",
    "title": "睡眠才是生命的原始状态",
    "rawTitle": "0107 睡眠才是生命的原始状态",
    "dateCode": "0107",
    "youtubeId": null,
    "feishuUrl": "https://my.feishu.cn/wiki/GFjrwT6vhixHOPkMy7zcatFxnIh",
    "intro": [
      "斯坦福神经科学教授 Andrew Huberman 和加州伯克利睡眠研究专家 Matt Walker 的深度对话。",
      "Walker 有个反常识的观点：也许不是我们演化出了睡眠，而是我们从睡眠中演化出了清醒——睡眠才是生命的原始状态。",
      "他还提出了一个有趣的思想实验：从演化角度看，睡眠简直愚蠢透顶——你没法找伴侣、没法繁殖、没法觅食、还容易被捕食。但睡眠在演化的每一步都\"英勇抗争\"过来了，这说明它不可协商。",
      "总结一下做个笔记👇",
      "1️⃣ 快速眼动睡眠(REM)时，大脑会发信号让脊髓\"瘫痪\"全身骨骼肌。这是保护机制——让你的心智可以安全做梦，否则你梦见自己会飞就真从窗户跳出去了。",
      "2️⃣ 咖啡因不是给你能量，而是\"抢椅子\"——它占据腺苷受体但不激活，让大脑不知道你已经醒了16小时。咖啡因退去后，所有累积的腺苷一起涌来，这就是\"咖啡因崩溃\"。",
      "3️⃣ 睡前喝酒不是\"助眠\"而是\"镇静\"——酒精是在敲晕你的大脑皮层，这和自然入睡的脑电波完全不同。而且酒精会阻断REM睡眠，导致生长激素释放下降超过50%。",
      "4️⃣ 褪黑素不产生睡眠，只是\"发令员\"——它把睡眠选手叫到起跑线，但自己不参加比赛。研究显示褪黑素平均只增加3.9分钟睡眠，效果极其微弱。",
      "5️⃣ 市面上褪黑素补充剂通常是身体自然需求的10-20倍甚至更多。研究显示最佳剂量是0.1-0.3毫克，而药店常见的是5-10毫克——这是超生理剂量。",
      "6️⃣ REM睡眠是长寿的最强预测指标，而且是线性关系——每减少5%的REM睡眠，死亡风险增加约13%。这不是U型曲线，是直线。",
      "7️⃣ 酸樱桃汁的睡眠研究很惊人：三项独立研究分别发现它能减少1小时夜醒时间、增加34分钟和84分钟睡眠。猕猴桃（连皮吃）也有类似效果，机制可能是通过GABA系统。",
      "8️⃣ 性高潮后催乳素增加，催产素也上升，战斗逃跑系统消退——这些都是促进睡眠的机制。研究发现女性每多睡1小时，与伴侣发生性亲密关系的兴趣增加14%。",
      "9️⃣ 凌晨3-4点的担忧和白天完全不同——那时的焦虑带有灾难化程度，与清醒时不成比例。24小时自杀率数据显示，半夜几小时的自杀率高得不成比例。",
      "🔟 一晚糟糕睡眠后的最佳策略是\"什么都别做\"——别晚起、别午睡、别多喝咖啡、别提前上床。这样才能保持睡眠压力的自然累积。",
      "1️⃣1️⃣ 写\"烦恼日记\"（睡前1-2小时）能让入睡时间减少50%，效果堪比药物。Walker把这比作\"关闭浏览器的情绪标签页\"。"
    ],
    "highlights": [
      "这段话让我对Walker更加尊敬",
      "\"我觉得我以前做得特别不好，就是太直接了，尤其是对那些有睡眠问题的人。早期我传递这些信息时，我想在科学上保持严谨。但我也真的不想出去吓唬人，尤其是那些为睡眠挣扎的人，因为那可能只会让事情变得更糟。",
      "我通过学习如何成为一个稍微好一点的公众沟通者，得到了很好的教训。我确实觉得我犯了一个大错。我当时有点油门踩得太猛，刹车踩得太少。我对理想的睡眠世界有自己的想法，但我也意识到，我们没人生活在那个所谓的理想世界里。\"",
      "这种反思能力太难得了。一个顶级科学家能承认自己的沟通方式有问题，并且努力改进——这本身就是一种智慧。",
      "整期对话下来，最让我印象深刻的是Walker那句话：",
      "\"我觉得睡眠就像潮水，能抬高所有那些健康的船。它是身心健康最根本的层面。\"",
      "还有那个关于演化的思想实验——也许睡眠才是生命的原始状态，清醒反而是后来演化出来的。如果是这样，我们每天\"醒着\"其实才是异常状态，而\"睡着\"才是回归本源。",
      "这个彻底改变了我对睡眠的看法。",
      "本文基于Huberman Lab播客整理"
    ],
    "fullText": "斯坦福神经科学教授 Andrew Huberman 和加州伯克利睡眠研究专家 Matt Walker 的深度对话。\nWalker 有个反常识的观点：也许不是我们演化出了睡眠，而是我们从睡眠中演化出了清醒——睡眠才是生命的原始状态。\n他还提出了一个有趣的思想实验：从演化角度看，睡眠简直愚蠢透顶——你没法找伴侣、没法繁殖、没法觅食、还容易被捕食。但睡眠在演化的每一步都\"英勇抗争\"过来了，这说明它不可协商。\n总结一下做个笔记👇\n1️⃣ 快速眼动睡眠(REM)时，大脑会发信号让脊髓\"瘫痪\"全身骨骼肌。这是保护机制——让你的心智可以安全做梦，否则你梦见自己会飞就真从窗户跳出去了。\n2️⃣ 咖啡因不是给你能量，而是\"抢椅子\"——它占据腺苷受体但不激活，让大脑不知道你已经醒了16小时。咖啡因退去后，所有累积的腺苷一起涌来，这就是\"咖啡因崩溃\"。\n3️⃣ 睡前喝酒不是\"助眠\"而是\"镇静\"——酒精是在敲晕你的大脑皮层，这和自然入睡的脑电波完全不同。而且酒精会阻断REM睡眠，导致生长激素释放下降超过50%。\n4️⃣ 褪黑素不产生睡眠，只是\"发令员\"——它把睡眠选手叫到起跑线，但自己不参加比赛。研究显示褪黑素平均只增加3.9分钟睡眠，效果极其微弱。\n5️⃣ 市面上褪黑素补充剂通常是身体自然需求的10-20倍甚至更多。研究显示最佳剂量是0.1-0.3毫克，而药店常见的是5-10毫克——这是超生理剂量。\n6️⃣ REM睡眠是长寿的最强预测指标，而且是线性关系——每减少5%的REM睡眠，死亡风险增加约13%。这不是U型曲线，是直线。\n7️⃣ 酸樱桃汁的睡眠研究很惊人：三项独立研究分别发现它能减少1小时夜醒时间、增加34分钟和84分钟睡眠。猕猴桃（连皮吃）也有类似效果，机制可能是通过GABA系统。\n8️⃣ 性高潮后催乳素增加，催产素也上升，战斗逃跑系统消退——这些都是促进睡眠的机制。研究发现女性每多睡1小时，与伴侣发生性亲密关系的兴趣增加14%。\n9️⃣ 凌晨3-4点的担忧和白天完全不同——那时的焦虑带有灾难化程度，与清醒时不成比例。24小时自杀率数据显示，半夜几小时的自杀率高得不成比例。\n🔟 一晚糟糕睡眠后的最佳策略是\"什么都别做\"——别晚起、别午睡、别多喝咖啡、别提前上床。这样才能保持睡眠压力的自然累积。\n1️⃣1️⃣ 写\"烦恼日记\"（睡前1-2小时）能让入睡时间减少50%，效果堪比药物。Walker把这比作\"关闭浏览器的情绪标签页\"。\n断断续续，终于把这期三个多小时的Huberman Lab播客看完了。\n干货太多了。Matt Walker是加州伯克利的神经科学和心理学教授，专门研究睡眠，写过畅销书《我们为什么要睡觉》。Andrew Huberman说，这次和Walker的讨论让他对睡眠的理解，比他读过的所有论文和参加过的所有研讨会加起来还要多。\n我今天把这次访谈的精华整理出来，供大家学习。\n主持人：我们从最基础的问题开始，什么是睡眠？\nWalker：要说功能，睡眠可能是一个人能做的、用来重置身心健康的最有效的一件事了。但睡眠这个过程本身是一场极其复杂的生理芭蕾。如果你能看到晚上睡觉时大脑和身体发生了什么，你绝对会大吃一惊。\nWalker接着说了一个非常反常识的观点：\n\"我们一直假设我们是为了睡觉而演化的。但我质疑过这一点——有没有可能反过来，我们一开始就是睡着的，清醒状态反而是从睡眠中演化出来的？睡眠也许才是原始状态，是最根本的生命状态。\"\n这个思维方式太有意思了。如果是这样，那\"睡眠是我们为清醒付出的代价\"这种说法就得反过来想。\n主持人：快速眼动睡眠以前被称为\"矛盾睡眠\"，现在还这么叫吗？\nWalker：确实非常矛盾。如果我只测量你的脑电波，我坐在睡眠实验室外面光看脑电波的话，我很难判断你到底是醒着还是在REM睡眠——因为这两种状态下的脑电活动模式非常接近。\n但矛盾在于：你醒着的时候，我走进去你肯定是坐着、意识清醒；可一旦你进入REM睡眠，你的身体是完全动不了的。\n主持人：这是怎么做到的？\nWalker：就在你进入REM睡眠的前几秒，你的脑干会发一个信号，一直传到脊髓，和控制骨骼肌的运动神经元沟通。这个信号就是\"瘫痪\"的信号。所以当你进入梦境睡眠时，你整个人是被锁在自己身体里动弹不得的。\n主持人：大自然为什么要这么做？\nWalker：原因很简单——大脑麻痹了你的身体，好让你的心智可以安全地做梦。你想想，如果我们都会把梦里的动作做出来，那我们早就被基因库淘汰了。比如我梦见自己能飞，然后我就站到公寓窗户上跳了出去——那就完蛋了。\n这个解释太直观了。谢天谢地，非自主控制的肌肉没有被麻痹，所以你还能继续呼吸，心脏还在跳。这也是为什么男性在REM睡眠时会勃起、女性会有阴道润滑——那些自主神经控制的功能没有被关闭。\n主持人：你能带我过一遍一晚上的睡眠过程吗？\nWalker：我通常十点半睡觉，大概七点前自然醒。刚睡着时，我会先进入浅度的非快速眼动睡眠，也就是第一和第二阶段。然后大概20分钟后，开始往下进入更深的第三、第四阶段。\n我的心率开始下降，脑电波活动也开始变慢。醒着的时候，脑电波可能每秒活动二三十、四五十次，进入浅度睡眠后降到15-20次，然后真的开始慢下来，降到每秒8-10次。\n进入深度睡眠时会发生一件很了不起的事：突然之间，我大脑皮层里成千上万的细胞会决定一起放电，然后又一起沉默。这种生理协调在任何其他大脑状态下都看不到。\nWalker解释了关键的结构差异：\n\"前半夜那90分钟的周期里，大部分时间都是由大量的深度非快速眼动睡眠组成的。一旦进入后半夜，这个跷跷板的平衡就变了——大部分时间要么是浅睡眠，要么是越来越多的REM睡眠。\"\n这就是为什么坐红眼航班那么糟糕。如果你凌晨三点才睡觉，你不会从头开始获得深度睡眠，而是直接进入REM主导的阶段——你的深度睡眠会严重不足。\nWalker说了一段我觉得特别精彩的话：\n\"从演化角度看，睡眠简直太蠢了——或者说清醒才是愚蠢的。你没法找伴侣、没法繁殖、没法觅食、没法照顾后代，最糟糕的是你还容易被捕食。基于任何一个理由，睡眠都应该被自然选择淘汰掉。\n但它没有。睡眠在演化的每一步都英勇抗争过来了。这意味着每个睡眠阶段都是不可协商的。如果大自然找到了哪怕只从我们身上削减一点点睡眠的方法，那会带来巨大的演化优势。但看起来它并没有这么做。\"\n这段话太有力了。我们经常想着怎么少睡一点多干点活，但演化用360万年告诉我们：不行。\n主持人：咖啡因是如何让我们感觉更清醒的？\nWalker：我们先从腺苷说起。从你早上醒来的那一刻起，一种叫腺苷的化学物质就会在大脑里不断累积。你醒着的时间越长，累积的腺苷就越多，你就越困。这就是我们所说的\"睡眠压力\"。\n咖啡因做的事情很聪明——它进入你的系统，然后占据了那些腺苷的受体。但它并不是占据之后就去激活它们，那样反而会增加困意。\n咖啡因的作用方式是：它用相当尖锐的手肘和腺苷竞争，硬是把它们挤开，通过占据受体来劫持它，但之后只是把它堵住了。它在功能上让受体失效，因为它让腺苷没法玩了。\n这就像有人走进一个房间，你正要坐到椅子上，咖啡因冲进来把椅子抽走了。你就会想，好吧，现在我没地方坐了。\n这个\"抢椅子\"的比喻太形象了。所以即使你大脑里的腺苷浓度没变，但你的大脑已经不知道你醒了16小时还是6小时了——因为腺苷没法告诉大脑真实情况。\n那问题来了：咖啡因从受体上脱落时会发生什么？\nWalker：会发生不幸的事情，我们称之为\"咖啡因崩溃\"。你不光要面对喝咖啡前就有的那么多腺苷，还要加上咖啡因在你身体里这几个小时内累积出来的所有腺苷。感觉像是一场腺苷的海啸。\n咖啡因的半衰期大概是5-6小时，四分之一寿命大概是10-12小时。这就是为什么Walker建议睡前8-10小时停止摄入咖啡因。\n更可怕的是，即使你觉得晚上喝咖啡也能睡着，研究显示你的深度睡眠可能会减少高达30%。\"要让你的深度睡眠减少30%，我得让你老上10-12岁，或者你也可以每天晚上用几杯浓缩咖啡对自己这么做。\"\n主持人：如果有人晚上喝一两杯红酒，会对睡眠有什么影响？\nWalker：酒精属于镇静剂。人们常犯的第一个错误是把酒精当做助眠剂。但不幸的是，酒精根本不是助眠剂。\n酒精因为是镇静剂，它真正做的是想敲晕你的大脑皮层，它在镇静你的皮层，而镇静不是睡眠。但当我们晚上喝几杯睡前酒时，我们把镇静误认为是睡眠，会说\"我每次喝几杯都能更快入睡\"。事实上，你更快地失去意识，但你不一定能更快地自然入睡。\n酒精的第二个问题是它会使睡眠碎片化。它通过激活战斗逃跑神经系统，会让你在夜里醒来很多次。其中很多你不会记得，但你的睡眠会被弄得千疮百孔。\n第三个问题是酒精在阻断REM睡眠方面相当有效。\nWalker分享了一个惊人的研究数据：\n\"有一项研究让受试者喝到接近标准血液酒精浓度的水平。结果，在含有酒精的夜间睡眠中，他们的生长激素释放量下降了超过50%。\"\n生长激素对成年人的新陈代谢和组织修复至关重要。这个数据太吓人了。\n主持人：褪黑素作为补充剂对睡眠有帮助吗？\nWalker：可惜的是，证据表明，在健康的非老年人中，褪黑素作为助眠剂并不是特别有用。\n最近有一项荟萃分析告诉我们，褪黑素平均只会让总睡眠时间增加3.9分钟——是分钟，不是百分比——而且它只会让睡眠效率提高2.2%。\n真的，这效果太弱了。\nWalker解释了褪黑素真正的作用：\n\"褪黑素就像奥运会百米赛跑的发令员——它把所有睡眠选手叫到起跑线上，然后开始这场伟大的睡眠竞赛。但它自己不参加比赛，那是另一套完全不同的大脑化学物质和大脑区域的事儿。\"\n更让人担忧的是剂量问题：\n主持人：我们知道每晚通常有多少褪黑素被释放到血液里吗？\nWalker：市面上的剂量要高好几个数量级。我们发现能看到睡眠益处的最佳剂量大概在0.1到0.3毫克之间。市面上常见的剂量是5-10毫克，通常是身体自然期望的10倍、20倍甚至更多——这是超生理剂量。\n主持人分享了一个让人警觉的经历：\n\"很多年前我还是研究生的时候，我们会给季节性繁殖的动物注射褪黑素。结果它们的性腺，不管是睾丸还是卵巢，都会萎缩上百倍。从杏仁大小缩到一粒米那么大。我只要看过一次，就对超生理水平的褪黑素非常担心了。\"\n而且，有研究检测了超过20个不同品牌的褪黑素补充剂，发现实际含量从比标示少83%到比标示多478%不等。这个质控问题太严重了\n主持人：有没有什么非传统的助眠方法？\nWalker：说实话，几年前当人们开始说酸樱桃对睡眠有好处时，我想，天哪，这听起来有点你在加州待太久了。但作为科学家，我们必须保持开放的心态。\n我去查了文献，发现有三项非常好的随机安慰剂交叉实验。一项研究发现它让夜间醒着的时间减少了一个多小时；另外两项发现它让睡眠时间分别增加了34分钟和84分钟。\n而且这些都是独立的研究，来自不同的团队，我非常信任他们的工作。\n猕猴桃也有类似的效果：\nWalker：据我所知，真正有价值的人体研究只有一个，但他们发现它能缩短入睡时间、让人睡得更久、晚上醒着的时间也更少。\n主持人：是吃整个猕猴桃吗？\nWalker：是吃整个猕猴桃，连皮吃。\n主持人：人们看我这么吃都皱眉头！\nWalker：不不不，我觉得好东西可能就在皮里。\n更有意思的是机制：在动物研究中，研究者可以用GABA阻断剂来阻断猕猴桃的睡眠益处。这意味着猕猴桃对睡眠的好处，可能部分是通过大脑的天然抑制性神经递质系统GABA来介导的。\nWalker分享了一个非常重要的研究发现：\n\"大概两年前哈佛大学有一份报告，他们发现如果你看不同睡眠阶段对寿命的贡献，REM睡眠是你长寿的最强预测指标。\n而且这是一个线性关系，不是我们经常看到的那种U型或J型曲线。它真的是线性的——你得到的REM睡眠越少，你的死亡概率就越高。\n我记得是每减少5%的REM睡眠，相关的死亡风险就增加13%左右。\"\n这个数据太有力了。所以不只是深度睡眠重要，REM睡眠对长寿的预测能力甚至更强。\n这段对话让我松了一口气：\n主持人：很多人包括我自己，经常睡了三四个小时后就醒了。这对健康有多大害处？\nWalker：我觉得如果你像你描述的那样频繁醒来，我可",
    "ytTitle": null,
    "ytChannel": null,
    "ytChannelUrl": null,
    "ytViews": null,
    "ytPublished": null
  },
  {
    "id": "AHzkwSqoNim3zKk4zQkcO2HjnMe",
    "title": "十字路口播客 × ZARA访谈",
    "rawTitle": "0106-十字路口播客 × ZARA访谈",
    "dateCode": "0106",
    "youtubeId": null,
    "feishuUrl": "https://my.feishu.cn/wiki/AHzkwSqoNim3zKk4zQkcO2HjnMe",
    "intro": [
      "zara 是 25 年对我影响最大的博主，两个月前，我在即刻上分享过 zara 的创作方法。",
      "今天看到她去了十字路口的播客。",
      "花了一早上时间听完了这期十字路口采访张zara 的播客。",
      "干货太多了。Zara 可能是我今年见过的、把\"非技术背景如何在AI时代崛起\"这个问题讲得最透彻的人。",
      "她的小红书一年从2万涨到18万粉丝，发了将近500篇内容，平均1.5天一篇。",
      "她今年转岗做产品经理，业余用Vibe Coding发布了自己第一个产品。她曾经在The Information做记者，在真格、GGV做过VC，现在在硅谷某互联网公司——但她本科是哈佛心理学专业，完全没有技术背景。",
      "这期播客的信息密度极高。我把全文精编出来，按主题重新组织，供大家学习。"
    ],
    "highlights": [
      "Zara 凭一己之力，促进了小红书 AI 视频赛道的发展。",
      "每天我都能刷到许多人用和 zara 一样的方式",
      "分享自己使用 AI 的方式",
      "也让我投身其中，以热爱、好奇、成长为目的而创作内容",
      "借用我自己在各个社交媒体的签名“Simple living ，Lazy creating”来收个尾",
      "希望在新年，大家能像这期播客反复讲的——积极行动但不用太卷、太焦虑。",
      "松弛感的关键是找到那个属于你自己的成长方式。",
      "在成长的过程中找到自己。"
    ],
    "fullText": "zara 是 25 年对我影响最大的博主，两个月前，我在即刻上分享过 zara 的创作方法。\n今天看到她去了十字路口的播客。\n花了一早上时间听完了这期十字路口采访张zara 的播客。\n干货太多了。Zara 可能是我今年见过的、把\"非技术背景如何在AI时代崛起\"这个问题讲得最透彻的人。\n她的小红书一年从2万涨到18万粉丝，发了将近500篇内容，平均1.5天一篇。\n她今年转岗做产品经理，业余用Vibe Coding发布了自己第一个产品。她曾经在The Information做记者，在真格、GGV做过VC，现在在硅谷某互联网公司——但她本科是哈佛心理学专业，完全没有技术背景。\n这期播客的信息密度极高。我把全文精编出来，按主题重新组织，供大家学习。\n1 活人感是未来营销的关键词：AI生成内容泛滥，有真人气息的表达反而稀缺。OpenAI最有影响力的内容从来不是官方账号发的，都是Sam Altman自己发推。\n2 人人都是CMO：Lovable全员发推特造势、Arc每周更新把程序员大头贴放出来——小公司的竞争优势就是全员marketing。\n3 定位是折腾出来的，不是想出来的：她一开始也不知道该发什么，连续日更半年后才找到\"非技术背景看AI\"的独特视角。\n4 Follow builders, not influencers：Influencer转述信息，Builder分享实战。Granola创始人Krispi Dragon、Google Labs负责人Josh Woodward、PR教主Lulu——她的三位年度精神导师。\n5  反向提问法：别问AI问题，让AI问你问题。写文档前先和AI语音聊10分钟，一次只问一个问题，然后让AI整理成文档——这样写出来的东西完全是你的观点。\n6  5%的改变：李松蔚的理论——让人做超过5%的改变，人就不做了。她的建议是：先想周围人最常问你的三个问题，那就是你的冷启动内容。\n7  Long game思维：她小红书没有任何变现，但她说\"今天涨的每一个粉丝都是未来省的marketing成本\"——积累Karma功德银行。\n8 Technically curious > Technical：技术好奇心是后天习得的心态，不是技术背景决定的。她身边很多程序员对AI进展毫无兴趣。\n9  AI帮她学会了产品：不是AI传授知识，是AI降低了实践门槛。学产品最好的方式就是用Cursor做产品、发产品、收反馈。\n10  松弛感的成长：她录视频对她来说像玩一样。找到那种\"别人觉得是工作，你觉得像玩\"的事——What feels like play to you but feels like work to others.\n11  产品与内容的本质相同：都是\"人类行为预测系统\"——发了之后看反馈，不断训练sense，循环次数越多越有竞争力。\n12  三圈定位法：你想说的 ∩ 受众想听的 ∩ 对你有利的 = 你的个人定位。Who比How many更重要。\n13  AI时代的两类人：对High agency的人是最好的时代，AI是超能力；对另一类人可能是被取代——但Agency大于Intelligence。\n播客地址：\n主持人：你今年有没有注意到一些新的趋势，尤其是可能别人没有特别注意到的？\nZara：我个人一直比较关注的是go-to-market和营销方面的变化。AI降低了产品开发的成本，速度大大提升，成本大大下降。但与此同时，营销和分发变得更难了。\n以前我们会认为代码是稀缺资源，因为开发成本非常贵。现在我觉得注意力才是一个更稀缺的资源。\n之前大家说\"万事俱备，只欠CTO\"。现在感觉CMO变得更重要了。讲故事的能力、营销、创建用户社区——这些都变得非常重要。\n她后来在推特发了一条话，把这个观点推到了极致：\"以前叫Talk is cheap, show me the code. 现在反过来了——Code is cheap, show me the talk.\"\n代码门槛崩塌之后，真正稀缺的是什么？是洞察力、是讲故事的能力、是分发。这正是文科生的主场。\n主持人：社交媒体上充斥着AI生成的内容，你觉得什么样的内容会脱颖而出？\nZara：如果你用AI写出来的内容没有任何真实感，我感受不到背后有一个独特的观点，你都没有effort去把它改得不像AI——这个内容就有问题。\n我觉得未来营销的关键词是活人感。\n我需要感受到你的产品或内容背后有一个活生生的人，我能跟你产生一种连接。比如播客就是一个非常有活人感的媒介。你一听就知道不是AI，因为我们的声音有瑕疵。\n你想想，OpenAI最有影响力的内容什么时候是官方账号发的？多数情况都是Sam Altman自己在发推特。大家喜欢follow人，而不是品牌。\n她举了一个很有意思的例子：Arc浏览器每周更新的Changelog，不是冷冰冰地列10个功能，而是图文并茂、涂鸦风格，甚至会把做这个功能的程序员名字和大头贴放上去。\n这就是活人感。你产生了和这个产品非常强的连接感和社区感。\n主持人：你能举一些全员CMO的创业公司例子吗？\nZara：比如Lovable，他们非常重视Employee Social。不仅是创始人天天发推特，员工也鼓励大家天天发推。每发一个新功能，全员都会去转发造势。\n就像聚美每次大促，全员都会把微信头像改成301或者901——就是周年庆的那个大图标。\n其实小公司在这方面有巨大优势。大公司有各种PR政策不让大家出去讲，但小公司可以全员marketing。\n主持人：有些人担心说错话怎么办？\nZara：你做了一个产品，你不讲大家完全不知道。这等于白做了。最害怕的是nobody cares——默认情况就是nobody cares。\n大部分人的问题不是说错话，而是根本没人知道你在做什么。在注意力稀缺的时代，沉默才是最大的风险。\n主持人：你小红书涨得很快，但很多人不知道怎么找自己的定位。\nZara：我今年从2万涨到18万粉丝，但更值得关注的数字是——我总共发了将近500篇。平均1.5天一篇。刚开始是连续日更了半年，一天都没断过。\n很多人问我怎么找定位。我也没办法告诉你你的定位——可能你现在也不知道。但你先别想那么多，先去发。\n发了几十、一百篇之后，你就会有感觉。你会知道什么样的内容大家喜欢看，什么样的没人看。这个sense是训练出来的。\n定位不是你想的定位，而是观众觉得你的定位才是你的定位。\n主持人：你早期发的内容现在回头看是什么感受？\nZara：我早期定位也没想清楚。我后来的定位跟一开始想的也不太一样。我发现定位这件事情不是想出来的，是折腾出来的。\nZara 现在的定位是：\"从一个非技术背景的从业人员的视角来分享对AI趋势的一些见解，包括个人的学习成长。\n这个定位其实很巧妙——绝大部分讲AI的人都是技术背景，但世界上绝大部分人都是非技术背景。供需错配，造就了蓝海。\n主持人：你小红书分享的资源推荐类内容很火，你怎么找内容？\nZara：我有一个原则：Follow builders, not influencers.\n刚开始我也follow了很多influencer，Twitter上的营销号，谁发了什么模型就讲一讲，没有什么观点或洞察\n后来我发现，最高质量的信息都来自于行业实际从业者。比如OpenAI、Anthropic的人，Cursor这些创业公司的创始人或团队成员。他们非常喜欢对外分享，而且全都是免费公开的。\n我养成了一个习惯：从头到尾看完一个YouTube长视频。有些人的内容干货密度非常高，从头到尾没有一句废话。\n从头到尾看完就好像我跟他开了一个视频会议一样。我可以免费跟硅谷最top的从业者开视频会议。\n十字路口 2025 年最火的一期是采访刘小排——Claude Code token消耗全球第一的那个华人。他也是一个Builder，讲的东西来自实战经验，不是转述别人的。\nInfluencer接广告推产品，Builder分享因为不靠这个赚钱，所以更真诚。\n主持人：今年有哪些Builder给了你很大启发？\nZara：第一个是Granola的创始人Krispi Dragon。 他有几句话让我印象很深：作为产品经理，你当然要做用户访谈，但不是用户说什么你就做什么。每个用户说的东西是在提升你的直觉，最后还是要靠你的直觉在做。\n他还说，在应用层不要跟模型层竞争，而是借用它的优势。\n第二个是Google的VP Josh Woodward，他是Gemini和Google Labs的负责人。今年Google的AI产品有很大突破，从追赶变成杀出来了。\n他让我印象深的是：他说Google Labs发新产品时，他让产品经理不要盯着数字看板。去看用户的眼睛，看他们有没有眼前一亮，有没有Aha moment。 早期这个指标比数字更重要。\n第三个是Lulu，硅谷的PR教主。她有一个很有影响力的观点叫Go Direct——创业者CEO要自己去跟受众产生影响，不要通过媒体中介。\nZara 还有一个三圈理论：你想说的 ∩ 受众想听的 ∩ 对你有利的 = 你的个人定位。对Founder来说，Who比How many更重要。\n主持人：有没有特别推荐的AI用法？\nZara：你要颠倒你跟AI的交互关系。 绝大部分人是问AI问题，我一直认为应该是AI问人问题。\n比如我要写一个文档，第一件事不是坐在电脑前打开空白文档开始打字。我会打开Claude或ChatGPT语音模式，说：\"我现在要写一个产品方案，一次性问我一个问题，帮我把这个想清楚。\"\n然后AI就开始问：你的受众是谁？你要解决他们什么问题？这个跟竞品有什么区别？我就啪啪啪输出，因为讲话是没有门槛的。\n聊了十几分钟，我跟AI说：\"下面把我刚才说的整理成一个文档。\"——文档就写出来了，稍微改一改就能用。而且写出来完全是我的东西，不像AI写的。\n这个方法还有一个好处：你可以在不方便写作的时候写作。她说有一次堵车，就跟ChatGPT语音聊了一个文档，到家文档就写出来了。\n另一个技巧：问AI \"你需要我给你什么\"。很多时候你给的上下文不够充足，AI就开始干活产出很差。你加一句\"你需要我给你什么才能干得更好\"，AI就会反问自己需要什么信息。\n主持人：很多人知道要行动，但就是迈不出第一步，你有什么建议？\nZara：心理学家李松蔚有个理论叫5%的改变——让人做超过5%的改变，人就不做了。\n我在规律发小红书之前也犹豫了一年。买了灯、三脚架，说我要拍什么，结果一年设备都落灰了。后来有一天我说我不管那么多了，先发。\n如果是第一次做内容不知道讲什么，你可以先回想：周围的人最常问你的三个问题是什么？ 如果大家经常问你一个问题，说明这个点在别人眼里是你最有趣的地方。\n这些东西在你看来可能特别理所当然，但恰恰是大家会感兴趣的。如果你能跳出来，用小白语言讲出来——这就是大家想听的。\n主持人：你又上班又发小红书又做产品，怎么有那么多时间？\nZara：我反问你：你怎么有时间刷小红书、刷抖音、打游戏、看剧？\n这些事对我来说就是娱乐，是一个正反馈很强、给我能量的事情。它不消耗我能量，所以非常可持续。我在里面是非常有松弛感的。\n很多人说真正的放松不是躺着，也不是刷短视频——刷完会觉得空虚难受。\n我今年的另一个关键词是有松弛感的成长。我没有逼自己做任何事情，这些事无缝融入到了日常生活工作的一部分。\n主持人：怎么找到这种松弛？\nZara：包括定位、包括松弛感，都不是坐在家里想出来的。它背后需要努力和行动才能找到。\n去年学AI的时候我还挺焦虑的，觉得没有相关背景。但我持续去试这个事，没有放弃。今年有了一些突破，有一些真能做出来，有正反馈了。\n前提是你要持续去试，不能放弃。 当你有了反馈之后，这件事就更容易变成你喜欢的事。变成你喜欢的事，你才能有松弛感。\nPaul Graham有一篇文章叫《如何成就伟大事业》，里面有一句话：找到那种你做起来毫不费力、但别人觉得做不了的事——What feels like play to you, but feels like work to others.\n主持人：你小红书有没有变现？那些产",
    "ytTitle": null,
    "ytChannel": null,
    "ytChannelUrl": null,
    "ytViews": null,
    "ytPublished": null
  },
  {
    "id": "F6YdwQ4EliqtRmkg2D1c2Qgvnae",
    "title": "0114尹烨 X 脱不花：不花钱的养生方法",
    "rawTitle": "0114尹烨 X 脱不花：不花钱的养生方法",
    "dateCode": "",
    "youtubeId": null,
    "feishuUrl": "https://my.feishu.cn/wiki/F6YdwQ4EliqtRmkg2D1c2Qgvnae",
    "intro": [
      "今天看到尹烨去了脱不花的播客。花了三个小时听完了这期播客。干货太多了。",
      "尹烨是我这几年见过的把\"健康长寿\"这个问题讲得最透彻的人。他是华大基因CEO，做了二十多年基因研究，但他讲的不是高科技抗衰，而是几乎不花钱的养生方法。他有一个核心观点：人体是生态系统，不是汽车——你不能靠\"换件\"来维护，只能靠\"稳态\"来经营。",
      "这期播客的信息密度极高。我把全文精编出来，按主题重新组织，供大家学习。"
    ],
    "highlights": [
      "脱不花：如果对预期寿命缺乏想象力，人们会犯什么错误？",
      "尹烨：两个极端。一个觉得自己还能活很久，就不在意当下，今天先作一下明天再补。另一个觉得自己活不了那么久，所以更要挥霍。",
      "其实所有人都不可能掌控未来，但所有人都能把握当下。未来就是由无数个现在的积分构成的。控制这一刻就是控制未来。",
      "你怎么过今天你就怎么过今生。今生是由无数个一天决定的。",
      "尹烨凭多年基因研究和科普，把\"健康长寿\"从玄学变成了可操作的科学。让我最触动的是那句\"人体是生态系统，不是汽车\"——我们总想着偶尔放纵、事后补救，但生态要的是稳态，不是波动。",
      "借用尹烨的话来收个尾：怎么过今天就是怎么过今生。希望大家能像这期播客反复讲的——用理性骗身体的本能，远离多巴胺刺激，回到内啡肽成就。活在当下，热气腾腾。"
    ],
    "fullText": "今天看到尹烨去了脱不花的播客。花了三个小时听完了这期播客。干货太多了。\n尹烨是我这几年见过的把\"健康长寿\"这个问题讲得最透彻的人。他是华大基因CEO，做了二十多年基因研究，但他讲的不是高科技抗衰，而是几乎不花钱的养生方法。他有一个核心观点：人体是生态系统，不是汽车——你不能靠\"换件\"来维护，只能靠\"稳态\"来经营。\n这期播客的信息密度极高。我把全文精编出来，按主题重新组织，供大家学习。\n1. 生态vs机器：人体不是汽车，不能靠换件保养。人最怕的是波动——不要大喜大悲，不要忽高忽低，生命的本质是稳态\n2. 吃到不饿：不是七分饱八分饱，而是\"不饿就停\"。这个标准比任何数字都精准，因为消化到感知需要时间差\n3. 先菜后肉：先吃沙拉，再吃蛋白，最后吃碳水。顺序比吃什么更重要，能把血糖曲线从尖峰变成缓坡\n4. 饭后两分钟：饭后百步走不是迷信，走两分钟血糖就平了。身体以为你要消耗，就不会把能量存成脂肪\n5. 深度睡眠=洗脑：脑脊液在深度睡眠时冲刷大脑，带走阿尔兹海默相关的废物蛋白。睡眠是重启，不是休息\n6. 对抗菌群：睡前饿是肠道菌群在勾搭你，不吃，第二天醒来反而不饿。你要用理性骗身体的本能\n7. 学个乐器：所有乐器都是后来学的，会开发新脑区。这是预防老年痴呆回报率最高的投资\n8. 行善是养生：日行一善不是道德标准，是养生行为。行善产生内啡肽，让你处于达观状态\n9. 多巴胺vs内啡肽：中年人要远离多巴胺刺激，回到内啡肽成就。前者是瘾，后者是满足\n10. 女性长寿密码：两条X染色体是备份，左右脑连接更强善于倾诉，雌激素周期保护心血管，社会教育趋于温和\n11. 抗衰不花钱：调好嘴、迈开腿、睡好觉、做好事、好心情——这五条做完美，你还衰什么衰？\n12. 单一配方=智商税：但凡你认为单一化学物质就能抗衰，都是智商税。低维度的东西改变不了复杂系统\n脱不花：您觉得普遍的健康误区是什么？\n尹烨：我们没有把人体当成一个生态系统去管理，把它看成了一辆汽车去管理。你认为能换件、能保养，我今天缺油了下次加满。不行的。\n人最怕的实际是波动。不要大喜大悲，不要忽高忽低。\n很多人血糖管理说\"我最近血糖不稳\"，就老波动。胰岛就怕这样子，一会儿高了一会儿低了。所以我并不主张大家今天暴饮暴食，然后饿两天；连续熬夜，然后周末补觉；从来不运动，上来先跑个400。都是这么出事的。\n这个观点太重要了。我们总想着\"偶尔放纵一下，回头补回来\"，但身体不是这么运作的。它是生态，生态最核心的是稳定。你不能今天大火明天严寒，谁受得了。\n尹烨：吃饭的时候有一个特别简单的事情，大家就可以平抑血糖——先吃菜。\n我们一般建议先吃沙拉。沙拉本身热量极低，但有大量的膳食纤维。吃完以后你会觉得没那么饿了，这个时候再吃蛋白，最后吃点主食，你就可以把碳水往后倒。\n油醋汁就够了，不一定要拌沙拉酱，热量太高。橄榄油、亚麻籽油这类不饱和脂肪酸为主的油，配上醋。多一克醋减一克盐，这是每天要干的事。\n脱不花：那\"吃到不饿\"这个标准怎么把握？\n尹烨：不是七分饱八分饱，那个词儿很难理解。就是不饿就可以停了。你要知道消化再到你的感知要一个时间差，等你感觉饱了其实已经过了。\n尹烨：饭后百步走真的有道理。现在24小时血糖仪都有了，好几个人给我反馈说，走两分钟血糖就是平的。\n为什么呢？吃完饭你往椅子上一倒，胰岛觉得你吃这个糖是为了要贮存，要打仗去，得把能量给你存起来。而吃完饭一走，身体以为你要消耗，就把糖给消耗掉了。\n人是一个很精准的东西，它知道你躺着还是立着。我们要用理性和认知来骗身体的本能。\n这让我想到很多人吃完午饭就瘫在椅子上刷手机。其实就站起来走两分钟，血糖曲线就完全不一样了。\n尹烨：人类要拿出三分之一的时间去睡觉。睡觉怎么可能就是简单的让你休息一下？它一定有非常深层次的生物学功用。\n脑脊液充斥在我们整个大脑外围，它的核心作用就是洗脑——真正生理意义上的洗脑。接进来刷一遍，回来再刷，把废物带走。\n如果没有深度睡眠就洗得不彻底。阿尔兹海默症不就是淀粉样蛋白沉积吗？一个给大脑糊上，一个把神经连接缠上。谁来把这些有问题的东西带走？靠脑脊液，在深度睡眠中进行。\n脱不花：所以熬夜的危害是...\n尹烨：你的大脑没有被充分清洗。越来越记不住事儿，越来越觉得跟睡了跟没睡似的。\n这给我吓着了。以后再也不敢熬夜了。\n尹烨：很多时候睡前很饿，如果不吃，醒了以后你饿吗？不饿。\n这个时候你要明白，我又战胜了一次肠道菌群对我的勾引。好多时候没有成就感，最喜欢干的事情就是胡吃海塞、剁手买东西。\n脱不花：所以睡前乱吃东西是因为没有成就感？\n尹烨：是这样。那个时候你处于多巴胺刺激的状态，越多越大，没有头。但内啡肽不一样，完成了我就OK。\n中年人要远离多巴胺的刺激，回到内啡肽的成就。睡前背单词、背古文，有一点成就感来了，脑袋那个场强要调动起来，反而能睡着。\n我有个哥们儿原来睡不好觉，现在打开英文书就睡了。\n脱不花：预防老年痴呆有什么建议？\n尹烨：学一种乐器。特别具体，但这是回报率最高的。\n所有的乐器都是后来学的，它用的是一个全新脑区。语言是从小学的，你的中文英文可能在不同脑区，但都是早期形成的。乐器不一样，它相当于开发了一个备份的地方。\n你还记得《寻梦环游记》吗？那个奶奶Coco什么都忘了，最后孙子弹吉他，remember me，她就想起来了。这个片子是非常深层次的脑科学认知。音乐用的是很远的脑区，最后都忘了，这个还记得。\n脱不花：那美术呢？\n尹烨：不行，后来眼睛不行。人到老年视力跟不上，但乐器可以，它能取悦自己到很老。\n尹烨：过去我们认为行善是个道德标准，现在它是一个养生行为。\n日行一善，它是正向心理学的一部分，有脑科学和神经生物学的基础。行善产生内啡肽，让你处于达观的状态——不是乐观和悲观，是超越乐和悲。\n你的过去可以被你的未来所治愈。666次失败665次，最后一次成功，前面都被治愈了。人类最了不起的神性，是相信的力量。\n脱不花：所以家里脾气大的人...\n尹烨：鼓励他行善。咱不为了别人，咱为了自己养生。\n脱不花：关于抗衰，我们最应该知道什么？\n尹烨：养生的方法绝大部分都不花钱。先把\"抗衰等于昂贵\"这件事拆开。\n我要说五条：调好嘴——吃到不饿，先吃蔬菜，多醋少盐，多茶少酒；迈开腿——7000到9000步就够了；睡好觉；做好事；好心情。\n这五项做完美的人，你还衰什么衰？就活在那个自洽的世界里。\n脱不花：那硅谷那个抗衰狂人呢？\n尹烨：各种失败。三代换血失败，各种都没有证明取得更好效果。如果抗衰是富豪的奢侈品，永生的人会被非永生的人用物理的方式干掉。坐头等舱，我坐经济舱，我把船凿了一样。\n脱不花：哪些抗衰是智商税？\n尹烨：但凡你认为单一配方就能抗衰的问题都是智商税。\n一个化学物质，你说就这一个点上就能解决，这往往就是智商税。化学是个低维度的，生命是高维度的。用一个低维度的东西就能把复杂系统完全改变了，这怎么可能？\nVC就是VC，从植物里提的还是化学合成的，它就是一样的。很多人说VC有橙子味儿，那是橙子香精有橙子味。泡腾片有什么好处？多喝了杯水。\n脱不花：女性预期寿命比男性长，这是为什么？\n尹烨：几个假说。第一，女性是两条X染色体，相当于代码量加倍了，有备份。男性XY，X上有问题就是有问题，没得补。\n第二，女性左右脑连接更强，共情能力强，更善于倾诉和化解压力。你看母猴们都在那带崽儿、互相抓虱子，那就是聊天。\n第三，女性有激素周期变化，雌激素对心脑血管有保护作用。\n第四，社会对女性的教育趋于温和。暴力犯罪98.5%以上都是男性。女性更容易达成互洽，而不是赶尽杀绝。\n日本有个数据：结婚的男性平均活81岁，不结婚的67岁。没有老太太管他，老头死得多快。\n脱不花：如果对预期寿命缺乏想象力，人们会犯什么错误？\n尹烨：两个极端。一个觉得自己还能活很久，就不在意当下，今天先作一下明天再补。另一个觉得自己活不了那么久，所以更要挥霍。\n其实所有人都不可能掌控未来，但所有人都能把握当下。未来就是由无数个现在的积分构成的。控制这一刻就是控制未来。\n你怎么过今天你就怎么过今生。今生是由无数个一天决定的。\n尹烨凭多年基因研究和科普，把\"健康长寿\"从玄学变成了可操作的科学。让我最触动的是那句\"人体是生态系统，不是汽车\"——我们总想着偶尔放纵、事后补救，但生态要的是稳态，不是波动。\n借用尹烨的话来收个尾：怎么过今天就是怎么过今生。希望大家能像这期播客反复讲的——用理性骗身体的本能，远离多巴胺刺激，回到内啡肽成就。活在当下，热气腾腾。\n",
    "ytTitle": null,
    "ytChannel": null,
    "ytChannelUrl": null,
    "ytViews": null,
    "ytPublished": null
  },
  {
    "id": "UQudwg5xYiSaY4kYVaXckbVlnad",
    "title": "0115Anthropic :AI 在校园的真实使用情况",
    "rawTitle": "0115Anthropic :AI 在校园的真实使用情况",
    "dateCode": "",
    "youtubeId": null,
    "feishuUrl": "https://my.feishu.cn/wiki/UQudwg5xYiSaY4kYVaXckbVlnad",
    "intro": [
      "今天看到 Anthropic 的 Greg 邀请了四位来自 LSE、普林斯顿、伯克利和 ASU 的学生大使聊 AI 在校园的真实使用情况。花了一小时听完了这期播客。",
      "这几位学生（Zen, Kovay, Marcus, Tino）他们身处名校，既是学生也是 Claude 校园大使，直接观察到了 90% 的学生是如何在“灰色地带”中使用 AI 的。他们提到的“AI 是动机的镜子”和“所有权羞耻”等概念非常深刻。",
      "这期播客的信息密度极高。我把全文精编出来，按主题重新组织，供大家学习。"
    ],
    "highlights": [
      "断断续续，终于看完了这期 Anthropic 制作的深度对话。",
      "干货很多。Greg 找来的这四位学生（Zen, Kovay, Marcus, Tino）可能是目前对“AI 进校园”最有发言权的人。他们不仅自己是高频用户，还是校园里的推广大使，看尽了身边同学的各种骚操作和真实困惑。",
      "为什么值得关注？因为大家都在聊“AI 颠覆教育”，但大多是专家在臆测。而这期对话直接把麦克风交给了学生，揭示了**“作弊”与“协作”之间那条模糊的线到底在哪**。",
      "我今天不忙，把这次访谈全文精编出来，供大家学习。赠人玫瑰，手有余香。",
      "下面是 Youtube 链接：https://www.youtube.com/watch?v=...",
      "#01 AI 是学习动机的“照妖镜”",
      "主持人：我们先聊聊大环境，现在校园里关于 AI 的氛围是什么样的？",
      "Marcus (Berkeley)：不管是写作业、总结讲座，还是在助教没空时答疑，几乎所有人（90%）都在用 AI。",
      "Zen (LSE)：我觉得 AI 在教育中其实是一面镜子，能照出你上大学的动机。",
      "学生的动机大概分三类：",
      "1. 深造：钻研专业知识。",
      "2. 职业准备：找份好工作。",
      "3. 社交：混个文凭，享受生活。",
      "AI 把这些动机暴露无遗——想省时间去玩的人，会让 AI 代劳把活干了；而真心想深造的人，会避开 AI 的捷径，或者积极地用它来强化理解。",
      "我：这个“镜子理论”真的太精准了。AI 并没有改变人性，它只是放大了人性。想偷懒的更容易偷懒，想学习的能学得更快。",
      "Tino (ASU)：说实话，现在你有工具可以不学无术也能混毕业，所以责任完全回归到了学生自己身上。你想走捷径，它能帮你完全绕开思考；你想学，它能让你学得更好。",
      "#02 到底什么算作弊？划出“所有权”的底线",
      "主持人：怎么区分良性协作还是过度依赖？这道线很难划。",
      "Kovay (Princeton)：我划出了一道清晰的底线：如果我坐在这个房间里，却没法解释或者辩护我做出来的东西，那就不行。",
      "即便别人问了一个非常刁钻的问题，我也得能答上来。如果你根本不理解背后的逻辑，那就是越界了。这关乎所有权（Ownership）。"
    ],
    "fullText": "今天看到 Anthropic 的 Greg 邀请了四位来自 LSE、普林斯顿、伯克利和 ASU 的学生大使聊 AI 在校园的真实使用情况。花了一小时听完了这期播客。\n这几位学生（Zen, Kovay, Marcus, Tino）他们身处名校，既是学生也是 Claude 校园大使，直接观察到了 90% 的学生是如何在“灰色地带”中使用 AI 的。他们提到的“AI 是动机的镜子”和“所有权羞耻”等概念非常深刻。\n这期播客的信息密度极高。我把全文精编出来，按主题重新组织，供大家学习。\n本期对话揭示了 AI 原住民一代如何在学校规则尚未跟上的情况下，自行探索与 AI 共存的伦理和方法。\n教育中的 AI 本质：一面镜子\n1. 动机的镜子：AI 是一面镜子，照出你上大学的动真正机。如果你只想混文凭，它就是最好的代劳工具；如果你想深造，它是最强的强化学习导师。\n2. 所有权底线：能否辩护是核心界限。如果你坐在这个房间里，却无法解释或辩护你（用 AI 辅助）做出来的东西，那就是越界了。\n3. AI垃圾（Slop）定义：如果 AI 生成的内容还不如你自己动脑子想出来的好，或者充满了套路化的“AI 腔”（比如滥用破折号），那就是垃圾内容（Slop）。\n4. 所有权羞耻：学生普遍存在一种矛盾心理——即便只是用 AI 做辅助或头脑风暴，也会下意识隐瞒，“羞耻”于承认自己使用了 AI，因为目前仍缺乏描述这种“人机协作”的恰当语境。\n5. 项目化学习法：高效的用法是为每门课在 Claude 里建立一个独立的 Project，上传大纲和资料，把它当成专注的“课程助教”进行深度对话，而非简单的一问一答。\n6. 编程门槛消失：文科生（心理学、政经）几天内就能用 Cursor 或 Claude 做出能跑的 APP。不仅是写代码，更是实现了从“想法”到“产品”的零门槛跨越。\n7. 逆向图灵测试：学生开始用 AI 模拟教授或面试官。在提交作业前，先让 AI 扮演教授评分并给出反馈；找工作时，用 AI 模拟面试官进行对练。\n8. 灰色地带的自律：学校政策往往滞后，有的课禁用有的课鼓励。学生处于“灰色地带”，必须依靠自律来决定是“外包思考”还是“辅助思考”。\n9. 反直觉的作弊：“作弊”不仅是直接复制答案，不仅没意义，而且在面对最后的“答辩”环节时会原形毕露——AI 无法替你为观点辩护。\n10. 招聘新标准：企业现在的面试（如 HireVue）甚至本身就是 AI 面试官。懂 AI 且能展现“AI 素养”的毕业生，比传统全能型学生更受青睐。\n断断续续，终于看完了这期 Anthropic 制作的深度对话。\n干货很多。Greg 找来的这四位学生（Zen, Kovay, Marcus, Tino）可能是目前对“AI 进校园”最有发言权的人。他们不仅自己是高频用户，还是校园里的推广大使，看尽了身边同学的各种骚操作和真实困惑。\n为什么值得关注？因为大家都在聊“AI 颠覆教育”，但大多是专家在臆测。而这期对话直接把麦克风交给了学生，揭示了**“作弊”与“协作”之间那条模糊的线到底在哪**。\n我今天不忙，把这次访谈全文精编出来，供大家学习。赠人玫瑰，手有余香。\n下面是 Youtube 链接：https://www.youtube.com/watch?v=...\n#01 AI 是学习动机的“照妖镜”\n主持人：我们先聊聊大环境，现在校园里关于 AI 的氛围是什么样的？\nMarcus (Berkeley)：不管是写作业、总结讲座，还是在助教没空时答疑，几乎所有人（90%）都在用 AI。\nZen (LSE)：我觉得 AI 在教育中其实是一面镜子，能照出你上大学的动机。\n学生的动机大概分三类：\n1. 深造：钻研专业知识。\n2. 职业准备：找份好工作。\n3. 社交：混个文凭，享受生活。\nAI 把这些动机暴露无遗——想省时间去玩的人，会让 AI 代劳把活干了；而真心想深造的人，会避开 AI 的捷径，或者积极地用它来强化理解。\n我：这个“镜子理论”真的太精准了。AI 并没有改变人性，它只是放大了人性。想偷懒的更容易偷懒，想学习的能学得更快。\nTino (ASU)：说实话，现在你有工具可以不学无术也能混毕业，所以责任完全回归到了学生自己身上。你想走捷径，它能帮你完全绕开思考；你想学，它能让你学得更好。\n#02 到底什么算作弊？划出“所有权”的底线\n主持人：怎么区分良性协作还是过度依赖？这道线很难划。\nKovay (Princeton)：我划出了一道清晰的底线：如果我坐在这个房间里，却没法解释或者辩护我做出来的东西，那就不行。\n即便别人问了一个非常刁钻的问题，我也得能答上来。如果你根本不理解背后的逻辑，那就是越界了。这关乎所有权（Ownership）。\nZen (LSE)：我完全同意。如果你的产出被质疑时，你无法像给五年级小学生解释一样把它讲清楚，那这东西就不是你的，是你从 Claude 那里“偷”来的。\n我：这其实提出了一个新的考核标准——答辩（Defense）比作业（Homework）更重要。在 AI 时代，提交什么已经不重要了，重要的是你能否捍卫你的观点。\nMarcus (Berkeley)：没错。作弊只是第一层。大 Boss 是最后的演示环节。那时候 AI 可没法替你说话，也没法替你思考。\n#03 “AI 垃圾”与“所有权羞耻”\n主持人：美式词典把 \"Slop\"（垃圾内容） 选为年度词汇。对你们来说什么算 AI Slop？\nMarcus (Berkeley)：如果 AI 给我的结果还不如我自己动脑子想出来的好，那就是垃圾。特别是那种套路化的求职信。\nKovay (Princeton)：现在的模型（Claude/GPT）都有特定的“语调”，比如特别喜欢用破折号，或者某种机械的结构。有些学生做小组作业，直接把 AI 生成的东西贴上来，甚至连“Claude 可能会犯错”的提示语都忘了删。这就是我定义的 AI 垃圾。\n我：这太真实了。现在看文章，扫一眼那股“AI 味”就出来了。\nZen (LSE)：还有一个有趣的现象是“所有权羞耻”。即使有些学生是用 AI 做正经项目，一提起来也会说“我只是稍微用了点 AI”。\n因为现在人类和 AI 的界限模糊了，大家很难说清谁在主导。虽然他们做了很多头脑风暴，但被问到时往往会把功劳都推给 AI，或者因为用了 AI 而感到不好意思。我们还缺乏一套话语体系来大大方方地描述这种“人机协作”。\n#04 文科生也能手搓 APP：编程门槛的消失\n主持人：既然是 Claude Builder Club，大家都在造什么呢？\nMarcus (Berkeley)：我觉得 AI 最大的突破就是降低了门槛。哪怕没有计算机背景，学政经、心理学甚至数学的同学，都能在几天内把想法变成能跑的原型。\nKovay (Princeton)：我这儿有个例子。普林斯顿有一群大一新生，完全是出于好玩，做了一个“普林斯顿愿望清单”的项目，帮大家实现毕业前想做的事。他们是舍友，原本是非技术背景，但做出来的东西非常有洞察力。\nZen (LSE)：我们学校也是。以前社团只有一个简单的 Instagram 页面，现在都在用 Claude Code 搭建内容丰富的网站。\n我：这个趋势非常明显。AI 抹平了 \"Coding\" 的技能门槛，现在比拼的是 \"Idea\" 和 \"User Insight\"。\n#05 给同龄人的建议：Project 化学习\n主持人：对于现在这些学生，你们有什么建议？\nTino (ASU)：学会它。 无论你想创业还是学习。\n我有具体的操作建议：给你在大学上的每一门课都开一个独立的 Project。\n把大纲、资料、讲义全部传上去，把它当成这门课的专属助教。不要只是简单地问答，要与它进行长对话，让它理解这门课的上下文。\nZen (LSE)：还有，利用好 \"Style\"（风格设置）。比如用“学习模式”，让它反过来问你问题，引导你循序渐进地理解，而不是直接给你答案。如果在提交作业前，你还可以让它模拟苛刻的教授给你打分。\nGreg 和这几位校园大使展示了 AI 浪潮中最真实的一面——混乱、热情、灰色地带，但也充满了进化的可能。\n我特别喜欢 Zen 说的那个比喻：AI 是面镜子。它不负责教你做人，但它会诚实地反映出你是一个想糊弄过去的人，还是一个想真正变强的人。\n借用一句非常有力的个人签名来收个尾：\"Technology is a bicycle for the mind.\"（乔布斯）。\n希望大家能像这期播客反复讲的——不要让 AI 替你骑车，而是要学着驾驭这辆自行车，去到以前靠双脚走不到的远方。\n",
    "ytTitle": null,
    "ytChannel": null,
    "ytChannelUrl": null,
    "ytViews": null,
    "ytPublished": null
  },
  {
    "id": "UrpAw5FxdiqAqFkSKPlcpEDNnLf",
    "title": "0122被马斯克开除的 xAI 员工，在播客中说了什么",
    "rawTitle": "0122被马斯克开除的 xAI 员工，在播客中说了什么",
    "dateCode": "",
    "youtubeId": null,
    "feishuUrl": "https://my.feishu.cn/wiki/UrpAw5FxdiqAqFkSKPlcpEDNnLf",
    "intro": [
      "今天看到一期炸裂的访谈。xAI 的早期工程师 Sulaiman Ghoury 在播客中毫无保留地曝光了 xAI 的内部运作细节——从代码提交的具体价值、到利用特斯拉车队做分布式计算的疯狂计划、再到已经在公司内部测试的虚拟员工。",
      "这期播客播出后不久，Sulaiman 就被马斯克开除了。原因很简单：他透露了太多不该说的东西。",
      "Sulaiman Ghoury 是 xAI 从成立8个月时就加入的早期员工，亲历了122天建成 Colossus 数据中心、开发 Grok 模型、以及正在推进的 MicroHard（人类模拟器）项目。他在访谈中几乎没有任何保留，从商业数据、技术细节、到内部决策流程，全盘托出。",
      "这期访谈的信息密度极高。我把他透露的那些\"不该说的东西\"整理出来，你就知道为什么马斯克要开除他了。"
    ],
    "highlights": [
      "关于内部工作模式",
      "Sulaiman 说：\"我们算过一笔账，现在往主仓库提交一次代码，平均价值大约是250万美元。我今天就提交了五次。\"",
      "主持人立刻算了一笔账：那你今天创造了1250万美元的价值？",
      "没错。这就是 xAI 的杠杆效应。",
      "xAI 成立于2023年，是马斯克在被踢出 OpenAI 后创办的 AI 公司。从一开始，这家公司就以惊人的速度在狂奔。122天建成第一个 Colossus 数据中心，连黄仁勋都在公开夸赞这种速度。工程师只有100人左右，规模比其他实验室小了一个数量级，却做出了 Grok 系列模型，现在还在开发 MicroHard——一个能在数字世界里模拟人类工作的系统。",
      "Sulaiman 是怎么加入的？说出来可能会让一些人感到安慰：他之前创业失败了两次。",
      "第一次他想做 MicroHard 的雏形，结果发现\"你不可能靠100万美元就做出 MicroHard 这种东西\"。后来那家公司倒闭了，他又花了半年把钱烧光，去做航天和挖矿项目，结果发现也行不通。于是他又给 xAI 联合创始人 Greg Yang 发邮件问还能不能再聊聊。",
      "第二天面试，周一就入职了。",
      "第一天没人告诉他要干嘛，就给了电脑和工牌。他去找 Greg 说：\"我连团队都没有，也没人给我派活儿。\"Greg 说大概是因为喜欢他之前做的东西跟 MicroHard 的长期目标有关。",
      "这就是 xAI 的风格。没有明确的职位，没有严格的分工，谁能干就谁上。",
      "在 xAI 工作最有趣的地方是什么？",
      "Sulaiman  \"没人会对我说不行。如果我有个好主意，通常当天就能把它做出来，然后展示给马斯克或者其他人看，立马就能得到反馈。\"",
      "这种速度在其他公司几乎不可能。\"我从没在别的地方见过这么多顶尖的人，而且每个人都在一线干活。\"",
      "马斯克对速度的追求到了什么程度？",
      "Sulaiman 说了一句很有意思的话：\"如果你尝试用一个月去干原本要一年的活儿，你可能最后花了两个月才干完，但那依然比原来快得多。\"",
      "关于 MicroHard 和特斯拉车队的计划。",
      "Sulaiman 说他们在做的是 MicroHard \"人类模拟器\"——能在数字世界里模拟人类工作的系统。",
      "\"只要是需要键盘鼠标输入、看着屏幕做决定的活儿，我们都能直接模拟，不需要任何软件适配。\"",
      "那怎么部署呢？",
      "两天后他们就找到了答案：特斯拉的车载电脑。"
    ],
    "fullText": "今天看到一期炸裂的访谈。xAI 的早期工程师 Sulaiman Ghoury 在播客中毫无保留地曝光了 xAI 的内部运作细节——从代码提交的具体价值、到利用特斯拉车队做分布式计算的疯狂计划、再到已经在公司内部测试的虚拟员工。\n这期播客播出后不久，Sulaiman 就被马斯克开除了。原因很简单：他透露了太多不该说的东西。\nSulaiman Ghoury 是 xAI 从成立8个月时就加入的早期员工，亲历了122天建成 Colossus 数据中心、开发 Grok 模型、以及正在推进的 MicroHard（人类模拟器）项目。他在访谈中几乎没有任何保留，从商业数据、技术细节、到内部决策流程，全盘托出。\n这期访谈的信息密度极高。我把他透露的那些\"不该说的东西\"整理出来，你就知道为什么马斯克要开除他了。\n特斯拉车队做分布式计算：北美400万辆特斯拉、80%时间闲置、车载芯片比云服务便宜、付钱给车主租算力\n虚拟员工已在内部测试：同事收到虚拟员工消息、走到办公桌发现根本没人、公司没告诉大家\nColossus 建设的审批trick：以\"嘉年华公司\"名义租临时用地、规避正式审批、122天搞定\n电力系统配置：80多台移动发电机、巨大电池组、市政电网切换、兆瓦级波动\n组织架构细节：只有100人、管理层仅三层、不到8人非工程师、全公司扁平化\nMicroHard 速度目标：最初要求比人类快1.5倍、现在可能快8倍、完全不同的技术路线\n收入目标存在：虽然不能说具体数字、但项目延迟几天就能算出亏损多少\n马斯克的Cybertruck赌约：Tyler 24小时内让GPU跑起来就送车，真的送了\n泛化能力惊人：完全没训练过的任务都能完美完成、今天刚给马斯克演示\n招聘黑客松策略：办活动就为招5个人、预期回报远超成本\n客户工作流程细节：发现客户有20多个未被提及的操作步骤、完全自动驾驶模式\n关于内部工作模式\nSulaiman 说：\"我们算过一笔账，现在往主仓库提交一次代码，平均价值大约是250万美元。我今天就提交了五次。\"\n主持人立刻算了一笔账：那你今天创造了1250万美元的价值？\n没错。这就是 xAI 的杠杆效应。\nxAI 成立于2023年，是马斯克在被踢出 OpenAI 后创办的 AI 公司。从一开始，这家公司就以惊人的速度在狂奔。122天建成第一个 Colossus 数据中心，连黄仁勋都在公开夸赞这种速度。工程师只有100人左右，规模比其他实验室小了一个数量级，却做出了 Grok 系列模型，现在还在开发 MicroHard——一个能在数字世界里模拟人类工作的系统。\nSulaiman 是怎么加入的？说出来可能会让一些人感到安慰：他之前创业失败了两次。\n第一次他想做 MicroHard 的雏形，结果发现\"你不可能靠100万美元就做出 MicroHard 这种东西\"。后来那家公司倒闭了，他又花了半年把钱烧光，去做航天和挖矿项目，结果发现也行不通。于是他又给 xAI 联合创始人 Greg Yang 发邮件问还能不能再聊聊。\n第二天面试，周一就入职了。\n第一天没人告诉他要干嘛，就给了电脑和工牌。他去找 Greg 说：\"我连团队都没有，也没人给我派活儿。\"Greg 说大概是因为喜欢他之前做的东西跟 MicroHard 的长期目标有关。\n这就是 xAI 的风格。没有明确的职位，没有严格的分工，谁能干就谁上。\n在 xAI 工作最有趣的地方是什么？\nSulaiman  \"没人会对我说不行。如果我有个好主意，通常当天就能把它做出来，然后展示给马斯克或者其他人看，立马就能得到反馈。\"\n这种速度在其他公司几乎不可能。\"我从没在别的地方见过这么多顶尖的人，而且每个人都在一线干活。\"\n马斯克对速度的追求到了什么程度？\nSulaiman 说了一句很有意思的话：\"如果你尝试用一个月去干原本要一年的活儿，你可能最后花了两个月才干完，但那依然比原来快得多。\"\n关于 MicroHard 和特斯拉车队的计划。\nSulaiman 说他们在做的是 MicroHard \"人类模拟器\"——能在数字世界里模拟人类工作的系统。\n\"只要是需要键盘鼠标输入、看着屏幕做决定的活儿，我们都能直接模拟，不需要任何软件适配。\"\n那怎么部署呢？\n两天后他们就找到了答案：特斯拉的车载电脑。\n\"北美就有400万辆特斯拉，其中一半以上有硬件四代芯片。这些车80%的时间都停在那儿充电，我们可以付钱给车主租用时间，在车上运行人类模拟器。\"\n在特斯拉电脑上运行模型，比在亚马逊或甲骨文的虚拟机上、甚至比直接买英伟达硬件都要便宜得多。\"这不需要任何额外的基建，纯粹是软件层面的实现。\"\n xAI 可以用接近零成本的方式，获得全球最大的分布式计算网络。\nOpenAI 和 Anthropic 还在为算力发愁，xAI 已经找到了一个几乎是作弊的解决方案。\n而且，这个方案的核心资产，特斯拉完全在马斯克的控制之下。\nxAI内部虚拟员工\nSulaiman 透露他们已经在公司内部测试虚拟员工了。而且没告诉其他员工。\n\"有些员工在干活时，虚拟员工会发消息问'嘿，能帮我个忙吗？'虚拟员工会说'好，来我办公桌这儿聊'，结果那人走过去一看，根本没人。\"\n好几次有人给 Sulaiman 发消息说：\"嘿，组织架构图上显示这个人汇报给你，他今天没来上班吗？\"其实那只是个 AI 虚拟员工。\n这是一个已经在生产环境中运行的系统。而且它的泛化能力\"比我们想象的要强得多\"。\"就在今天我们给马斯克演示了几个案例，那些任务我们完全没训练过，但它完成得非常完美，远超预期。\"\n如果这是真的，那 xAI 可能已经在某种程度上实现了通用智能体，能够自主处理各种数字工作的 AI。这比 Grok 模型本身要重要得多。\n关于 Colossus 数据中心的建设\n他们建 Colossus 数据中心时，技术上租的是\"临时用地\"，因为这是通过审批最快的方法。\n地方政府有个特殊条款，如果你只是想临时改造这块地，比如办个嘉年华，审批就很快。\n“所以 xAI 其实是一家\"嘉年华公司\"？\n\"没错，目前就是一家嘉年华公司，所以122天就搞定了。\"\n这等于告诉监管部门：\"我们钻了你们的空子。\"\n关于电力系统\nSulaiman 透露了让人咋舌的细节。\n当地方电网负荷太高时，他们就得切换到用卡车运来的80多台移动发电机供电。\n\"我们必须做到无缝切换，不能干扰到那些极其脆弱的训练任务。GPU 和硬件对电力的需求波动非常大，毫秒之间就能产生兆瓦级的变化。\"\n这也是为什么在数据中心旁边放巨大电池组。\n\"电池的调峰能力比发电机快得多。发电机是物理转动的东西，加速减速都需要时间。\"\n从物理层面看，他们有本地电容、电池组、发电机，最后才是市政电网。这种配置的成本绝对是天文数字。\n关于 xAI 的组织架构。\n\"管理层只有三层：IC（独立贡献者）、联合创始人及部分新经理、然后就是马斯克。因为每个经理要带的人太多了，所以没什么东西是自上而下强推的。\"\n全公司工程师大概100个左右。\n\"全公司可能只有不到8个人不是工程师背景\"。\n销售团队也全是工程师。\"我当时心想销售？那我不想跟他聊了。\n结果他转头就开始跟我聊他正在训练的一个模型。\"\n这种极致扁平化的组织，在硅谷可能是独一份。但公开透露这些信息，等于把 xAI 的核心竞争力：极致的效率和速度的实现方式全盘托出。竞争对手听了会说谢谢。\n关于马斯克的管理方式，\nSulaiman 也透露了不少细节。\n\"马斯克的反馈要么非常宏观，要么非常微观，很少有中间地带。宏观上可能是产品方向和客户定位，微观上尤其是涉及计算效率和延迟时，他总能给出具体建议。\"\n而且马斯克\"其实很愿意接受自己是错的，但你得拿出证据，必须是'我们试一下看结果'，不能只是个人观点\"。\n有一次开会，马斯克听完汇报直接打了个电话，\"对方的软件团队第二天就发了补丁，大家并肩作战直到问题解决。如果是平时，这种事儿可能要来回扯皮好几周\"。\nTyler 跟马斯克打赌的故事也很离谱。当时他们在安装新的 GPU，马斯克说如果 Tyler 能在24小时内让这些 GPU 开始跑训练，就送他一辆 Cybertruck。\n结果那天晚上真的跑起来了。Tyler 拿到了车，Sulaiman 说：\"我现在从食堂窗户看出去，还能看到那辆车。\"\n这种赌约文化在马斯克的公司里很常见，但公开说出来，会让外界对 xAI 的工作方式产生各种揣测。\n关于 MicroHard 的决策\nSulaiman 透露了一个关键信息。\n\"其中之一是决定让 MicroHard 的模型运行速度至少比人类快1.5倍。现在看来，它可能比人类快得多，甚至是8倍。\"\n这个决策让他们走上了一条完全不同的路。\"其他实验室做人类模拟器时，思路通常是增加推理能力，把模型做大。但那个决策让我们走上了一条完全不同的路。\"\n为什么速度这么重要？\"参考 FSD（全自动驾驶）也能预见到，谁也不想等十分钟让电脑干一件我自己五分钟就能干完的事儿。但如果它10秒钟就能干完，那我愿意付很多钱。\"\n这个逻辑显而易见，但把它作为核心产品策略公开出来，等于告诉竞争对手：这是正确的方向。\n关于客户工作流程\nSulaiman 透露他们在跟客户合作时，会访谈、观察、实地观察。\n\"一周后我们发现虚拟员工总在某些特定地方犯错，我们就跑去观察真人是怎么做的。结果发现真人操作里有二十多个步骤，在之前的访谈里完全没提过。\"\n这说明人类在重复做某件事时，已经进入了\"自动驾驶模式\"。\n\"就像你开车开了1个小时，可能一秒钟的记忆都没留下。\"\nMicroHard 的核心技术路线是靠观察真实工作流程。\n关于收入目标\nSulaiman 虽然说\"具体数字我不能说\"，但他透露了一个关键信息：\"在我脑子里，只要项目延迟或提前，我能立刻算出这一年我们是多赚了还是亏了多少钱。\"\n主持人说：\"这种波动一定很惊人。\"\nSulaiman 说：\"是的，数字非常巨大，因为预期回报太高，而且节奏太快，所以几天的延迟在比例上就显得非常可观。\"\n这等于间接确认了 xAI 有明确的、可能非常激进的收入目标。\n写在最后\n整期访谈下来，Sulaiman 几乎把 xAI 的所有核心机密都说了一遍：商业数据、技术路线、组织架构、基础设施、客户策略、甚至未来的分布式计算计划。\n这些信息对竞争对手来说价值连城，对监管部门来说可能是调查的线索，对投资人来说是珍贵的内部信息。\n据传，这期播客播出后不久，他就被马斯克开除了。\n对我们这些吃瓜群众来说，这可能是了解 xAI 内部运作最真实、最详细的一次机会。\n毕竟，以后再也不会有人敢这么说了。\n",
    "ytTitle": null,
    "ytChannel": null,
    "ytChannelUrl": null,
    "ytViews": null,
    "ytPublished": null
  },
  {
    "id": "EED3wO1i7iGPagkeleMc5AfAnKF",
    "title": "Sam Altman 访谈：AI 知识工作的未来 | 2026-02-07",
    "rawTitle": "Sam Altman 访谈：AI 知识工作的未来 | 2026-02-07",
    "dateCode": "",
    "youtubeId": "PMUK3Th80vc",
    "feishuUrl": "https://my.feishu.cn/wiki/EED3wO1i7iGPagkeleMc5AfAnKF",
    "intro": [
      "Sam Altman 最新预言：AI 知识工作的未来",
      "> 未来不是不同工具做不同任务——而是一个统一的 AI 处理一切",
      "核心洞察：",
      "• 从Vibe Coding到专业工程的分裂正在消失",
      "• 编码模型将成为所有知识工作的底层能力",
      "• 单一 AI 助手将整合记忆、上下文、公司知识"
    ],
    "highlights": [
      "来源： Stanford GSB 专访\n视频链接： https://www.youtube.com/watch?v=PMUK3Th80vc\n整理： 小爪 🐾"
    ],
    "fullText": "Sam Altman 最新预言：AI 知识工作的未来\n> 未来不是不同工具做不同任务——而是一个统一的 AI 处理一切\n核心洞察：\n• 从Vibe Coding到专业工程的分裂正在消失\n• 编码模型将成为所有知识工作的底层能力\n• 单一 AI 助手将整合记忆、上下文、公司知识\n总结一下做个笔记👇\n1️⃣ 编码模型是下一代知识工作的基础设施\n即使很多人意识不到他们在编程，但实际上每个人都会使用编码模型来完成各种知识工作。\n2️⃣ Vibe Coding 和专业工程的界限正在模糊\n以前分得很开：普通人用聊天，工程师用代码。未来会是同一个 AI。\n3️⃣ 统一记忆是核心竞争力\n一个 AI 记住你的一切——你的写作风格、公司上下文、项目历史。\n4️⃣ 用途无缝切换\n从科学发现到写邮件草稿，同一个 AI 随时可用电脑完成任务。\n5️⃣ OpenAI 的战略转变\n从聊天为主转向编码+聊天融合，统一解决所有问题。\n---\n来源： Stanford GSB 专访 | YouTube: https://www.youtube.com/watch?v=PMUK3Th80vc\n断断续续，终于看完了 Sam Altman 在 Stanford GSB 的专访。\n说实话，这次访谈非常短，但信息密度极高。Altman 分享了他对 AI 未来格局的核心判断——不是工具分裂，而是一个统一的 AI 搞定一切。\n为什么值得关注？因为这代表了 OpenAI 战略方向的重大转向，也是每个知识工作者必须理解的趋势。\n我今天不忙，把这次访谈的核心观点精编出来，供大家学习。赠人玫瑰，手有余香。\n下面是 YouTube 链接：https://www.youtube.com/watch?v=PMUK3Th80vc\n#01 从分裂到统一\n主持人： 我很好奇你的看法。过去几年 OpenAI 的策略似乎是Vibe Coding——普通人在 ChatGPT 里聊天，而专业的工程工作交给 Codex。这种分裂好像正在改变？\nSam Altman： 我相信这一定会融合。未来人们会使用同一个 AI。有时候做不那么严肃的工作，有时候做极其严肃的工作。但它会拥有你的所有记忆、所有上下文，根据需要连接到你的公司。然后你就可以说：我要做一个重大的科学发现，或者我需要起草一封邮件——然后让 AI 使用你的电脑做任何需要的事。\n编辑解读：\nAltman 这段话描绘了一个非常清晰的未来图景。\n关键转变在于：\n从不同工具服务不同人群 → 同一个 AI 服务同一个人\n这意味着什么？\n意味着你现在在 ChatGPT 里学到的提示词技巧、对话方式，会直接迁移到未来的专业工作场景。不会有一条清晰的分界线说\"到这里你必须换工具\"。\n也意味着记忆和上下文会成为 AI 的核心竞争力。谁能更好地记住你的偏好、理解你的业务上下文，谁就能赢得用户。\n#02 编码模型是底层能力\nSam Altman： 我们绝对会看到一种趋势——每个人都在使用编码模型，即使他们没有意识到这一点，来完成各种令人印象深刻的知识工作。会有很好的方式来实现这种整合。\n编辑解读：\n这句话揭示了 Altman 战略判断的核心：\n编码模型 = 下一代知识工作的 CPU\n什么意思？\n以前我们说\"会用 Excel\"是职场基本功，以后\"会用 AI 编程\"也会成为基本功。不是说你要去当程序员，而是你要理解如何用自然语言指挥 AI 完成任务。\nVibe Coding（感觉式编程）这个词可能会逐渐消失——因为以后所有工作都是\"感觉式\"的，只是背后的技术越来越强大。\n延伸思考：\nAltman 没有说但暗示了的是：\n• 专业化分工消失：以前有\"产品经理不懂技术\"的问题，以后不存在了——每个人都指挥 AI\n• 速度决定一切：谁能更快地把需求转化为 AI 指令，谁就赢\n• 上下文即护城河：你的公司知识、你的个人偏好、你的项目历史——这些会成为 AI 能力的放大器\n编辑小结：\n这次访谈虽然短，但 Altman 说了几个非常关键的判断：\n统一大于分裂 —— 不会再有\"普通人用聊天，专家用代码\"的分裂\n记忆即能力 —— 谁记住你更多，谁就更强\n编码是基础设施 —— 即使你不写代码，你也在使用编码模型\nOpenAI 的战略方向很清晰：做一个统一的 AI，满足所有知识工作需求。\n未来已来，只是分布不均。\n来源： Stanford GSB 专访\n视频链接： https://www.youtube.com/watch?v=PMUK3Th80vc\n整理： 小爪 🐾\n",
    "ytTitle": "Sam Altman: AI Will Replace All Knowledge Work Through One Universal Assistant",
    "ytChannel": "Every",
    "ytChannelUrl": "https://www.youtube.com/@EveryInc",
    "ytViews": null,
    "ytPublished": null
  }
]